{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48315979-642e-442e-a129-ddbcf65630b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%run ../load_magic/storage.py\n",
    "\n",
    "s = Storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cdc476b-b971-4f98-871d-a8636f155971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_proportion_score(word_str, letter_proportions_df):\n",
    "    word_score = 0\n",
    "    for row_index, row_series in letter_proportions_df.iterrows():\n",
    "        letter = row_series.letter_char\n",
    "        if letter in word_str:\n",
    "            proportion = row_series.proportion\n",
    "            word_score += proportion\n",
    "    \n",
    "    return word_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ce3eba1-301c-4abc-93e3-7b09f3bd6556",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_lists(candidate_word, colors_list, greys_list=None, yellows_list=None, greens_list=None):\n",
    "    if greys_list is None: greys_list = []\n",
    "    if yellows_list is None: yellows_list = []\n",
    "    if greens_list is None: greens_list = []\n",
    "    for color, index in zip(range(len(candidate_word)), colors_list):\n",
    "        if color == 'grey':\n",
    "            greys_list.append(candidate_word[index])\n",
    "        elif color == 'yellow':\n",
    "            yellows_list.append(candidate_word[index])\n",
    "        elif color == 'green':\n",
    "            greens_list.append(f\"(candidate_word[{index}] == '{candidate_word[index]}')\")\n",
    "    \n",
    "    return greys_list, yellows_list, greens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85489573-1d6f-41df-baf3-57a12c61ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_best_word(candidates_list):\n",
    "    \n",
    "    # Get proportions from candidate list\n",
    "    import collections\n",
    "\n",
    "    letters_list = []\n",
    "    for word_str in candidates_list:\n",
    "        letters_list += list(word_str)\n",
    "    counter = collections.Counter(letters_list)\n",
    "    letter_proportions_df = pd.DataFrame([{'letter_char': x, 'letter_count': y} for x, y in dict(counter).items()])\n",
    "    min_count = letter_proportions_df.letter_count.min()\n",
    "    letter_proportions_df['proportion'] = letter_proportions_df.letter_count.map(lambda x: x/min_count)\n",
    "    \n",
    "    # Minimize words to pick through after you get the next word colors back\n",
    "    \n",
    "    # Calculate maximum proportionality\n",
    "    max_score = 0\n",
    "    max_word = ''\n",
    "    for word_str in candidates_list:\n",
    "        word_score = get_proportion_score(word_str, letter_proportions_df)\n",
    "        if word_score > max_score:\n",
    "            max_score = word_score\n",
    "            max_word = word_str\n",
    "    \n",
    "    return max_word, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d82462-72fc-459d-a936-fedbe029ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get words from the Wordle JavaScript\n",
    "if s.pickle_exists('wordle_words_list'):\n",
    "    words_list = s.load_object('wordle_words_list')\n",
    "else:\n",
    "\n",
    "    # Get words from the Wordle JavaScript\n",
    "    import requests\n",
    "\n",
    "    link = 'https://www.powerlanguage.co.uk/wordle/main.db1931a8.js'\n",
    "    f = requests.get(link)\n",
    "    commands_list = f.text.split(';')\n",
    "    list_str = commands_list[331].split(']')[0].split('[')[1]\n",
    "    words_list = eval(f'[{list_str}]')\n",
    "    s.store_objects(wordle_words_list=words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526994aa-c309-4995-9bb2-9ad653238a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if s.pickle_exists('english_letter_frequencies_df'):\n",
    "    letter_proportions_df = s.load_object('english_letter_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get proportions from word list\n",
    "    import collections\n",
    "\n",
    "    letters_list = []\n",
    "    for word_str in words_list:\n",
    "        letters_list += list(word_str)\n",
    "    counter = collections.Counter(letters_list)\n",
    "    letter_proportions_df = pd.DataFrame([{'letter_char': x, 'letter_count': y} for x, y in dict(counter).items()])\n",
    "    min_count = letter_proportions_df.letter_count.min()\n",
    "    letter_proportions_df['proportion'] = letter_proportions_df.letter_count.map(lambda x: x/min_count)\n",
    "    s.store_objects(english_letter_frequencies_df=letter_proportions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c8740-402f-408f-a87e-49bed619a97a",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Solve a Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf6ae53-67c5-47f9-a313-b3f54e38638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get words from GloVe: Global Vectors for Word Representation\n",
    "import re\n",
    "\n",
    "words_list = []\n",
    "file_path = r'D:\\Documents\\GitHub\\job-hunting\\data\\6B\\glove.6B.300d.txt'\n",
    "az_regex = re.compile('[^a-z]')\n",
    "with open(file_path, encoding='utf8') as infile:\n",
    "    for line in infile:\n",
    "        word_str = line.split()[0]\n",
    "        if (len(word_str) == 5) and not az_regex.search(word_str):\n",
    "            words_list.append(word_str)\n",
    "words_list.remove('aerio')\n",
    "words_list.remove('ioane')\n",
    "words_list.remove('eonia')\n",
    "words_list.remove('tabou')\n",
    "words_list.remove('tamou')\n",
    "words_list.remove('tarom')\n",
    "words_list.remove('tarmo')\n",
    "words_list.remove('marot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de2d02d9-d897-41cd-a032-93bd440627a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words_list.remove('marto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ff01416-897e-417b-aced-6c9a7234aace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('raise', 188.09339407744875)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max_word, max_score = get_best_word(words_list)\n",
    "max_word, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c63c296b-bbbd-4f89-9db0-db5046965d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabor ['aabar', 'aamar', 'aarau', 'aaron', 'aaryn', 'baard', 'baarn', 'babar', 'babor', 'babra', 'babur', 'bacar', 'badar', 'bador', 'badra', 'badru', 'badry', 'bagar', 'bagra', 'bahar', 'bahro', 'bahru', 'bajar', 'bajor', 'bajra', 'bajur', 'bakar', 'bakra', 'bakry', 'bakur', 'balar', 'baldr', 'balor', 'bamar', 'baqar', 'baraa', 'barab', 'barac', 'barad', 'barah', 'barak', 'baral', 'baram', 'baran', 'baraq', 'barat', 'barau', 'baray', 'barba', 'barbo', 'barbu', 'barby', 'barca', 'barch', 'barco', 'barda', 'bardo', 'bardu', 'bardy', 'barff', 'barga', 'bargh', 'bargo', 'bargy', 'barha', 'barka', 'barko', 'barla', 'barma', 'barmy', 'barna', 'barno', 'barnt', 'barny', 'baron', 'barot', 'barra', 'barro', 'barry', 'barta', 'barth', 'bartl', 'barto', 'barty', 'bartz', 'barua', 'barud', 'barum', 'barun', 'baruq', 'barva', 'barwa', 'barza', 'bator', 'batra', 'batur', 'batyr', 'bauru', 'bawra', 'bayar', 'bayor', 'bazar', 'cabra', 'cakra', 'calor', 'camra', 'camry', 'capra', 'caral', 'caram', 'carat', 'carax', 'caray', 'carbo', 'carby', 'carco', 'cardo', 'cardy', 'carga', 'cargo', 'carla', 'carll', 'carlo', 'carly', 'carma', 'carmo', 'carna', 'carno', 'carny', 'carob', 'carod', 'carol', 'carom', 'caron', 'carow', 'carpa', 'carra', 'carro', 'carry', 'carta', 'carto', 'carty', 'carya', 'caryl', 'caryn', 'cator', 'cayor', 'daara', 'dabar', 'dabra', 'dabur', 'dadar', 'dadra', 'dafur', 'dagar', 'dagor', 'dagur', 'dahar', 'dakar', 'dalry', 'damar', 'damra', 'daour', 'daraa', 'darab', 'darah', 'daraj', 'darak', 'daran', 'daraq', 'darat', 'daraz', 'darbo', 'darby', 'darcy', 'darda', 'dardo', 'darga', 'dargo', 'darja', 'darko', 'darky', 'darla', 'darly', 'darma', 'darna', 'darod', 'darol', 'darom', 'daron', 'darpa', 'darra', 'darro', 'darry', 'darth', 'darty', 'darug', 'darul', 'darva', 'darya', 'daryl', 'daryn', 'datar', 'daura', 'davar', 'davor', 'davro', 'dawar', 'dawra', 'dayro', 'fabra', 'fabro', 'fabry', 'fagor', 'fajar', 'fakhr', 'falor', 'fanar', 'faour', 'farad', 'farag', 'farah', 'faraj', 'faran', 'farar', 'faraz', 'farda', 'fardc', 'fardh', 'farfa', 'fargo', 'farha', 'farka', 'farma', 'farol', 'faron', 'farra', 'farro', 'farry', 'faruj', 'faruk', 'farul', 'farum', 'faruq', 'faryd', 'faryl', 'fator', 'fatra', 'faura', 'favor', 'fawar', 'gaard', 'gabar', 'gabor', 'gabra', 'gabry', 'gadar', 'gafar', 'gafur', 'gagor', 'gagra', 'gajar', 'ganar', 'ganor', 'garab', 'garad', 'garak', 'garam', 'garan', 'garat', 'garay', 'garba', 'garbh', 'garbo', 'garda', 'gardo', 'gardy', 'garff', 'garga', 'garko', 'garma', 'garmo', 'garon', 'garou', 'garra', 'garro', 'garry', 'garth', 'gartz', 'garua', 'garud', 'garum', 'garut', 'garza', 'gator', 'gatra', 'gaura', 'gavar', 'gazar', 'haarp', 'haart', 'habar', 'habor', 'habra', 'habur', 'hadar', 'hador', 'hadra', 'hagar', 'hahrd', 'hajar', 'hajra', 'hamar', 'hamor', 'hamra', 'hapur', 'harad', 'haraj', 'harak', 'haram', 'haran', 'harap', 'harar', 'harat', 'harav', 'haraz', 'harba', 'harby', 'harco', 'harda', 'hardt', 'hardy', 'harfa', 'harff', 'harjo', 'harju', 'harka', 'harod', 'haron', 'harpa', 'harpo', 'harpy', 'harra', 'harro', 'harry', 'harta', 'harth', 'hartl', 'harto', 'hartt', 'harty', 'hartz', 'haruf', 'harum', 'harun', 'haruo', 'harut', 'hatra', 'hatry', 'haugr', 'haury', 'hawar', 'hazar', 'hazor', 'hazra', 'jaara', 'jabar', 'jabor', 'jabra', 'jabur', 'jacor', 'jadar', 'jafar', 'jafra', 'jahar', 'jahra', 'jamar', 'jamra', 'jarad', 'jarah', 'jarak', 'jaral', 'jaran', 'jarar', 'jaray', 'jarba', 'jarka', 'jarmo', 'jarno', 'jarod', 'jaron', 'jarpa', 'jarry', 'jatra', 'javar', 'javor', 'jawar', 'jawor', 'jazar', 'kabar', 'kabra', 'kacar', 'kadar', 'kadyr', 'kafar', 'kafra', 'kafur', 'kahar', 'kahrd', 'kakar', 'kalar', 'kalra', 'kamar', 'kamra', 'kanar', 'kaoru', 'kapar', 'kapor', 'kapur', 'karad', 'karaj', 'karak', 'karal', 'karam', 'karan', 'karar', 'karat', 'karbo', 'karch', 'kargo', 'karhu', 'karka', 'karkh', 'karla', 'karlo', 'karly', 'karma', 'karna', 'karno', 'karny', 'karol', 'karon', 'karoo', 'karou', 'karpa', 'karpf', 'karpo', 'karra', 'karry', 'karta', 'karth', 'karua', 'karuk', 'karun', 'karup', 'karur', 'karwa', 'karya', 'karyl', 'karyn', 'karyo', 'katar', 'kator', 'katra', 'katyr', 'kaura', 'kawar', 'labor', 'labra', 'labro', 'lacor', 'ladar', 'lador', 'ladra', 'lahar', 'lahor', 'lakra', 'lalor', 'lamar', 'laran', 'larba', 'larch', 'larco', 'lardo', 'lardy', 'larga', 'largo', 'larky', 'larma', 'laron', 'laroy', 'larra', 'larry', 'larut', 'larva', 'latro', 'latur', 'laura', 'lauro', 'laury', 'lavar', 'lavor', 'lavra', 'lawry', 'layar', 'lazar', 'lazor', 'mabry', 'macor', 'macra', 'macro', 'macur', 'madar', 'madra', 'mafra', 'magar', 'magor', 'magra', 'magro', 'mahar', 'mahra', 'mahrt', 'mahru', 'mahur', 'majar', 'major', 'majra', 'makar', 'makor', 'makro', 'malar', 'malor', 'manar', 'manor', 'marad', 'marah', 'maraj', 'marak', 'maral', 'maram', 'maran', 'marar', 'marat', 'marca', 'march', 'marck', 'marco', 'marcq', 'marcu', 'marcy', 'marda', 'mardy', 'marfa', 'marga', 'margo', 'margy', 'marha', 'marja', 'marjo', 'marka', 'marko', 'markt', 'marku', 'marky', 'marla', 'marlo', 'marlu', 'marly', 'marma', 'marmo', 'marna', 'marny', 'maroc', 'marof', 'marol', 'marom', 'maron', 'marou', 'marpa', 'marra', 'marro', 'marry', 'marta', 'marth', 'martu', 'marty', 'martz', 'maruf', 'marum', 'marun', 'maruo', 'marut', 'marva', 'marwa', 'marya', 'maryk', 'marzo', 'matar', 'matra', 'matru', 'maura', 'mauro', 'maury', 'mavor', 'mavra', 'mavro', 'mawar', 'mayar', 'mayor', 'mayra', 'mayur', 'mazar', 'mazor', 'mazra', 'mazur', 'nabor', 'nachr', 'nacra', 'nadar', 'nador', 'nadra', 'nadur', 'nafar', 'nagar', 'nagor', 'nagra', 'nahar', 'nahor', 'nahra', 'najar', 'nakar', 'namor', 'namur', 'nanur', 'naour', 'napro', 'naral', 'naran', 'naray', 'narba', 'narch', 'narco', 'narcy', 'narda', 'nardo', 'narla', 'narod', 'narok', 'narol', 'narra', 'narro', 'narth', 'narum', 'narva', 'narwa', 'naryn', 'natar', 'natur', 'nauru', 'navar', 'nawar', 'nayar', 'nazar', 'nazor', 'oakar', 'paarl', 'padar', 'padro', 'pagar', 'pahar', 'pahor', 'pakur', 'palar', 'papar', 'parad', 'parag', 'parah', 'param', 'paran', 'parar', 'paray', 'parch', 'parco', 'parda', 'pardo', 'pardy', 'parga', 'pargh', 'pargo', 'parka', 'parla', 'parlo', 'parma', 'parnu', 'parol', 'paroo', 'parot', 'parow', 'parra', 'parro', 'parry', 'parta', 'parth', 'parto', 'party', 'parul', 'parun', 'parur', 'parva', 'parvo', 'patar', 'patra', 'patro', 'patru', 'patry', 'paura', 'pawar', 'payor', 'pazar', 'qadar', 'qadry', 'qahar', 'qajar', 'qamar', 'qarah', 'qarun', 'qatar', 'taara', 'tabar', 'tabor', 'tabra', 'tafur', 'tagar', 'tagro', 'tahar', 'takur', 'talar', 'tamar', 'tamra', 'tamur', 'tanar', 'tanor', 'tanur', 'tarab', 'taraf', 'tarah', 'tarak', 'taral', 'taran', 'tarar', 'taraz', 'tarba', 'tarda', 'tardo', 'tardy', 'targa', 'targu', 'tarja', 'tarka', 'tarlo', 'tarma', 'tarmu', 'tarna', 'tarok', 'taron', 'tarot', 'tarra', 'tarry', 'tarta', 'tarto', 'tartt', 'tartu', 'tarty', 'taruc', 'tarun', 'taryn', 'tatar', 'tatra', 'tatro', 'tatry', 'taura', 'tauro', 'tavor', 'tawar', 'tayar', 'vaart', 'vadra', 'vahrd', 'vajra', 'valar', 'valor', 'valur', 'vapor', 'varah', 'varan', 'varco', 'varda', 'vardo', 'vardy', 'varga', 'vargo', 'varla', 'varma', 'varna', 'varno', 'varon', 'varro', 'varta', 'varty', 'varum', 'varun', 'varya', 'vatra', 'vatry', 'vavra', 'waard', 'waart', 'wagar', 'wakra', 'waqar', 'warao', 'waray', 'warba', 'warby', 'warda', 'wardy', 'warga', 'wargo', 'warka', 'warna', 'warta', 'warth', 'warty', 'warum', 'waurn', 'wawro', 'yagur', 'yajur', 'yanar', 'yanru', 'yapor', 'yardy', 'yaron', 'yarov', 'yarra', 'yarur', 'yator', 'yatra', 'yawar', 'zaara', 'zabar', 'zadar', 'zador', 'zadra', 'zafar', 'zafra', 'zagar', 'zagor', 'zahar', 'zahra', 'zamor', 'zarah', 'zarak', 'zaran', 'zarar', 'zarco', 'zarda', 'zardo', 'zarka', 'zarko', 'zarma', 'zarqa', 'zarra', 'zarya', 'zarza', 'zator', 'zawar', 'zawra']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "greys_list = ['i', 's', 'e']\n",
    "yellows_list = ['r', 'a']\n",
    "candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if (word_str[0] not in ['r']) and (word_str[1] == 'a') and (word_str[2] not in ['i']):\n",
    "        if (word_str[3] not in ['s']) and (word_str[4] not in ['e']):\n",
    "            if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                    candidates_list.append(word_str)\n",
    "max_word, max_score = get_best_word(candidates_list)\n",
    "print(max_word, sorted(candidates_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc4e3156-dbb5-4474-a425-9c52013c8b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taboo ['taboo', 'tabot', 'tacom', 'tatoo', 'tatou', 'tavoy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "greys_list = ['i', 's', 'e', 'b', 'o']\n",
    "yellows_list = ['r', 'a']\n",
    "candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if (word_str[0] == 't') and (word_str[1] == 'a') and (word_str[2] not in ['i']):\n",
    "        if (word_str[3] not in ['s']) and (word_str[4] not in ['e']):\n",
    "            if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                    candidates_list.append(word_str)\n",
    "max_word, max_score = get_best_word(candidates_list)\n",
    "print(max_word, sorted(candidates_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc5f3d4e-0ec4-4152-9c59-72831738e9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak ['sheaf', 'speak']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "greys_list = ['r', 'i', 'l', 'n', 't', 'd']\n",
    "yellows_list = ['a', 's', 'e']\n",
    "candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if (word_str[0] == 's') and (word_str[1] not in ['a', 'e', 't']) and (word_str[2] == 'e'):\n",
    "        if (word_str[3] == 'a') and (word_str[4] not in ['e', 's', 'd']):\n",
    "            if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                    candidates_list.append(word_str)\n",
    "max_word, max_score = get_best_word(candidates_list)\n",
    "print(max_word, sorted(candidates_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88bb9c59-91b4-49c3-8c2b-014f17a98710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trams ['tracs', 'traks', 'trams', 'trays']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "greys_list = ['l', 'e', 'h', 'n', 'p']\n",
    "yellows_list = ['a', 't', 'r', 's']\n",
    "candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if (word_str[0] == 't') and (word_str[1] == 'r') and (word_str[2] == 'a'):\n",
    "        if (word_str[3] not in ['e', 's', 'n', 'p']) and (word_str[4] == 's'):\n",
    "            if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                    candidates_list.append(word_str)\n",
    "max_word, max_score = get_best_word(candidates_list)\n",
    "print(max_word, sorted(candidates_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4dc91f7-e9f0-459d-b61d-cc6288bd38e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trays ['tracs', 'traks', 'trays']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "greys_list = ['l', 'e', 'h', 'n', 'p', 'm']\n",
    "yellows_list = ['a', 't', 'r', 's']\n",
    "candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if (word_str[0] == 't') and (word_str[1] == 'r') and (word_str[2] == 'a'):\n",
    "        if (word_str[3] not in ['e', 's', 'n', 'p', 'm']) and (word_str[4] == 's'):\n",
    "            if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                    candidates_list.append(word_str)\n",
    "max_word, max_score = get_best_word(candidates_list)\n",
    "print(max_word, sorted(candidates_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe32844-4fec-4703-aa09-1ea42c04dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_largest_equivalence_class(candidates_list, base_greys_list=None, base_yellows_list=None, base_greens_list=None):\n",
    "    if base_greys_list is None: base_greys_list = []\n",
    "    if base_yellows_list is None: base_yellows_list = []\n",
    "    if base_greens_list is None: base_greens_list = []\n",
    "    max_possibles_list = []\n",
    "    max_candidate_word = ''\n",
    "    for candidate_word in candidates_list:\n",
    "        possibles_list = []\n",
    "        for color1 in ['grey', 'yellow', 'green']:\n",
    "            for color2 in ['grey', 'yellow', 'green']:\n",
    "                for color3 in ['grey', 'yellow', 'green']:\n",
    "                    for color4 in ['grey', 'yellow', 'green']:\n",
    "                        for color5 in ['grey', 'yellow', 'green']:\n",
    "                            colors_list = [color1, color2, color3, color4, color5]\n",
    "                            greys_list, yellows_list, greens_list = build_lists(candidate_word, colors_list,\n",
    "                                                                                base_greys_list, base_yellows_list, base_greens_list)\n",
    "                            if all(map(lambda x: eval(x), greens_list)):\n",
    "                                if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                                    if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                                        possibles_list.append(candidate_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c52589-61c0-422b-a08a-53463ad76bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for word_str in candidates_list:\n",
    "    greys_list = ['a', 'i', 's']\n",
    "    yellows_list = ['r']\n",
    "    greens_list = [\"(candidate_word[4] == 'e')\"]\n",
    "    max_possibles_list = get_largest_equivalence_class(word_str, base_greys_list=greys_list, base_yellows_list=yellows_list, base_greens_list=greens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a1d462-74e7-4137-b6c0-4d24e736aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forge ['forge', 'gorge']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "greys_list = ['l', 'a', 't', 'u']\n",
    "yellows_list = ['r', 'g']\n",
    "candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if (word_str[0] not in ['l', 'r']) and (word_str[1] == 'o') and (word_str[2] not in ['t', 'g']):\n",
    "        if (word_str[3] not in ['e', 'u']) and (word_str[4] == 'e'):\n",
    "            if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                    candidates_list.append(word_str)\n",
    "max_word, max_score = get_best_word(candidates_list)\n",
    "print(max_word, sorted(candidates_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b79ec7-87ee-4f7f-a16a-6552b6da1f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gorge ['gorge']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "greys_list = ['l', 'a', 't', 'u', 'f']\n",
    "yellows_list = []\n",
    "candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if (word_str[0] not in ['l', 'r', 'f']) and (word_str[1] == 'o') and (word_str[2] == 'r'):\n",
    "        if (word_str[3] == 'g') and (word_str[4] == 'e'):\n",
    "            if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                    candidates_list.append(word_str)\n",
    "max_word, max_score = get_best_word(candidates_list)\n",
    "print(max_word, sorted(candidates_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db6ab8-8ad5-4020-a3e5-3aa8d65c985a",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7998f7b-c11b-4fb6-b377-0714029ee27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "random.sample(words_list, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2e582-41a4-4883-816a-e3c4f9e32b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "letter_proportions_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60784307-9098-462e-9b60-8ebb82a74570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (letter_proportions_df.letter_char == 'e')\n",
    "letter_proportions_df[mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadc25d-db2c-40b6-80a9-85b46285a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "letter_proportions_df.sort_values('proportion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63baa5d4-f095-4634-b382-7258a0c60cf4",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53706f0-4bd1-4d27-b4d0-57e5237cb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if s.pickle_exists('english_word_frequencies_df'):\n",
    "    word_proportions_df = s.load_object('english_word_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get words from the Wordle JavaScript\n",
    "    if s.pickle_exists('wordle_words_list'):\n",
    "        words_list = s.load_object('wordle_words_list')\n",
    "    else:\n",
    "\n",
    "        # Get words from the Wordle JavaScript\n",
    "        import requests\n",
    "\n",
    "        link = 'https://www.powerlanguage.co.uk/wordle/main.db1931a8.js'\n",
    "        f = requests.get(link)\n",
    "        commands_list = f.text.split(';')\n",
    "        list_str = commands_list[331].split(']')[0].split('[')[1]\n",
    "        words_list = eval(f'[{list_str}]')\n",
    "        s.store_objects(wordle_words_list=words_list)\n",
    "        \n",
    "    rows_list = [{'word_str': word_str, 'proportion_score': get_proportion_score(word_str)} for word_str in words_list]\n",
    "    word_proportions_df = pd.DataFrame(rows_list)\n",
    "    s.store_objects(english_word_frequencies_df=word_proportions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1a5d9-315a-4136-9fc9-7a7faf92c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_proportions_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b7266-269e-4978-93b4-e6538b27567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proportion_score_dict = word_proportions_df.set_index('word_str').proportion_score.to_dict()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "307a8a6e-86b1-4e11-a1f3-7d4e7aff9ae7",
   "metadata": {},
   "source": [
    "\n",
    "if s.pickle_exists('english_word_frequencies_df'):\n",
    "    word_proportions_df = s.load_object('english_word_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get words from the word list\n",
    "    if s.pickle_exists('glove_english_five_letter_words_list'):\n",
    "        words_list = s.load_object('glove_english_five_letter_words_list')\n",
    "    else:\n",
    "        \n",
    "        # Get words from GloVe: Global Vectors for Word Representation\n",
    "        import re\n",
    "        \n",
    "        words_list = []\n",
    "        file_path = r'D:\\Documents\\GitHub\\job-hunting\\data\\6B\\glove.6B.300d.txt'\n",
    "        az_regex = re.compile('[^a-z]')\n",
    "        with open(file_path, encoding='utf8') as infile:\n",
    "            for line in infile:\n",
    "                word_str = line.split()[0]\n",
    "                if (len(word_str) == 5) and not az_regex.search(word_str):\n",
    "                    words_list.append(word_str)\n",
    "        \n",
    "        words_list.remove('aerio')\n",
    "        words_list.remove('ioane')\n",
    "        words_list.remove('eonia')\n",
    "        words_list.remove('sunol')\n",
    "        words_list.remove('solun')\n",
    "        words_list.remove('skuld')\n",
    "        s.store_objects(glove_english_five_letter_words_list=words_list)\n",
    "    rows_list = [{'word_str': word_str, 'proportion_score': get_proportion_score(word_str)} for word_str in words_list]\n",
    "    word_proportions_df = pd.DataFrame(rows_list)\n",
    "    s.store_objects(english_word_frequencies_df=word_proportions_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b276b57-2ae0-4c93-96bf-bb0a4d1a5aec",
   "metadata": {},
   "source": [
    "\n",
    "if s.pickle_exists('popular_english_five_letter_words_list'):\n",
    "    words_list = s.load_object('popular_english_five_letter_words_list')\n",
    "else:\n",
    "    %run ../load_magic/soup.py\n",
    "\n",
    "    file_path = '../data/html/five_letter_words.html'\n",
    "    page_soup = get_page_soup(file_path)\n",
    "    words_list = []\n",
    "    for word_li in page_soup.select('li'):\n",
    "        word_str = word_li.text.lower()\n",
    "        words_list.append(word_str)\n",
    "    s.store_objects(popular_english_five_letter_words_list=words_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d71f6c15-e4c7-46d3-8ddd-e29644d9d536",
   "metadata": {},
   "source": [
    "\n",
    "if s.pickle_exists('english_letter_frequencies_df'):\n",
    "    letter_proportions_df = s.load_object('english_letter_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get proportions from cryptography web page\n",
    "    %run ../load_magic/dataframes.py\n",
    "\n",
    "    url = 'https://www3.nd.edu/~busiforc/handouts/cryptography/letterfrequencies.html'\n",
    "    dfs_list = get_page_tables(url, verbose=True)\n",
    "    letter_proportions_df = dfs_list[2].copy()\n",
    "    left_columns_list = [0, 1, 2]\n",
    "    left_df = letter_proportions_df[left_columns_list].rename(columns={0: 'letter_char', 1: 'frequency', 2: 'proportion'})\n",
    "    right_columns_list = [3, 4, 5]\n",
    "    right_df = letter_proportions_df[right_columns_list].rename(columns={3: 'letter_char', 4: 'frequency', 5: 'proportion'})\n",
    "    letter_proportions_df = pd.concat([left_df, right_df])\n",
    "    letter_proportions_df.letter_char = letter_proportions_df.letter_char.map(lambda x: x.lower())\n",
    "    def f(proportion):\n",
    "        if proportion == '(1)':\n",
    "            proportion = 1.0\n",
    "        else:\n",
    "            proportion = float(proportion)\n",
    "\n",
    "        return proportion\n",
    "    letter_proportions_df.proportion = letter_proportions_df.proportion.map(f)\n",
    "    s.store_objects(english_letter_frequencies_df=letter_proportions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff26a0-9736-401c-b115-e1aab7f4723e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
