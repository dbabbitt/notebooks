{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48315979-642e-442e-a129-ddbcf65630b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%run ../load_magic/storage.py\n",
    "%run ../load_magic/lists.py\n",
    "import collections\n",
    "\n",
    "s = Storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cdc476b-b971-4f98-871d-a8636f155971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_proportion_score(word_str, letter_proportions_df):\n",
    "    word_score = 0\n",
    "    for row_index, row_series in letter_proportions_df.iterrows():\n",
    "        letter = row_series.letter_char\n",
    "        if letter in word_str:\n",
    "            proportion = row_series.proportion\n",
    "            word_score += proportion\n",
    "    \n",
    "    return word_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85489573-1d6f-41df-baf3-57a12c61ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_best_word(candidates_list):\n",
    "    \n",
    "    # Get proportions from candidate list\n",
    "    import collections\n",
    "\n",
    "    letters_list = []\n",
    "    for word_str in candidates_list:\n",
    "        letters_list += list(word_str)\n",
    "    counter = collections.Counter(letters_list)\n",
    "    letter_proportions_df = pd.DataFrame([{'letter_char': x, 'letter_count': y} for x, y in dict(counter).items()])\n",
    "    min_count = letter_proportions_df.letter_count.min()\n",
    "    letter_proportions_df['proportion'] = letter_proportions_df.letter_count.map(lambda x: x/min_count)\n",
    "    \n",
    "    # Minimize words to pick through after you get the next word colors back\n",
    "    \n",
    "    # Calculate maximum proportionality\n",
    "    max_score = 0\n",
    "    max_word = ''\n",
    "    for word_str in candidates_list:\n",
    "        word_score = get_proportion_score(word_str, letter_proportions_df)\n",
    "        if word_score > max_score:\n",
    "            max_score = word_score\n",
    "            max_word = word_str\n",
    "    \n",
    "    return max_word, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f844bd1e-e02c-443d-9e1f-0cb5d2c3ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def measure_word(test_word, target_word):\n",
    "    colors_list = []\n",
    "    for i in range(5):\n",
    "        if test_word[i] == target_word[i]:\n",
    "            colors_list.append('G')\n",
    "        elif test_word[i] in target_word:\n",
    "            colors_list.append('Y')\n",
    "        else:\n",
    "            colors_list.append('x')\n",
    "    \n",
    "    return ''.join(colors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f48193-ced2-404a-953f-10550a2e572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_word_guess(response_patterns_df, candidates_list, guesses_list=[]):\n",
    "    if len(candidates_list) == 1:\n",
    "        \n",
    "        return candidates_list[0]\n",
    "    mask_series = response_patterns_df.target_word.isin(candidates_list) & ~response_patterns_df.test_word.isin(guesses_list)\n",
    "    columns_list = ['test_word', 'response_pattern']\n",
    "    guess_df = response_patterns_df[mask_series].groupby(columns_list).count()\n",
    "    guess_df = guess_df.reset_index().groupby('test_word').max().sort_values(by='target_word').head(20)\n",
    "\n",
    "    # Get proportions from candidate list\n",
    "    if guess_df.shape[0] > 1:\n",
    "        letters_list = []\n",
    "        for word_str in guess_df.index:\n",
    "            letters_list += list(word_str)\n",
    "        counter = collections.Counter(letters_list)\n",
    "        letter_proportions_df = pd.DataFrame([{'letter_char': x, 'letter_count': y} for x, y in dict(counter).items()])\n",
    "        min_count = letter_proportions_df.letter_count.min()\n",
    "        letter_proportions_df['proportion'] = letter_proportions_df.letter_count.map(lambda x: x/min_count)\n",
    "\n",
    "        guess_df['word_score'] = guess_df.index.map(lambda x: get_proportion_score(x, letter_proportions_df))\n",
    "        max_word_score = guess_df.word_score.max()\n",
    "        mask_series = (guess_df.word_score == max_word_score)\n",
    "        guess_df = guess_df[mask_series]\n",
    "    \n",
    "    guesses_list = guess_df.sort_values(by='target_word', ascending=False).index.tolist()\n",
    "    guess = None\n",
    "    if guesses_list:\n",
    "        guess = guesses_list[0]\n",
    "    \n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b27f3a9e-7fdb-4eae-93c7-2127f71ad20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_greens_set(test_words_list, response_patterns_list):\n",
    "    greens_set = set()\n",
    "    for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "        for i in range(5):\n",
    "            if response_pattern[i] == 'G':\n",
    "                greens_set.add(test_word[i])\n",
    "    \n",
    "    return greens_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a815af57-72e5-470e-be15-be741dab74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_yellows_set(test_words_list, response_patterns_list):\n",
    "    yellows_set = set()\n",
    "    for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "        for i in range(5):\n",
    "            if response_pattern[i] == 'Y':\n",
    "                yellows_set.add(test_word[i])\n",
    "    \n",
    "    return yellows_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2f2466f-19dd-4c24-9279-60ddef9c020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_greys_list(test_words_list, response_patterns_list):\n",
    "    greens_set = get_greens_set(test_words_list, response_patterns_list)    \n",
    "    yellows_set = get_yellows_set(test_words_list, response_patterns_list)\n",
    "    greys_set = set()\n",
    "    for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "        for i in range(5):\n",
    "            if (response_pattern[i] == 'x') and (test_word[i] not in greens_set) and (test_word[i] not in yellows_set):\n",
    "                greys_set.add(test_word[i])\n",
    "    greys_list = sorted(greys_set)\n",
    "    \n",
    "    return greys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f1a2af-b009-49f0-a50b-de4e645984a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_yellows_list(test_words_list, response_patterns_list):\n",
    "    yellows_set = set()\n",
    "    for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "        for i in range(5):\n",
    "            if (response_pattern[i] == 'Y'):\n",
    "                yellows_set.add(test_word[i])\n",
    "    yellows_list = sorted(yellows_set)\n",
    "    \n",
    "    return yellows_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e662063-9063-4624-93c1-e58982b16d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_greened(word_str, test_words_list, response_patterns_list):\n",
    "    transposed_tests_list = list(map(list, zip(*test_words_list)))\n",
    "    transposed_responses_list = list(map(list, zip(*response_patterns_list)))\n",
    "    is_greened = True\n",
    "    for i in range(5):\n",
    "        test_chars_list = transposed_tests_list[i]\n",
    "        response_chars_list = transposed_responses_list[i]\n",
    "        if 'G' in response_chars_list:\n",
    "            idx = response_chars_list.index('G')\n",
    "            is_greened = is_greened and (word_str[i] == test_chars_list[idx])\n",
    "        else:\n",
    "            is_greened = is_greened and (word_str[i] not in test_chars_list)\n",
    "    \n",
    "    return is_greened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54bd2475-7f5e-408f-9ed0-5c08bd39286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_candidates_list(test_words_list, response_patterns_list, previous_candidates_list=[]):\n",
    "    mask_series = False\n",
    "    for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "        mask_series = mask_series | ((response_patterns_df.test_word == test_word) & (response_patterns_df.response_pattern == response_pattern))\n",
    "    candidates_df = response_patterns_df[mask_series].groupby('target_word').count()\n",
    "    mask_series = (candidates_df.response_pattern == len(response_patterns_list))\n",
    "    candidates_list = sorted(set(candidates_df[mask_series].index.tolist()))\n",
    "    if previous_candidates_list and not candidates_list:\n",
    "        greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "        yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "        for word_str in previous_candidates_list:\n",
    "            if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                    if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                        candidates_list.append(word_str)\n",
    "    \n",
    "    return candidates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4d82462-72fc-459d-a936-fedbe029ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get words list\n",
    "if s.pickle_exists('wordle_words_list'):\n",
    "    words_list = s.load_object('wordle_words_list')\n",
    "else:\n",
    "    \n",
    "    # Get words from the Wordle JavaScript\n",
    "    import re\n",
    "\n",
    "    words_list = []\n",
    "    az_regex = re.compile('[^a-z]')\n",
    "    file_path = r'D:\\Documents\\GitHub\\notebooks\\data\\txt\\wordle_words_short_list.txt'\n",
    "    with open(file_path, encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            word_str = line.strip()\n",
    "            if (len(word_str) == 5) and not az_regex.search(word_str):\n",
    "                words_list.append(word_str)\n",
    "    file_path = r'D:\\Documents\\GitHub\\notebooks\\data\\txt\\wordle_words_long_list.txt'\n",
    "    with open(file_path, encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            word_str = line.strip()\n",
    "            if (len(word_str) == 5) and not az_regex.search(word_str):\n",
    "                words_list.append(word_str)\n",
    "    words_list = list(set(words_list))\n",
    "    # import requests\n",
    "    \n",
    "    # link = 'https://www.powerlanguage.co.uk/wordle/main.814b2d17.js'\n",
    "    # f = requests.get(link)\n",
    "    # commands_list = f.text.split(';')\n",
    "    # list_str = commands_list[331].split(']')[0].split('[')[1]\n",
    "    # words_list = eval(f'[{list_str}]')\n",
    "    s.store_objects(wordle_words_list=words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c082bb9f-2429-4923-8664-18d19345a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the response patterns\n",
    "if s.pickle_exists('wordle_response_patterns_df'):\n",
    "    response_patterns_df = s.load_object('wordle_response_patterns_df')\n",
    "else:\n",
    "    # rows_list = []\n",
    "    # for test_word in words_list:\n",
    "    #     for target_word in words_list:\n",
    "    #         row_dict = {}\n",
    "    #         row_dict['test_word'] = test_word\n",
    "    #         row_dict['target_word'] = target_word\n",
    "    #         row_dict['response_pattern'] = measure_word(test_word, target_word)\n",
    "    #         rows_list.append(row_dict)\n",
    "    # response_patterns_df = pd.DataFrame(rows_list)\n",
    "    response_patterns_df = s.load_csv('response_patterns_df', folder_path=s.saves_folder)\n",
    "    s.store_objects(wordle_response_patterns_df=response_patterns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b52ff2-71c8-4a47-93e7-4e0846491d47",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Use the Dataset of All Responses to Solve a Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7e479dea-9abb-42ee-9159-d81acd48b075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: 12,972\n",
      "FIRST MOVE: reals\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_first_guess = get_word_guess(response_patterns_df, words_list)\n",
    "print(f'list of possible solutions: {len(words_list):,}')\n",
    "print(f'FIRST MOVE: {tree_first_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4b0bd2ed-074e-4f14-9a34-aaba95aea7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions (126): abaca, abaci, aback, abaft, abaka, abamp, aband, abaya, adapt, again, agama, agami, amain, amaut, anana, anata, apaid, apayd, ataxy, avant, await, awato, ayaya, bhaji, bhang, biach, bwana, bwazi, chack, chaco, chado, chaff, chaft, chain, champ, chana, chang, chank, chant, chapt, chawk, chaya, coach, coact, coady, coapt, coati, cyano, dhaba, diact, diazo, dwang, dwaum, foamy, ghaut, ghazi, giant, gnawn, goaty, guaco, guana, guano, guava, hiant, hoagy, idant, igapo, imago, imaum, inapt, jnana, kaama, khadi, khaki, khaph, khaya, khazi, kiaat, kiack, kiang, knack, kyack, kyang, miaou, miaow, ngaio, ngana, ngati, nyaff, obang, okapi, otaku, phang, piani, piano, poach, poaka, pzazz, quack, quaff, quaky, quant, quayd, taata, thack, thagi, thaim, thana, thang, thank, thanx, thawy, toady, tuath, twain, twang, twank, umami, unapt, viand, whack, whamo, whang, whata, whaup, and xoana\n",
      "SECOND MOVE: nicht\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_first_guess = 'reals'\n",
    "tree_first_response_pattern = 'xxGxx'\n",
    "tree_first_candidates_list = get_candidates_list([tree_first_guess], [tree_first_response_pattern])\n",
    "print(f'list of possible solutions ({len(tree_first_candidates_list):,}): {conjunctify_list(tree_first_candidates_list)}')\n",
    "tree_second_guess = get_word_guess(response_patterns_df, tree_first_candidates_list, guesses_list=[tree_first_guess])\n",
    "print(f'SECOND MOVE: {tree_second_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bd1a87a9-77b8-4250-b604-3a7e077f224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions (10): chack, chaco, chado, chaff, champ, chawk, chaya, coach, poach, and whack\n",
      "THIRD MOVE: conky\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tree_second_guess = 'nicht'\n",
    "tree_second_response_pattern = 'xxYYx'\n",
    "test_words_list = [tree_first_guess, tree_second_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern]\n",
    "tree_second_candidates_list = get_candidates_list(test_words_list, response_patterns_list, tree_first_candidates_list)\n",
    "print(f'list of possible solutions ({len(tree_second_candidates_list):,}): {conjunctify_list(tree_second_candidates_list)}')\n",
    "tree_third_guess = get_word_guess(response_patterns_df, tree_second_candidates_list, guesses_list=test_words_list)\n",
    "print(f'THIRD MOVE: {tree_third_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b3daf242-daf0-468d-88c1-4888b1cf4577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions (1): whack\n",
      "FOURTH MOVE: whack\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tree_third_guess = 'conky'\n",
    "tree_third_response_pattern = 'YxxYx'\n",
    "test_words_list = [tree_first_guess, tree_second_guess, tree_third_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern, tree_third_response_pattern]\n",
    "tree_third_candidates_list = get_candidates_list(test_words_list, response_patterns_list, tree_second_candidates_list)\n",
    "print(f'list of possible solutions ({len(tree_third_candidates_list):,}): {conjunctify_list(tree_third_candidates_list)}')\n",
    "tree_fourth_guess = get_word_guess(response_patterns_df, tree_third_candidates_list, guesses_list=test_words_list)\n",
    "print(f'FOURTH MOVE: {tree_fourth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "88e7fbfd-9dad-4492-9aa9-8ba15d4200b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions (1): whack\n",
      "FIFTH MOVE: whack\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tree_fourth_guess = 'whack'\n",
    "tree_fourth_response_pattern = 'GGGGG'\n",
    "test_words_list = [tree_first_guess, tree_second_guess, tree_third_guess, tree_fourth_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern, tree_third_response_pattern, tree_fourth_response_pattern]\n",
    "tree_fourth_candidates_list = get_candidates_list(test_words_list, response_patterns_list, tree_third_candidates_list)\n",
    "print(f'list of possible solutions ({len(tree_fourth_candidates_list):,}): {conjunctify_list(tree_fourth_candidates_list)}')\n",
    "tree_fifth_guess = get_word_guess(response_patterns_df, tree_fourth_candidates_list, guesses_list=test_words_list)\n",
    "print(f'FIFTH MOVE: {tree_fifth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ccbf45d4-466a-4585-83f9-e46ecde3204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (1): whack\n",
      "SIXTH MOVE: whack\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_fifth_response_pattern = 'GGGGG'\n",
    "test_words_list = [tree_first_guess, tree_second_guess, tree_third_guess, tree_fourth_guess, tree_fifth_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern, tree_third_response_pattern, tree_fourth_response_pattern,\n",
    "                          tree_fifth_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "tree_fifth_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                tree_fifth_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(tree_fifth_candidates_list)}): {conjunctify_list(sorted(tree_fifth_candidates_list))}')\n",
    "tree_sixth_guess, max_score = get_best_word(tree_fifth_candidates_list)\n",
    "print(f'SIXTH MOVE: {tree_sixth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "23fac885-0ee7-4d19-ab28-6e851093348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree_sixth_response_pattern = 'GGGGG'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c8740-402f-408f-a87e-49bed619a97a",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Maximize Green Responses to Solve a Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1ff01416-897e-417b-aced-6c9a7234aace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (12,972)\n",
      "FIRST MOVE: arose\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_first_guess, max_score = get_best_word(words_list)\n",
    "print(f'list of possible solutions: ({len(words_list):,})')\n",
    "print(f'FIRST MOVE: {leaf_first_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c5a17dc9-be97-4806-a41f-a64ca308b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (801): babka, babul, bacca, baccy, bacha, baddy, badly, baffy, baggy, bahut, baith, baiza, bajan, baldy, balky, bally, balmy, balti, balun, bambi, banak, banal, banda, bandh, bandy, bania, bantu, banty, banya, batch, batik, batta, battu, batty, baulk, bavin, bawdy, bawty, bhaji, bhang, bhuna, biach, biali, bialy, bigha, bimah, binal, bivia, black, blady, blaff, blain, bland, blank, blatt, blaud, blawn, bubal, bubba, buffa, bulla, bunia, bunya, bwana, bwazi, bylaw, byway, cabal, cabby, cabin, cacky, cacti, caddy, cadgy, cajun, calid, calif, calix, calla, calmy, calpa, calyx, caman, campi, campy, canal, candy, canid, canna, canny, canty, capiz, capul, caput, catch, catty, cauda, cauld, caulk, cavil, chack, chaff, chaft, chain, chalk, champ, chana, chang, chank, chant, chapt, chawk, chaya, chica, china, chufa, cilia, cital, clach, clack, claim, clamp, clang, clank, clapt, claut, clavi, cnida, culpa, cuppa, cycad, dabba, dacha, dadah, daddy, daffy, dagga, daggy, daily, daint, dally, daman, dampy, dancy, dandy, danny, datal, datum, dauby, dault, daunt, davit, dawah, dayan, daych, daynt, dhaba, diact, dicta, dinna, dital, divan, divna, diwan, ducal, ducat, dukka, dulia, dumka, dunam, dwaal, dwalm, dwang, dwaum, fabby, facia, facta, faddy, faffy, faggy, fagin, faint, faith, falaj, fanal, fancy, fanga, fanny, fanum, fatal, fatly, fatty, fatwa, faugh, fauld, fault, fauna, fawny, final, finca, fitna, flack, flaff, flail, flaky, flamm, flamy, flank, flava, flawn, flawy, flaxy, fugal, gabba, gabby, gaddi, gadid, gaily, gaita, gaitt, galah, galax, gally, galut, gamay, gamba, gamic, gamin, gamma, gammy, gamut, ganch, gandy, ganja, gappy, gatch, gauch, gaucy, gaudy, gault, gaumy, gaunt, gauzy, gawcy, gawky, gayal, gayly, gazal, ghaut, ghazi, giant, glady, glaik, gland, glaum, glazy, glial, gnawn, guana, guava, gulag, gumma, gutta, habit, hadal, hadji, hafiz, haick, haika, haiku, haily, haint, haith, hajji, hakam, hakim, halal, halfa, halid, halma, halva, halwa, hamal, hamba, hammy, hamza, hanap, hanch, handy, hangi, hanky, hapax, haply, happi, happy, hatch, hatha, haugh, hauld, haulm, hault, haunt, hazan, hiant, hijab, hinau, hudna, human, hutia, huzza, hypha, iambi, ictal, idant, iliac, iliad, ilial, imaum, inapt, india, ingan, inlay, inula, ixnay, izzat, jacal, jacky, jaffa, jaggy, jalap, jambu, jammy, janny, janty, japan, jaunt, jawan, jazzy, jhala, jibba, jihad, jnana, jugal, junta, kaama, kabab, kacha, kadai, kahal, kaiak, kaika, kaing, kalam, kalif, kalpa, kamik, kandy, kanga, kanji, kanzu, kappa, kaput, katal, katti, kaugh, kaval, kawau, kayak, khadi, khaki, khaph, khaya, khazi, kiaat, kiack, kiang, kibla, kinda, kippa, klang, knack, kulak, kulan, kyack, kyang, labda, labia, laddy, lagan, lahal, laich, laigh, laika, laith, laity, lakin, laldy, lamby, lamia, lammy, lanai, lanch, lanky, lapin, latah, latch, lathi, lathy, lauan, lauch, laugh, laund, laval, lavvy, lawin, lawny, laxly, layin, layup, lazzi, liana, liang, ligan, lilac, liman, limax, limba, limma, limpa, linac, linga, litai, llama, luach, luffa, lytta, macaw, machi, madam, madid, madly, mafia, mafic, magic, magma, mahua, mahwa, maill, malam, malax, malic, malik, malmy, malty, malva, malwa, mamba, mamma, mammy, manat, mandi, manga, mangy, mania, manic, manky, manly, manna, manta, manty, manul, mapau, maqui, matai, match, matin, matza, mauby, maund, mauzy, mavin, mawky, maxim, mayan, mazut, miaul, mikva, milia, milpa, mugga, mulga, mulla, munga, mutha, muzak, myall, mynah, nabla, naggy, nahal, naiad, nakfa, nalla, namma, nancy, nandu, nanna, nanny, nanua, nappa, nappy, natal, natch, natty, nauch, naunt, naval, navvy, nawab, nduja, ngana, ngati, nicad, nidal, nikab, nikah, nikau, ninja, niqab, nival, nizam, nubia, nucha, nulla, nyaff, nyala, pacha, pacta, paddy, padma, pagan, paint, pakka, palay, palki, palla, pally, palmy, palpi, pampa, panax, panda, pandy, panga, panic, panim, panni, panty, papal, papaw, pappi, pappy, patch, patin, patka, patly, patty, pavan, pavid, pavin, pawaw, pawky, phang, phial, phyla, piani, pibal, pical, pikau, pilaf, pilau, pilaw, pinna, pinta, pipal, pitta, pizza, plack, plaid, plain, plait, plank, plant, platt, platy, playa, plaza, plica, pucan, pucka, puffa, pujah, pukka, pulka, punga, punka, pupal, pygal, pzazz, qajaq, qanat, qapik, qibla, quack, quaff, quail, quaky, qualm, quant, quayd, quina, taata, tabby, tabid, tabla, tabun, tacan, tacit, tacky, taffy, tafia, taggy, tagma, taiga, taint, takhi, takin, takky, talak, talaq, talcy, talky, tally, talma, talpa, taluk, tamal, tamin, tammy, tanga, tangi, tangy, tanka, tanky, tanna, tanti, tanty, tappa, tatty, tauld, taunt, tavah, tawai, tawny, tazza, thack, thagi, thaim, thali, thana, thang, thank, thanx, thawy, thuja, thuya, tibia, tical, ticca, tidal, tikka, tilak, titan, tuath, tubal, tuina, tulpa, twain, twang, twank, typal, ugali, uhlan, ulama, ulnad, ulpan, umami, umiac, umiak, umiaq, ummah, unapt, unbag, unban, uncap, uncia, undam, ungag, unhat, unica, unjam, unlaw, unlay, unman, unpay, untax, uplay, uptak, uvula, vacua, vagal, vakil, valid, vampy, vanda, vapid, vatic, vauch, vault, vaunt, viand, vifda, vigia, villa, vinal, vinca, vital, vitta, vivat, vivda, vulva, wacky, waddy, wagga, wagyu, waift, walla, wally, walty, waltz, wanky, wanly, wanna, wanty, watap, watch, wauff, waugh, waulk, whack, whang, whata, whaup, whyda, wicca, wigan, wigga, wilga, wilja, winna, witan, wuxia, xylan, yabba, yabby, yacca, yacht, yacka, yakka, yampy, yamun, yappy, yauld, yawny, yclad, yucca, yulan, zaida, zaidy, zakat, zaman, zamia, zanja, zanza, zappy, zayin, zigan, zilla, zupan, zuppa, and zygal\n",
      "SECOND MOVE: layin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_first_guess = 'arose'\n",
    "leaf_first_response_pattern = 'Yxxxx'\n",
    "test_words_list = [leaf_first_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_first_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_first_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_first_candidates_list)}): {conjunctify_list(sorted(leaf_first_candidates_list))}')\n",
    "leaf_second_guess, max_score = get_best_word(leaf_first_candidates_list)\n",
    "print(f'SECOND MOVE: {leaf_second_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6198f8e9-ec46-46d7-8777-f91b3f352bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (40): bubba, buffa, chack, chaff, chaft, champ, chapt, chawk, chufa, cuppa, dhaba, ducat, dukka, dumka, dwaum, ghaut, guava, gumma, gutta, huzza, khaph, mugga, mutha, muzak, pucka, puffa, pujah, pukka, pzazz, quack, quaff, thack, thuja, tuath, ummah, uptak, whack, whata, whaup, and zuppa\n",
      "THIRD MOVE: chufa\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# leaf_second_guess = 'layin'\n",
    "leaf_second_response_pattern = 'xYxxx'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_second_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_second_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_second_candidates_list)}): {conjunctify_list(sorted(leaf_second_candidates_list))}')\n",
    "leaf_third_guess, max_score = get_best_word(leaf_second_candidates_list)\n",
    "print(f'THIRD MOVE: {leaf_third_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "19ac7319-fcd3-4916-b2ef-ec89102ba2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (2): thack and whack\n",
      "FOURTH MOVE: whack\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# leaf_third_guess = 'chufa'\n",
    "leaf_third_response_pattern = 'YGxxY'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess, leaf_third_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern, leaf_third_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_third_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_third_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_third_candidates_list)}): {conjunctify_list(sorted(leaf_third_candidates_list))}')\n",
    "leaf_fourth_guess, max_score = get_best_word(leaf_third_candidates_list)\n",
    "print(f'FOURTH MOVE: {leaf_fourth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6b71a8e7-6251-4bfa-9f9b-f7f38a852097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (1): whack\n",
      "FIFTH MOVE: whack\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# leaf_fourth_guess = 'whack'\n",
    "leaf_fourth_response_pattern = 'GGGGG'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess, leaf_third_guess, leaf_fourth_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern, leaf_third_response_pattern, leaf_fourth_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_fourth_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_fourth_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_fourth_candidates_list)}): {conjunctify_list(sorted(leaf_fourth_candidates_list))}')\n",
    "leaf_fifth_guess, max_score = get_best_word(leaf_fourth_candidates_list)\n",
    "print(f'FIFTH MOVE: {leaf_fifth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2cefa007-ac62-45bf-a659-7c2de9f3d1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (1): whack\n",
      "SIXTH MOVE: whack\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# leaf_fifth_guess = 'whack'\n",
    "leaf_fifth_response_pattern = 'GGGGG'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess, leaf_third_guess, leaf_fourth_guess, leaf_fifth_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern, leaf_third_response_pattern, leaf_fourth_response_pattern,\n",
    "                          leaf_fifth_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_fifth_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_fifth_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_fifth_candidates_list)}): {conjunctify_list(sorted(leaf_fifth_candidates_list))}')\n",
    "leaf_sixth_guess, max_score = get_best_word(leaf_fifth_candidates_list)\n",
    "print(f'SIXTH MOVE: {leaf_sixth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8745e77b-818c-4b1d-87bc-c7bab78d57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "leaf_sixth_response_pattern = 'GGGGG'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8fd7d3-7d89-42c6-a7ec-4797fcfca6d5",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Display the Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a716ee7d-8c1f-4c80-8402-650bf8f508a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def patternize_guess(word_str, pattern_str):\n",
    "    pre_str = '<span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:'\n",
    "    in_str = ';\">'\n",
    "    post_str = '</span>'\n",
    "    patternized_str = ''\n",
    "    for letter_str, letter_pattern in zip(word_str, pattern_str):\n",
    "        patternized_str += pre_str\n",
    "        if letter_pattern == 'G':\n",
    "            patternized_str += 'green'\n",
    "        elif letter_pattern == 'Y':\n",
    "            patternized_str += 'yellow'\n",
    "        else:\n",
    "            patternized_str += 'grey'\n",
    "        patternized_str += in_str + letter_str + post_str\n",
    "    \n",
    "    return patternized_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "85f85298-3ce0-44f3-afe0-e0327a2753c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from num2words import num2words\n",
    "\n",
    "def get_tr(ordinal, leaf_count=None, tree_count=None):\n",
    "    ordinal_str = num2words(ordinal, lang='en', to='ordinal')\n",
    "    previous_ordinal_str = num2words(ordinal-1, lang='en', to='ordinal')\n",
    "    if leaf_count is None:\n",
    "        leaf_count = eval(f'len(leaf_{previous_ordinal_str}_candidates_list)')\n",
    "    leaf_guess = eval(f'leaf_{ordinal_str}_guess')\n",
    "    leaf_pattern = eval(f'leaf_{ordinal_str}_response_pattern')\n",
    "    if tree_count is None:\n",
    "        tree_count = eval(f'len(tree_{previous_ordinal_str}_candidates_list)')\n",
    "    tree_guess = eval(f'tree_{ordinal_str}_guess')\n",
    "    tree_pattern = eval(f'tree_{ordinal_str}_response_pattern')\n",
    "    html_str = f'''<tr>\n",
    "        <td>{ordinal_str.title()}</td>\n",
    "        <td>{leaf_count:,}</td>\n",
    "        <td>{patternize_guess(leaf_guess, leaf_pattern)}</td>\n",
    "        <td>{tree_count:,}</td>\n",
    "        <td>{patternize_guess(tree_guess, tree_pattern)}</td>\n",
    "    </tr>'''\n",
    "    \n",
    "    return html_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "89bf24c8-c4e8-456c-bc0e-91c7c4ebefef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th rowspan=\"2\">Move</th>\n",
       "        <th colspan=\"2\" style=\"text-align:center\">Green Maximizer</th>\n",
       "        <th colspan=\"2\" style=\"text-align:center\">Branch Minimizer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th style=\"text-align:center\">Solutions</th>\n",
       "        <th style=\"text-align:center\">Guess</th>\n",
       "        <th style=\"text-align:center\">Solutions</th>\n",
       "        <th style=\"text-align:center\">Guess</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>First</td>\n",
       "        <td>12,972</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">r</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">o</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">s</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">e</span></td>\n",
       "        <td>12,972</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">r</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">e</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">l</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">s</span></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Second</td>\n",
       "        <td>801</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">l</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">y</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">i</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">n</span></td>\n",
       "        <td>126</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">n</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">i</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">t</span></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Third</td>\n",
       "        <td>40</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">u</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">f</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">a</span></td>\n",
       "        <td>10</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">o</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">n</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">k</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">y</span></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Fourth</td>\n",
       "        <td>2</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "        <td>1</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Fifth</td>\n",
       "        <td>1</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "        <td>1</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Sixth</td>\n",
       "        <td>1</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "        <td>1</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "HTML(f'''<table>\n",
    "    <tr>\n",
    "        <th rowspan=\"2\">Move</th>\n",
    "        <th colspan=\"2\" style=\"text-align:center\">Green Maximizer</th>\n",
    "        <th colspan=\"2\" style=\"text-align:center\">Branch Minimizer</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align:center\">Solutions</th>\n",
    "        <th style=\"text-align:center\">Guess</th>\n",
    "        <th style=\"text-align:center\">Solutions</th>\n",
    "        <th style=\"text-align:center\">Guess</th>\n",
    "    </tr>\n",
    "    {get_tr(1, leaf_count=len(words_list), tree_count=len(words_list))}\n",
    "    {get_tr(2)}\n",
    "    {get_tr(3)}\n",
    "    {get_tr(4)}\n",
    "    {get_tr(5)}\n",
    "    {get_tr(6)}\n",
    "</table>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15656dd0-971c-4645-91f1-235c41c07088",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3624b53e-e885-4560-9e41-c0950d78be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_patterns_set = set(['xGxxx', 'xGxYx', 'xYYYY'])\n",
    "# mask_series = False\n",
    "# for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "#     mask_series = mask_series | ((response_patterns_df.test_word == test_word) & (response_patterns_df.response_pattern == response_pattern))\n",
    "mask_series = response_patterns_df.response_pattern.isin(response_patterns_set)\n",
    "counts_df = response_patterns_df[mask_series].groupby('target_word').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec467754-bbb7-45c3-8d06-681538b3cbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_word</th>\n",
       "      <th>response_pattern</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jaffa</th>\n",
       "      <td>1862</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qajaq</th>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mamma</th>\n",
       "      <td>1751</td>\n",
       "      <td>1751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baboo</th>\n",
       "      <td>1676</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kazoo</th>\n",
       "      <td>1667</td>\n",
       "      <td>1667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_word  response_pattern\n",
       "target_word                             \n",
       "jaffa             1862              1862\n",
       "qajaq             1816              1816\n",
       "mamma             1751              1751\n",
       "baboo             1676              1676\n",
       "kazoo             1667              1667"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "counts_df.sort_values('response_pattern', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359ebd7-eccc-4877-b485-0c8278414088",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if s.pickle_exists('english_letter_frequencies_df'):\n",
    "    letter_proportions_df = s.load_object('english_letter_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get proportions from word list\n",
    "    import collections\n",
    "\n",
    "    letters_list = []\n",
    "    for word_str in words_list:\n",
    "        letters_list += list(word_str)\n",
    "    counter = collections.Counter(letters_list)\n",
    "    letter_proportions_df = pd.DataFrame([{'letter_char': x, 'letter_count': y} for x, y in dict(counter).items()])\n",
    "    min_count = letter_proportions_df.letter_count.min()\n",
    "    letter_proportions_df['proportion'] = letter_proportions_df.letter_count.map(lambda x: x/min_count)\n",
    "    s.store_objects(english_letter_frequencies_df=letter_proportions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7998f7b-c11b-4fb6-b377-0714029ee27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "random.sample(words_list, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2e582-41a4-4883-816a-e3c4f9e32b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "letter_proportions_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60784307-9098-462e-9b60-8ebb82a74570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (letter_proportions_df.letter_char == 'e')\n",
    "letter_proportions_df[mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadc25d-db2c-40b6-80a9-85b46285a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "letter_proportions_df.sort_values('proportion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63baa5d4-f095-4634-b382-7258a0c60cf4",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8075915-b84c-44a1-8c90-1b2cb7c428b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern_groupby = response_patterns_df.groupby('response_pattern').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f1f5e-e291-497a-9fbd-a791017b579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern_groupby.sort_values('test_word', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df0c52f-37b7-4748-bbcc-0598b4e5a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = response_patterns_df.target_word.isin(candidates_list)\n",
    "pattern_groupby = response_patterns_df[mask_series].groupby('response_pattern').count().sort_values('test_word', ascending=False)\n",
    "pattern_groupby.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c92bd-88dd-41a7-be00-cf40facbdf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern_groupby.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341a1dd-5470-4010-8954-93112948b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = response_patterns_df.target_word.isin(candidates_list) & (response_patterns_df.response_pattern.isin(['GGYGY', 'GYGGY', 'GYxGG']))\n",
    "response_patterns_df[mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d2c1a-4069-405e-be63-99af23ddf162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = response_patterns_df.test_word.isin(['arise'])\n",
    "pattern_groupby = response_patterns_df[mask_series].groupby('response_pattern').count().sort_values('test_word', ascending=False)\n",
    "pattern_groupby.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53616476-00d4-4882-b418-d663e1f78d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_list = ['arise']\n",
    "pattern_groupby.loc[test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab0fa28-c499-487b-96a4-452050d82011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get words from GloVe: Global Vectors for Word Representation\n",
    "import re\n",
    "\n",
    "words_list = []\n",
    "file_path = r'D:\\Documents\\GitHub\\job-hunting\\data\\6B\\glove.6B.300d.txt'\n",
    "az_regex = re.compile('[^a-z]')\n",
    "with open(file_path, encoding='utf8') as infile:\n",
    "    for line in infile:\n",
    "        word_str = line.split()[0]\n",
    "        if (len(word_str) == 5) and not az_regex.search(word_str):\n",
    "            words_list.append(word_str)\n",
    "words_list.remove('aerio')\n",
    "words_list.remove('ioane')\n",
    "words_list.remove('eonia')\n",
    "words_list.remove('tabou')\n",
    "words_list.remove('tamou')\n",
    "words_list.remove('tarom')\n",
    "words_list.remove('tarmo')\n",
    "words_list.remove('marot')\n",
    "words_list.remove('marto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8dfa2b-5342-4ba3-a02c-a6c05f371a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_lists(candidate_word, colors_list, greys_list=None, yellows_list=None, greens_list=None):\n",
    "    if greys_list is None: greys_list = []\n",
    "    if yellows_list is None: yellows_list = []\n",
    "    if greens_list is None: greens_list = []\n",
    "    for color, index in zip(range(len(candidate_word)), colors_list):\n",
    "        if color == 'grey':\n",
    "            greys_list.append(candidate_word[index])\n",
    "        elif color == 'yellow':\n",
    "            yellows_list.append(candidate_word[index])\n",
    "        elif color == 'green':\n",
    "            greens_list.append(f\"(candidate_word[{index}] == '{candidate_word[index]}')\")\n",
    "    \n",
    "    return greys_list, yellows_list, greens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd75bab-b1a4-452d-8c8a-5b493daeea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_largest_equivalence_class(candidates_list, base_greys_list=None, base_yellows_list=None, base_greens_list=None):\n",
    "    if base_greys_list is None: base_greys_list = []\n",
    "    if base_yellows_list is None: base_yellows_list = []\n",
    "    if base_greens_list is None: base_greens_list = []\n",
    "    max_possibles_list = []\n",
    "    max_candidate_word = ''\n",
    "    for candidate_word in candidates_list:\n",
    "        possibles_list = []\n",
    "        for color1 in ['grey', 'yellow', 'green']:\n",
    "            for color2 in ['grey', 'yellow', 'green']:\n",
    "                for color3 in ['grey', 'yellow', 'green']:\n",
    "                    for color4 in ['grey', 'yellow', 'green']:\n",
    "                        for color5 in ['grey', 'yellow', 'green']:\n",
    "                            colors_list = [color1, color2, color3, color4, color5]\n",
    "                            greys_list, yellows_list, greens_list = build_lists(candidate_word, colors_list,\n",
    "                                                                                base_greys_list, base_yellows_list, base_greens_list)\n",
    "                            if all(map(lambda x: eval(x), greens_list)):\n",
    "                                if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                                    if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                                        possibles_list.append(candidate_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f74fde-8cb4-416f-b0b7-c1eadda5c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for word_str in candidates_list:\n",
    "    greys_list = ['a', 'i', 's']\n",
    "    yellows_list = ['r']\n",
    "    greens_list = [\"(candidate_word[4] == 'e')\"]\n",
    "    max_possibles_list = get_largest_equivalence_class(word_str, base_greys_list=greys_list, base_yellows_list=yellows_list, base_greens_list=greens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53706f0-4bd1-4d27-b4d0-57e5237cb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if s.pickle_exists('english_word_frequencies_df'):\n",
    "    word_proportions_df = s.load_object('english_word_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get words from the Wordle JavaScript\n",
    "    if s.pickle_exists('wordle_words_list'):\n",
    "        words_list = s.load_object('wordle_words_list')\n",
    "    else:\n",
    "\n",
    "        # Get words from the Wordle JavaScript\n",
    "        import requests\n",
    "\n",
    "        link = 'https://www.powerlanguage.co.uk/wordle/main.db1931a8.js'\n",
    "        f = requests.get(link)\n",
    "        commands_list = f.text.split(';')\n",
    "        list_str = commands_list[331].split(']')[0].split('[')[1]\n",
    "        words_list = eval(f'[{list_str}]')\n",
    "        s.store_objects(wordle_words_list=words_list)\n",
    "        \n",
    "    rows_list = [{'word_str': word_str, 'proportion_score': get_proportion_score(word_str)} for word_str in words_list]\n",
    "    word_proportions_df = pd.DataFrame(rows_list)\n",
    "    s.store_objects(english_word_frequencies_df=word_proportions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1a5d9-315a-4136-9fc9-7a7faf92c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_proportions_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b7266-269e-4978-93b4-e6538b27567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proportion_score_dict = word_proportions_df.set_index('word_str').proportion_score.to_dict()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "307a8a6e-86b1-4e11-a1f3-7d4e7aff9ae7",
   "metadata": {},
   "source": [
    "\n",
    "if s.pickle_exists('english_word_frequencies_df'):\n",
    "    word_proportions_df = s.load_object('english_word_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get words from the word list\n",
    "    if s.pickle_exists('glove_english_five_letter_words_list'):\n",
    "        words_list = s.load_object('glove_english_five_letter_words_list')\n",
    "    else:\n",
    "        \n",
    "        # Get words from GloVe: Global Vectors for Word Representation\n",
    "        import re\n",
    "        \n",
    "        words_list = []\n",
    "        file_path = r'D:\\Documents\\GitHub\\job-hunting\\data\\6B\\glove.6B.300d.txt'\n",
    "        az_regex = re.compile('[^a-z]')\n",
    "        with open(file_path, encoding='utf8') as infile:\n",
    "            for line in infile:\n",
    "                word_str = line.split()[0]\n",
    "                if (len(word_str) == 5) and not az_regex.search(word_str):\n",
    "                    words_list.append(word_str)\n",
    "        \n",
    "        words_list.remove('aerio')\n",
    "        words_list.remove('ioane')\n",
    "        words_list.remove('eonia')\n",
    "        words_list.remove('sunol')\n",
    "        words_list.remove('solun')\n",
    "        words_list.remove('skuld')\n",
    "        s.store_objects(glove_english_five_letter_words_list=words_list)\n",
    "    rows_list = [{'word_str': word_str, 'proportion_score': get_proportion_score(word_str)} for word_str in words_list]\n",
    "    word_proportions_df = pd.DataFrame(rows_list)\n",
    "    s.store_objects(english_word_frequencies_df=word_proportions_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b276b57-2ae0-4c93-96bf-bb0a4d1a5aec",
   "metadata": {},
   "source": [
    "\n",
    "if s.pickle_exists('popular_english_five_letter_words_list'):\n",
    "    words_list = s.load_object('popular_english_five_letter_words_list')\n",
    "else:\n",
    "    %run ../load_magic/soup.py\n",
    "\n",
    "    file_path = '../data/html/five_letter_words.html'\n",
    "    page_soup = get_page_soup(file_path)\n",
    "    words_list = []\n",
    "    for word_li in page_soup.select('li'):\n",
    "        word_str = word_li.text.lower()\n",
    "        words_list.append(word_str)\n",
    "    s.store_objects(popular_english_five_letter_words_list=words_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d71f6c15-e4c7-46d3-8ddd-e29644d9d536",
   "metadata": {},
   "source": [
    "\n",
    "if s.pickle_exists('english_letter_frequencies_df'):\n",
    "    letter_proportions_df = s.load_object('english_letter_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get proportions from cryptography web page\n",
    "    %run ../load_magic/dataframes.py\n",
    "\n",
    "    url = 'https://www3.nd.edu/~busiforc/handouts/cryptography/letterfrequencies.html'\n",
    "    dfs_list = get_page_tables(url, verbose=True)\n",
    "    letter_proportions_df = dfs_list[2].copy()\n",
    "    left_columns_list = [0, 1, 2]\n",
    "    left_df = letter_proportions_df[left_columns_list].rename(columns={0: 'letter_char', 1: 'frequency', 2: 'proportion'})\n",
    "    right_columns_list = [3, 4, 5]\n",
    "    right_df = letter_proportions_df[right_columns_list].rename(columns={3: 'letter_char', 4: 'frequency', 5: 'proportion'})\n",
    "    letter_proportions_df = pd.concat([left_df, right_df])\n",
    "    letter_proportions_df.letter_char = letter_proportions_df.letter_char.map(lambda x: x.lower())\n",
    "    def f(proportion):\n",
    "        if proportion == '(1)':\n",
    "            proportion = 1.0\n",
    "        else:\n",
    "            proportion = float(proportion)\n",
    "\n",
    "        return proportion\n",
    "    letter_proportions_df.proportion = letter_proportions_df.proportion.map(f)\n",
    "    s.store_objects(english_letter_frequencies_df=letter_proportions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff26a0-9736-401c-b115-e1aab7f4723e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
