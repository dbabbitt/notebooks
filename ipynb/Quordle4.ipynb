{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48315979-642e-442e-a129-ddbcf65630b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "%run ../load_magic/storage.py\n",
    "%run ../load_magic/lists.py\n",
    "import collections\n",
    "\n",
    "s = Storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cdc476b-b971-4f98-871d-a8636f155971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_proportion_score(word_str, letter_proportions_df):\n",
    "    word_score = 0\n",
    "    for row_index, row_series in letter_proportions_df.iterrows():\n",
    "        letter = row_series.letter_char\n",
    "        if letter in word_str:\n",
    "            proportion = row_series.proportion\n",
    "            word_score += proportion\n",
    "    \n",
    "    return word_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85489573-1d6f-41df-baf3-57a12c61ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_best_word(candidates_list):\n",
    "    \n",
    "    # Get proportions from candidate list\n",
    "    import collections\n",
    "\n",
    "    letters_list = []\n",
    "    for word_str in candidates_list:\n",
    "        letters_list += list(word_str)\n",
    "    counter = collections.Counter(letters_list)\n",
    "    letter_proportions_df = pd.DataFrame([{'letter_char': x, 'letter_count': y} for x, y in dict(counter).items()])\n",
    "    min_count = letter_proportions_df.letter_count.min()\n",
    "    letter_proportions_df['proportion'] = letter_proportions_df.letter_count.map(lambda x: x/min_count)\n",
    "    \n",
    "    # Minimize words to pick through after you get the next word colors back\n",
    "    \n",
    "    # Calculate maximum proportionality\n",
    "    max_score = 0\n",
    "    max_word = ''\n",
    "    for word_str in candidates_list:\n",
    "        word_score = get_proportion_score(word_str, letter_proportions_df)\n",
    "        if word_score > max_score:\n",
    "            max_score = word_score\n",
    "            max_word = word_str\n",
    "    \n",
    "    return max_word, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f844bd1e-e02c-443d-9e1f-0cb5d2c3ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def measure_word(test_word, target_word):\n",
    "    colors_list = []\n",
    "    for i in range(5):\n",
    "        if test_word[i] == target_word[i]:\n",
    "            colors_list.append('G')\n",
    "        elif test_word[i] in target_word:\n",
    "            colors_list.append('Y')\n",
    "        else:\n",
    "            colors_list.append('x')\n",
    "    \n",
    "    return ''.join(colors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f48193-ced2-404a-953f-10550a2e572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_word_guess(response_patterns_df, candidates_list, guesses_list=[]):\n",
    "    if len(candidates_list) == 1:\n",
    "        \n",
    "        return candidates_list[0]\n",
    "    mask_series = response_patterns_df.target_word.isin(candidates_list) & ~response_patterns_df.test_word.isin(guesses_list)\n",
    "    columns_list = ['test_word', 'response_pattern']\n",
    "    guess_df = response_patterns_df[mask_series].groupby(columns_list).count()\n",
    "    guess_df = guess_df.reset_index().groupby('test_word').max().sort_values(by='target_word').head(20)\n",
    "\n",
    "    # Get proportions from candidate list\n",
    "    if guess_df.shape[0] > 1:\n",
    "        letters_list = []\n",
    "        for word_str in guess_df.index:\n",
    "            letters_list += list(word_str)\n",
    "        counter = collections.Counter(letters_list)\n",
    "        letter_proportions_df = pd.DataFrame([{'letter_char': x, 'letter_count': y} for x, y in dict(counter).items()])\n",
    "        min_count = letter_proportions_df.letter_count.min()\n",
    "        letter_proportions_df['proportion'] = letter_proportions_df.letter_count.map(lambda x: x/min_count)\n",
    "\n",
    "        guess_df['word_score'] = guess_df.index.map(lambda x: get_proportion_score(x, letter_proportions_df))\n",
    "        max_word_score = guess_df.word_score.max()\n",
    "        mask_series = (guess_df.word_score == max_word_score)\n",
    "        guess_df = guess_df[mask_series]\n",
    "    \n",
    "    guesses_list = guess_df.sort_values(by='target_word', ascending=False).index.tolist()\n",
    "    guess = None\n",
    "    if guesses_list:\n",
    "        guess = guesses_list[0]\n",
    "    \n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b27f3a9e-7fdb-4eae-93c7-2127f71ad20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_greens_set(test_words_list, response_patterns_list):\n",
    "    greens_set = set()\n",
    "    for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "        for i in range(5):\n",
    "            if response_pattern[i] == 'G':\n",
    "                greens_set.add(test_word[i])\n",
    "    \n",
    "    return greens_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a815af57-72e5-470e-be15-be741dab74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_yellows_set(test_words_list, response_patterns_list):\n",
    "    yellows_set = set()\n",
    "    for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "        for i in range(5):\n",
    "            if response_pattern[i] == 'Y':\n",
    "                yellows_set.add(test_word[i])\n",
    "    \n",
    "    return yellows_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f2466f-19dd-4c24-9279-60ddef9c020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_greys_list(test_words_list, response_patterns_list):\n",
    "    greens_set = get_greens_set(test_words_list, response_patterns_list)    \n",
    "    yellows_set = get_yellows_set(test_words_list, response_patterns_list)\n",
    "    greys_set = set()\n",
    "    for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "        for i in range(5):\n",
    "            if (response_pattern[i] == 'x') and (test_word[i] not in greens_set) and (test_word[i] not in yellows_set):\n",
    "                greys_set.add(test_word[i])\n",
    "    greys_list = sorted(greys_set)\n",
    "    \n",
    "    return greys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f1a2af-b009-49f0-a50b-de4e645984a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_yellows_list(test_words_list, response_patterns_list):\n",
    "    yellows_set = set()\n",
    "    for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "        for i in range(5):\n",
    "            if (response_pattern[i] == 'Y'):\n",
    "                yellows_set.add(test_word[i])\n",
    "    yellows_list = sorted(yellows_set)\n",
    "    \n",
    "    return yellows_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e662063-9063-4624-93c1-e58982b16d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_greened(word_str, test_words_list, response_patterns_list):\n",
    "    transposed_tests_list = list(map(list, zip(*test_words_list)))\n",
    "    transposed_responses_list = list(map(list, zip(*response_patterns_list)))\n",
    "    is_greened = True\n",
    "    for i in range(5):\n",
    "        test_chars_list = transposed_tests_list[i]\n",
    "        response_chars_list = transposed_responses_list[i]\n",
    "        if 'G' in response_chars_list:\n",
    "            idx = response_chars_list.index('G')\n",
    "            is_greened = is_greened and (word_str[i] == test_chars_list[idx])\n",
    "        else:\n",
    "            is_greened = is_greened and (word_str[i] not in test_chars_list)\n",
    "    \n",
    "    return is_greened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54bd2475-7f5e-408f-9ed0-5c08bd39286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_candidates_list(test_words_list, response_patterns_list, previous_candidates_list=[]):\n",
    "    mask_series = False\n",
    "    for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "        mask_series = mask_series | ((response_patterns_df.test_word == test_word) & (response_patterns_df.response_pattern == response_pattern))\n",
    "    candidates_df = response_patterns_df[mask_series].groupby('target_word').count()\n",
    "    mask_series = (candidates_df.response_pattern == len(response_patterns_list))\n",
    "    candidates_list = sorted(set(candidates_df[mask_series].index.tolist()))\n",
    "    if previous_candidates_list and not candidates_list:\n",
    "        greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "        yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "        for word_str in previous_candidates_list:\n",
    "            if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                    if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                        candidates_list.append(word_str)\n",
    "    \n",
    "    return candidates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d82462-72fc-459d-a936-fedbe029ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get words list\n",
    "if s.pickle_exists('wordle_words_list'):\n",
    "    words_list = s.load_object('wordle_words_list')\n",
    "else:\n",
    "    \n",
    "    # Get words from the Wordle JavaScript\n",
    "    import re\n",
    "\n",
    "    words_list = []\n",
    "    az_regex = re.compile('[^a-z]')\n",
    "    file_path = r'D:\\Documents\\GitHub\\notebooks\\data\\txt\\wordle_words_short_list.txt'\n",
    "    with open(file_path, encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            word_str = line.strip()\n",
    "            if (len(word_str) == 5) and not az_regex.search(word_str):\n",
    "                words_list.append(word_str)\n",
    "    file_path = r'D:\\Documents\\GitHub\\notebooks\\data\\txt\\wordle_words_long_list.txt'\n",
    "    with open(file_path, encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            word_str = line.strip()\n",
    "            if (len(word_str) == 5) and not az_regex.search(word_str):\n",
    "                words_list.append(word_str)\n",
    "    words_list = list(set(words_list))\n",
    "    # import requests\n",
    "    \n",
    "    # link = 'https://www.powerlanguage.co.uk/wordle/main.814b2d17.js'\n",
    "    # f = requests.get(link)\n",
    "    # commands_list = f.text.split(';')\n",
    "    # list_str = commands_list[331].split(']')[0].split('[')[1]\n",
    "    # words_list = eval(f'[{list_str}]')\n",
    "    s.store_objects(wordle_words_list=words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c082bb9f-2429-4923-8664-18d19345a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the response patterns\n",
    "if s.pickle_exists('wordle_response_patterns_df'):\n",
    "    response_patterns_df = s.load_object('wordle_response_patterns_df')\n",
    "else:\n",
    "    # rows_list = []\n",
    "    # for test_word in words_list:\n",
    "    #     for target_word in words_list:\n",
    "    #         row_dict = {}\n",
    "    #         row_dict['test_word'] = test_word\n",
    "    #         row_dict['target_word'] = target_word\n",
    "    #         row_dict['response_pattern'] = measure_word(test_word, target_word)\n",
    "    #         rows_list.append(row_dict)\n",
    "    # response_patterns_df = pd.DataFrame(rows_list)\n",
    "    response_patterns_df = s.load_csv('response_patterns_df', folder_path=s.saves_folder)\n",
    "    s.store_objects(wordle_response_patterns_df=response_patterns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b52ff2-71c8-4a47-93e7-4e0846491d47",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Minimize Branches to Solve a Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e479dea-9abb-42ee-9159-d81acd48b075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: 12,972\n",
      "FIRST MOVE: reals\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_first_guess = get_word_guess(response_patterns_df, words_list)\n",
    "print(f'list of possible solutions: {len(words_list):,}')\n",
    "print(f'FIRST MOVE: {tree_first_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b0bd2ed-074e-4f14-9a34-aaba95aea7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n",
      "list of possible solutions (832): bhoot, biccy, biddy, bidon, biffo, biffy, bifid, biggy, bight, bigot, bijou, bimbo, bindi, bingo, bingy, binit, biont, bipod, bitch, bitou, bitty, bivvy, bizzo, bizzy, bobby, bocci, bodhi, boffo, boggy, boing, boink, bombo, bongo, bonny, booby, boody, boofy, boogy, booky, boomy, boong, booth, booty, boozy, boppy, botch, bothy, botty, bough, bound, bovid, boxty, bubby, buchu, bucko, bucku, buddy, buffi, buffo, buffy, bufty, buggy, bumbo, bumph, bumpy, bunch, bunco, bundh, bundt, bundu, bundy, bungy, bunjy, bunko, bunny, bunty, buppy, butch, butoh, butty, butut, buxom, buzzy, chich, chick, chico, chimb, chimo, chimp, ching, chink, chino, chivy, chizz, chock, choco, choko, choky, chomp, choof, chook, choom, choon, chott, chout, choux, chowk, chuck, chuff, chump, chunk, chynd, ciggy, cinch, cinct, cippi, civic, civvy, cobby, cocci, cocco, cocky, codon, cogon, cohog, coign, combi, combo, comby, comfy, comic, comix, commo, commy, compo, compt, conch, condo, congo, conic, conin, conky, conto, convo, cooch, cooky, coomb, coomy, coopt, coppy, coqui, couch, cough, count, couth, covin, coxib, coypu, cubby, cubic, cubit, cuddy, cuffo, cuing, cumin, cundy, cunit, cupid, cuppy, cutch, cutin, cutto, cutty, cutup, cwtch, cynic, cyton, dhobi, dhoti, dhuti, dicht, dicky, dicot, dicty, diddy, dight, digit, dimbo, dingo, dingy, dinic, dinky, dippy, ditch, ditto, ditty, ditzy, divot, divvy, dixit, dizzy, djinn, dobby, docht, doddy, dodgy, doggo, doggy, dohyo, doing, domic, donko, donny, donut, doody, doomy, doozy, dotty, doubt, dough, dowdy, downy, dubbo, duchy, ducky, duddy, duing, dumbo, dumky, dummy, dumpy, dunch, dungy, dunno, dunny, duomi, duomo, duppy, dutch, dying, dykon, fichu, ficin, fifth, fifty, figgy, fight, finch, finny, fitch, fixit, fizzy, foggy, fogou, fondu, foody, footy, found, fount, fouth, fowth, fubby, fuddy, fudgy, fuffy, fuggy, fugio, fundi, fundy, fungi, fungo, funky, funny, futon, fuzzy, giddy, gigot, gimpy, ginch, ginny, ginzo, gipon, gippo, gippy, gitch, gizmo, gobbi, gobbo, gobby, going, gombo, gonch, gonif, gonof, gonzo, gooby, goody, goofy, gooky, goony, goopy, gopik, gotch, gothy, gouch, gouty, goyim, gucky, guimp, gumbo, gummi, gummy, gundy, gungy, gunky, gunny, guppy, guqin, gutty, guyot, gynny, gyppo, gyppy, hight, hikoi, himbo, hinky, hinny, hippo, hippy, hitch, hobby, hoick, hoing, hokku, hokum, hongi, honky, hooch, hoody, hooky, hooty, hoppy, hotch, hotty, houff, hough, hound, howdy, howff, hubby, hudud, huffy, huggy, humic, humid, humph, humpy, hunch, hunky, hutch, huzzy, hying, hyoid, hyphy, icing, ictic, idiom, idiot, imido, imino, immit, immix, impot, inbox, incog, incut, indow, infix, ingot, inion, innit, input, inwit, iodic, iodid, iodin, ionic, ippon, itchy, jiffy, jiggy, jigot, jimmy, jimpy, jingo, jinni, jocko, jocky, joint, jomon, jonty, jotty, jotun, judgy, jugum, juicy, jumbo, jumby, jumpy, junco, junky, junto, jupon, jutty, khoum, kibbi, kicky, kiddo, kiddy, kight, kikoi, kimbo, kindy, kinin, kinky, kitty, knock, knout, known, kokum, kombu, konbu, kondo, kooky, kotch, kotow, kudzu, kutch, micht, micky, middy, midgy, miffy, mifty, might, mimic, mincy, mingy, minim, minny, minty, mitch, mixup, mizzy, mobby, mochi, mochy, modii, moggy, mommy, mondo, mongo, monic, month, monty, mooch, moody, moong, moony, moppy, mothy, motif, motto, motty, mouch, mound, mount, mouth, mucho, mucic, mucid, mucin, mucky, muddy, mufti, muggy, mujik, mummy, munch, mungo, muntu, mutch, muton, muzzy, myoid, myopy, mythi, mythy, nicht, niffy, nifty, night, nimbi, ninny, ninon, ninth, nippy, nitid, niton, nitty, nobby, noddy, nohow, noint, nomic, nomoi, nonny, nooit, nooky, notch, notum, nouny, novum, nowty, nubby, nuddy, nudzh, nummy, nunny, nutty, nying, nymph, obiit, odium, oggin, ogmic, ohing, ohmic, onion, onium, ontic, oobit, oomph, ootid, oping, opium, optic, oubit, oucht, ought, oundy, outby, outdo, outgo, ovoid, owing, oxbow, phizz, phono, phony, photo, phpht, piccy, picky, picot, piggy, pight, pigmy, piing, pinch, pingo, pinko, pinky, pinny, pinon, pinot, pinto, pinup, piony, pipit, pippy, pitch, pithy, piton, pitot, pivot, poboy, pocky, poddy, podgy, poind, point, pommy, poncy, pongo, pongy, ponty, ponzu, pooch, poofy, poopy, poovy, poppy, potch, potin, potoo, potto, potty, pouch, pouff, pound, poupt, pouty, powin, pownd, powny, poynt, poyou, pozzy, pubco, pubic, puddy, pudgy, pudic, puffy, puggy, punch, punji, punky, punny, punto, punty, puppy, putid, puton, putti, putto, putty, pygmy, pyoid, qubit, quich, quick, quiff, quino, quint, quipo, quipu, quoif, quoin, quoit, quonk, quoth, thick, thigh, thing, think, thoft, thong, thumb, thump, thunk, thymi, thymy, tichy, ticky, tiddy, tight, tigon, timbo, timid, timon, tinct, tinny, tinty, tippy, titch, titty, titup, tiyin, tizzy, tocky, toddy, toffy, toing, tommy, tondi, tondo, tonic, tooth, tophi, topic, topoi, toppy, totty, touch, tough, touzy, towny, towzy, toxic, toxin, toyon, tubby, tufty, tuktu, tumid, tummy, tumpy, tunic, tunny, tupik, tutti, tutty, twink, twiny, twixt, tying, tyiyn, typic, typto, umpty, unbid, unbox, uncoy, uncut, undid, undug, unfit, unfix, ungod, ungot, ungum, unhip, unify, union, unity, unkid, unmix, unpin, untin, unwit, unwon, unzip, upbow, vichy, vinic, vivid, voddy, vodou, vodun, vomit, vouch, vozhd, vuggy, vughy, vutty, vying, which, whiff, whift, whiny, whipt, whity, whizz, whomp, whoof, whoop, whoot, whump, wicky, widdy, widow, width, wifty, wiggy, wight, wimpy, winch, windy, wingy, witch, withy, witty, womby, womyn, wongi, wonky, woody, woofy, woopy, wootz, woozy, wound, wuddy, ycond, yippy, yobbo, yobby, yogic, yogin, yoick, yomim, yonic, young, youth, yucch, yucko, yucky, yukky, yummo, yummy, yupon, yuppy, zhomo, zimbi, zinco, zincy, zingy, zinky, zippo, zippy, zizit, zocco, zombi, zooid, zooty, zoppo, zuzim, zygon, and zymic\n",
      "SECOND MOVE: poynt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_first_guess = 'reals'\n",
    "tree_first_response_pattern = 'xxxxx'\n",
    "tree_first_candidates_list = get_candidates_list([tree_first_guess], [tree_first_response_pattern])\n",
    "print(f'list of possible solutions ({len(tree_first_candidates_list):,}): {conjunctify_nouns(tree_first_candidates_list)}')\n",
    "tree_second_guess = get_word_guess(response_patterns_df, tree_first_candidates_list, guesses_list=[tree_first_guess])\n",
    "print(f'SECOND MOVE: {tree_second_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd1a87a9-77b8-4250-b604-3a7e077f224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions (44): boing, boink, bonny, boong, ching, chink, chino, chynd, djinn, doing, donny, downy, dying, finny, ginny, going, goony, gynny, hinny, hoing, hying, icing, imino, jinni, minny, moong, moony, ninny, nonny, nying, ohing, oping, owing, phono, phony, piing, pinny, piony, poind, pownd, powny, vying, whiny, and ycond\n",
      "THIRD MOVE: godly\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_second_guess = 'saunt'\n",
    "tree_second_response_pattern = 'xxxGx'\n",
    "test_words_list = [tree_first_guess, tree_second_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern]\n",
    "tree_second_candidates_list = get_candidates_list(test_words_list, response_patterns_list, tree_first_candidates_list)\n",
    "print(f'list of possible solutions ({len(tree_second_candidates_list):,}): {conjunctify_nouns(tree_second_candidates_list)}')\n",
    "tree_third_guess = get_word_guess(response_patterns_df, tree_second_candidates_list, guesses_list=test_words_list)\n",
    "print(f'THIRD MOVE: {tree_third_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3daf242-daf0-468d-88c1-4888b1cf4577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions (12): boing, boink, bonny, boong, doing, donny, downy, going, goony, moong, moony, and nonny\n",
      "FOURTH MOVE: gibed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_third_guess = 'hopes'\n",
    "tree_third_response_pattern = 'xGxxx'\n",
    "test_words_list = [tree_first_guess, tree_second_guess, tree_third_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern, tree_third_response_pattern]\n",
    "tree_third_candidates_list = get_candidates_list(test_words_list, response_patterns_list, tree_second_candidates_list)\n",
    "print(f'list of possible solutions ({len(tree_third_candidates_list):,}): {conjunctify_nouns(tree_third_candidates_list)}')\n",
    "tree_fourth_guess = get_word_guess(response_patterns_df, tree_third_candidates_list, guesses_list=test_words_list)\n",
    "print(f'FOURTH MOVE: {tree_fourth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88e7fbfd-9dad-4492-9aa9-8ba15d4200b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions (4): boing, boink, doing, and going\n",
      "FIFTH MOVE: gobis\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_fourth_guess = 'moile'\n",
    "tree_fourth_response_pattern = 'xGGxx'\n",
    "test_words_list = [tree_first_guess, tree_second_guess, tree_third_guess, tree_fourth_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern, tree_third_response_pattern, tree_fourth_response_pattern]\n",
    "tree_fourth_candidates_list = get_candidates_list(test_words_list, response_patterns_list, tree_third_candidates_list)\n",
    "print(f'list of possible solutions ({len(tree_fourth_candidates_list):,}): {conjunctify_nouns(tree_fourth_candidates_list)}')\n",
    "tree_fifth_guess = get_word_guess(response_patterns_df, tree_fourth_candidates_list, guesses_list=test_words_list)\n",
    "print(f'FIFTH MOVE: {tree_fifth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccbf45d4-466a-4585-83f9-e46ecde3204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (4): boing, boink, doing, and going\n",
      "SIXTH MOVE: boing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_fifth_guess = 'sepia'\n",
    "tree_fifth_response_pattern = 'xxxYx'\n",
    "test_words_list = [tree_first_guess, tree_second_guess, tree_third_guess, tree_fourth_guess, tree_fifth_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern, tree_third_response_pattern, tree_fourth_response_pattern,\n",
    "                          tree_fifth_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "tree_fifth_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                tree_fifth_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(tree_fifth_candidates_list)}): {conjunctify_nouns(sorted(tree_fifth_candidates_list))}')\n",
    "tree_sixth_guess, max_score = get_best_word(tree_fifth_candidates_list)\n",
    "print(f'SIXTH MOVE: {tree_sixth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23fac885-0ee7-4d19-ab28-6e851093348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (4): boing, boink, doing, and going\n",
      "SEVENTH MOVE: boing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_sixth_guess = 'quite'\n",
    "tree_sixth_response_pattern = 'xxGxx'\n",
    "test_words_list = [tree_first_guess, tree_second_guess, tree_third_guess, tree_fourth_guess, tree_fifth_guess, tree_sixth_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern, tree_third_response_pattern, tree_fourth_response_pattern,\n",
    "                          tree_fifth_response_pattern, tree_sixth_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "tree_sixth_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                tree_sixth_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(tree_sixth_candidates_list)}): {conjunctify_nouns(sorted(tree_sixth_candidates_list))}')\n",
    "tree_seventh_guess, max_score = get_best_word(tree_sixth_candidates_list)\n",
    "print(f'SEVENTH MOVE: {tree_seventh_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "581df188-5f95-4262-900f-4f129a0166c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (3): boing, boink, and going\n",
      "EIGHTH MOVE: boing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_seventh_guess = 'acrid'\n",
    "tree_seventh_response_pattern = 'xxxYx'\n",
    "test_words_list = [tree_first_guess, tree_second_guess, tree_third_guess, tree_fourth_guess, tree_fifth_guess, tree_sixth_guess, tree_seventh_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern, tree_third_response_pattern, tree_fourth_response_pattern,\n",
    "                          tree_fifth_response_pattern, tree_sixth_response_pattern, tree_seventh_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "tree_seventh_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                tree_seventh_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(tree_seventh_candidates_list)}): {conjunctify_nouns(sorted(tree_seventh_candidates_list))}')\n",
    "tree_eighth_guess, max_score = get_best_word(tree_seventh_candidates_list)\n",
    "print(f'EIGHTH MOVE: {tree_eighth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8faecd27-6636-4007-9111-a0e1c34eb3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (1): going\n",
      "NINTH MOVE: going\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_eighth_guess = 'boing'\n",
    "tree_eighth_response_pattern = 'xGGGG'\n",
    "test_words_list = [tree_first_guess, tree_second_guess, tree_third_guess, tree_fourth_guess, tree_fifth_guess, tree_sixth_guess, tree_seventh_guess, tree_eighth_guess]\n",
    "response_patterns_list = [tree_first_response_pattern, tree_second_response_pattern, tree_third_response_pattern, tree_fourth_response_pattern,\n",
    "                          tree_fifth_response_pattern, tree_sixth_response_pattern, tree_seventh_response_pattern, tree_eighth_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "tree_eighth_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                tree_eighth_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(tree_eighth_candidates_list)}): {conjunctify_nouns(sorted(tree_eighth_candidates_list))}')\n",
    "tree_ninth_guess, max_score = get_best_word(tree_eighth_candidates_list)\n",
    "print(f'NINTH MOVE: {tree_ninth_guess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c8740-402f-408f-a87e-49bed619a97a",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Maximize Green Responses to Solve a Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1ff01416-897e-417b-aced-6c9a7234aace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (12,972)\n",
      "FIRST MOVE: arose\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_first_guess, max_score = get_best_word(words_list)\n",
    "print(f'list of possible solutions: ({len(words_list):,})')\n",
    "print(f'FIRST MOVE: {leaf_first_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5a17dc9-be97-4806-a41f-a64ca308b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (796): babka, baboo, babul, bacca, bacco, baccy, bacha, bacon, baddy, badly, baffy, baggy, bahut, bajan, baldy, balky, bally, balmy, baloo, balun, banak, banal, banco, banda, bandh, bandy, banjo, bantu, banty, banya, batch, baton, batta, battu, batty, baulk, bawdy, bawty, bayou, bazoo, bhang, bhuna, black, blady, blaff, bland, blank, blatt, blaud, blawn, bloat, bobac, bobak, bocca, bogan, bonza, booay, bowat, boxla, boyau, boyla, bubal, bubba, buffa, bulla, bunya, bwana, bylaw, byway, cabal, cabby, cabob, caboc, cacao, cacky, caddy, cadgy, cagot, cahow, cajon, cajun, calla, calmy, calpa, calyx, caman, campo, campy, canal, candy, canna, canny, canon, canto, canty, capon, capot, capul, caput, catch, catty, cauda, cauld, caulk, caxon, chack, chaco, chado, chaff, chaft, chalk, champ, chana, chang, chank, chant, chapt, chawk, chaya, chola, chota, chufa, clach, clack, clamp, clang, clank, clapt, claut, cloak, cloam, coach, coact, coady, coala, coaly, coapt, cobza, cocoa, cohab, colza, comal, comma, conga, copal, copay, cotan, cotta, couta, cowal, cowan, coxal, coyau, culpa, cuppa, cyano, cycad, dabba, dacha, dadah, daddy, daffy, dagga, daggy, dally, daman, dampy, dancy, dandy, danny, datal, datto, datum, dauby, dault, daunt, dawah, dayan, daych, daynt, dhaba, dobla, dogan, dogma, dolma, domal, donah, donga, donna, doona, dotal, doula, douma, downa, ducal, ducat, dukka, dumka, dunam, dwaal, dwalm, dwang, dwaum, fabby, facta, faddy, faffy, faggy, fagot, falaj, fanal, fancy, fanga, fango, fanny, fanon, fanum, fatal, fatly, fatty, fatwa, faugh, fauld, fault, fauna, fawny, flack, flaff, flaky, flamm, flamy, flank, flava, flawn, flawy, flaxy, float, flota, foamy, focal, fonda, fouat, fugal, gabba, gabby, gadjo, galah, galax, gally, galop, galut, galvo, gamay, gamba, gambo, gamma, gammy, gamut, ganch, gandy, ganja, ganof, gappy, gatch, gauch, gaucy, gaudy, gault, gaumy, gaunt, gauzy, gavot, gawcy, gawky, gayal, gayly, gazal, gazon, gazoo, ghaut, glady, gland, glaum, glazy, gloam, gloat, gnawn, goaty, goban, gogga, gompa, gonad, gonna, gopak, gotta, gowan, guaco, guana, guano, guava, gulag, gumma, gutta, gyoza, hadal, hakam, halal, halfa, hallo, halma, halon, halva, halwa, hamal, hamba, hammy, hamza, hanap, hanch, handy, hanky, haoma, hapax, haply, happy, hatch, hatha, haugh, hauld, haulm, hault, haunt, havoc, hazan, hoagy, hodad, hodja, hogan, holla, honan, honda, hooka, hopak, hudna, human, huzza, hypha, jabot, jacal, jacky, jaffa, jaggy, jalap, jalop, jambo, jambu, jammy, jamon, janny, janty, japan, jaunt, jawan, jazzy, jhala, jnana, joual, jugal, junta, kaama, kabab, kabob, kacha, kahal, kalam, kalpa, kandy, kanga, kanzu, kapok, kapow, kappa, kaput, katal, kaugh, kaval, kawau, kayak, kazoo, khaph, khaya, khoja, klang, knack, koala, koban, kofta, kogal, kokam, koppa, kulak, kulan, kyack, kyang, labda, laddy, lagan, lahal, laldy, lamby, lammy, lanch, lanky, latah, latch, lathy, lauan, lauch, laugh, laund, laval, lavvy, lawny, laxly, layup, lazzo, llama, llano, loach, loamy, loath, local, logan, lohan, longa, loofa, lotah, lotta, louma, lovat, lowan, loyal, luach, luffa, lytta, macaw, macho, macon, madam, madly, magma, magot, mahua, mahwa, malam, malax, malmy, malty, malva, malwa, mamba, mambo, mamma, mammy, manat, manga, mango, mangy, manky, manly, manna, manta, manto, manty, manul, mapau, match, matlo, matza, matzo, mauby, maund, mauzy, mawky, mayan, mazut, mocha, modal, mohua, molal, molla, momma, monad, monal, moola, motza, mugga, mulga, mulla, munga, mutha, muzak, myall, mynah, myoma, nabla, nabob, nacho, naggy, nahal, nakfa, nalla, namma, nancy, nandu, nanna, nanny, nanua, napoo, nappa, nappy, natal, natch, natty, nauch, naunt, naval, navvy, nawab, nduja, ngana, ngoma, nodal, nomad, nopal, notal, noway, noxal, noyau, nucha, nulla, nyaff, nyala, oakum, obang, occam, octad, octal, octan, offal, oflag, ogham, ollav, omlah, onlay, otaku, outta, pacha, pacta, paddy, padma, pagan, pagod, pakka, palay, palla, pally, palmy, pampa, panax, panda, pandy, panga, panko, panto, panty, paolo, papal, papaw, pappy, patch, patka, patly, patty, pavan, pawaw, pawky, phang, phoca, phyla, plack, plank, plant, platt, platy, playa, plaza, ploat, poach, poaka, podal, pokal, polka, ponga, pooja, pooka, poppa, powan, pucan, pucka, puffa, pujah, pukka, pulao, pulka, punga, punka, pupal, pygal, pzazz, qajaq, qanat, quack, quaff, quaky, qualm, quant, quayd, quoad, quota, taata, tabby, tabla, taboo, tabun, tacan, tacho, tacky, taffy, taggy, tagma, takky, talak, talaq, talcy, talky, tally, talma, talon, talpa, taluk, tamal, tammy, tanga, tango, tangy, tanka, tanky, tanna, tanto, tanty, tappa, tatou, tatty, tauld, taunt, tauon, tavah, tawny, taxol, taxon, tazza, thack, thana, thang, thank, thanx, thawy, thuja, thuya, toady, today, tokay, tolan, toman, tonal, tonga, tonka, topaz, total, tuath, tubal, tulpa, twang, twank, typal, uhlan, ulama, ulnad, ulpan, ummah, unapt, unbag, unban, uncap, undam, ungag, unhat, unjam, unlaw, unlay, unman, unpay, untax, uplay, uptak, uvula, vacua, vagal, vampy, vanda, vauch, vault, vaunt, vocab, vocal, vodka, volta, volva, vulva, wacko, wacky, waddy, wagga, wagon, wagyu, wahoo, waldo, walla, wally, walty, waltz, wanky, wanly, wanna, wanty, watap, watch, wauff, waugh, waulk, wazoo, whack, whamo, whang, whata, whaup, whyda, woald, wokka, woman, wonga, xoana, xylan, yabba, yabby, yacca, yacht, yacka, yahoo, yakka, yakow, yampy, yamun, yapok, yapon, yappy, yauld, yawny, yclad, yojan, yowza, yucca, yulan, zakat, zaman, zambo, zanja, zanza, zappy, zonal, zonda, zoppa, zupan, zuppa, and zygal\n",
      "SECOND MOVE: tolan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_first_guess = 'arise'\n",
    "leaf_first_response_pattern = 'Yxxxx'\n",
    "test_words_list = [leaf_first_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_first_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_first_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_first_candidates_list)}): {conjunctify_nouns(sorted(leaf_first_candidates_list))}')\n",
    "leaf_second_guess, max_score = get_best_word(leaf_first_candidates_list)\n",
    "print(f'SECOND MOVE: {leaf_second_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6198f8e9-ec46-46d7-8777-f91b3f352bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (310): babka, baboo, bacca, bacco, baccy, bacha, bacon, baddy, baffy, baggy, bajan, banak, banco, banda, bandh, bandy, banjo, banya, bawdy, bayou, bazoo, bhang, bhuna, bobac, bobak, bocca, bogan, bonza, booay, boyau, bubba, buffa, bunya, bwana, byway, cabby, cabob, caboc, cacao, cacky, caddy, cadgy, cahow, cajon, cajun, caman, candy, canna, canny, canon, cauda, caxon, chack, chaco, chado, chaff, chana, chang, chank, chawk, chaya, chufa, coach, coady, cobza, cocoa, cohab, comma, conga, cowan, coyau, cyano, cycad, dabba, dacha, dadah, daddy, daffy, dagga, daggy, daman, dancy, dandy, danny, dauby, dawah, dayan, daych, dhaba, dogan, dogma, donah, donga, donna, doona, douma, downa, dukka, dumka, dunam, dwang, dwaum, fabby, faddy, faffy, faggy, fancy, fanga, fango, fanny, fanon, fanum, faugh, fauna, fawny, foamy, fonda, gabba, gabby, gadjo, gamay, gamba, gambo, gamma, gammy, ganch, gandy, ganja, ganof, gauch, gaucy, gaudy, gaumy, gauzy, gawcy, gawky, gazon, gazoo, gnawn, goban, gogga, gonad, gonna, gowan, guaco, guana, guano, guava, gumma, gyoza, hakam, hamba, hammy, hamza, hanch, handy, hanky, haoma, haugh, havoc, hazan, hoagy, hodad, hodja, hogan, honan, honda, hooka, hudna, human, huzza, jacky, jaffa, jaggy, jambo, jambu, jammy, jamon, janny, jawan, jazzy, jnana, kaama, kabab, kabob, kacha, kandy, kanga, kanzu, kaugh, kawau, kayak, kazoo, khaya, khoja, knack, koban, kokam, kyack, kyang, macaw, macho, macon, madam, magma, mahua, mahwa, mamba, mambo, mamma, mammy, manga, mango, mangy, manky, manna, mauby, maund, mauzy, mawky, mayan, mocha, mohua, momma, monad, mugga, munga, muzak, mynah, myoma, nabob, nacho, naggy, nakfa, namma, nancy, nandu, nanna, nanny, nanua, nauch, navvy, nawab, nduja, ngana, ngoma, nomad, noway, noyau, nucha, nyaff, oakum, obang, occam, ogham, qajaq, quack, quaff, quaky, quayd, quoad, ummah, unbag, unban, undam, ungag, unjam, unman, vacua, vanda, vauch, vocab, vodka, wacko, wacky, waddy, wagga, wagon, wagyu, wahoo, wanky, wanna, wauff, waugh, wazoo, whack, whamo, whang, whyda, wokka, woman, wonga, xoana, yabba, yabby, yacca, yacka, yahoo, yakka, yakow, yamun, yawny, yojan, yowza, yucca, zaman, zambo, zanja, zanza, and zonda\n",
      "THIRD MOVE: cyano\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_second_guess = 'slipt'\n",
    "leaf_second_response_pattern = 'xxxxx'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_second_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_second_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_second_candidates_list)}): {conjunctify_nouns(sorted(leaf_second_candidates_list))}')\n",
    "leaf_third_guess, max_score = get_best_word(leaf_second_candidates_list)\n",
    "print(f'THIRD MOVE: {leaf_third_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19ac7319-fcd3-4916-b2ef-ec89102ba2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (59): caman, comma, daman, dogma, douma, dumka, dunam, dwaum, fanum, foamy, gamay, gamba, gambo, gamma, gammy, gaumy, gumma, jambo, jambu, jammy, jamon, kaama, kokam, macaw, macon, madam, magma, mamba, mambo, mamma, mammy, manga, mango, mangy, manky, manna, mauby, maund, mauzy, mawky, mayan, momma, monad, mugga, munga, muzak, myoma, namma, ngoma, nomad, oakum, occam, undam, unjam, unman, woman, yamun, zaman, and zambo\n",
      "FOURTH MOVE: mango\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_third_guess = 'smith'\n",
    "leaf_third_response_pattern = 'xYxxx'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess, leaf_third_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern, leaf_third_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_third_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_third_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_third_candidates_list)}): {conjunctify_nouns(sorted(leaf_third_candidates_list))}')\n",
    "leaf_fourth_guess, max_score = get_best_word(leaf_third_candidates_list)\n",
    "print(f'FOURTH MOVE: {leaf_fourth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b71a8e7-6251-4bfa-9f9b-f7f38a852097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (29): comma, dogma, douma, dwaum, foamy, gamay, gamba, gambo, gamma, gammy, gaumy, gumma, jambo, jambu, jammy, macaw, madam, magma, mamba, mambo, mamma, mammy, mauby, mauzy, momma, mugga, myoma, occam, and zambo\n",
      "FIFTH MOVE: gambo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_fourth_guess = 'stink'\n",
    "leaf_fourth_response_pattern = 'xxxxx'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess, leaf_third_guess, leaf_fourth_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern, leaf_third_response_pattern, leaf_fourth_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_fourth_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_fourth_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_fourth_candidates_list)}): {conjunctify_nouns(sorted(leaf_fourth_candidates_list))}')\n",
    "leaf_fifth_guess, max_score = get_best_word(leaf_fourth_candidates_list)\n",
    "print(f'FIFTH MOVE: {leaf_fifth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2cefa007-ac62-45bf-a659-7c2de9f3d1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (5): comma, dogma, momma, myoma, and occam\n",
      "SIXTH MOVE: comma\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_fifth_guess = 'sulfo'\n",
    "leaf_fifth_response_pattern = 'xxxxY'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess, leaf_third_guess, leaf_fourth_guess, leaf_fifth_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern, leaf_third_response_pattern, leaf_fourth_response_pattern,\n",
    "                          leaf_fifth_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_fifth_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_fifth_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_fifth_candidates_list)}): {conjunctify_nouns(sorted(leaf_fifth_candidates_list))}')\n",
    "leaf_sixth_guess, max_score = get_best_word(leaf_fifth_candidates_list)\n",
    "print(f'SIXTH MOVE: {leaf_sixth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8745e77b-818c-4b1d-87bc-c7bab78d57dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (2): dogma and momma\n",
      "SEVENTH MOVE: dogma\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_sixth_guess = 'scowl'\n",
    "leaf_sixth_response_pattern = 'xxYxx'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess, leaf_third_guess, leaf_fourth_guess, leaf_fifth_guess, leaf_sixth_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern, leaf_third_response_pattern, leaf_fourth_response_pattern,\n",
    "                          leaf_fifth_response_pattern, leaf_sixth_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_sixth_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_sixth_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_sixth_candidates_list)}): {conjunctify_nouns(sorted(leaf_sixth_candidates_list))}')\n",
    "leaf_seventh_guess, max_score = get_best_word(leaf_sixth_candidates_list)\n",
    "print(f'SEVENTH MOVE: {leaf_seventh_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03035e14-e995-480c-860a-6f01091be695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (1): dogma\n",
      "EIGHTH MOVE: dogma\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_seventh_guess = 'scold'\n",
    "leaf_seventh_response_pattern = 'xxYxY'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess, leaf_third_guess, leaf_fourth_guess, leaf_fifth_guess, leaf_sixth_guess, leaf_seventh_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern, leaf_third_response_pattern, leaf_fourth_response_pattern,\n",
    "                          leaf_fifth_response_pattern, leaf_sixth_response_pattern, leaf_seventh_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_seventh_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_seventh_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_seventh_candidates_list)}): {conjunctify_nouns(sorted(leaf_seventh_candidates_list))}')\n",
    "leaf_eighth_guess, max_score = get_best_word(leaf_seventh_candidates_list)\n",
    "print(f'EIGHTH MOVE: {leaf_eighth_guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91ce1ebe-4e9d-4134-a9ba-dd6d1b59f582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of possible solutions: (1): dogma\n",
      "NINTH MOVE: dogma\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leaf_eighth_guess = 'quoth'\n",
    "leaf_eighth_response_pattern = 'xxYxx'\n",
    "test_words_list = [leaf_first_guess, leaf_second_guess, leaf_third_guess, leaf_fourth_guess, leaf_fifth_guess, leaf_sixth_guess, leaf_seventh_guess, leaf_eighth_guess]\n",
    "response_patterns_list = [leaf_first_response_pattern, leaf_second_response_pattern, leaf_third_response_pattern, leaf_fourth_response_pattern,\n",
    "                          leaf_fifth_response_pattern, leaf_sixth_response_pattern, leaf_seventh_response_pattern, leaf_eighth_response_pattern]\n",
    "yellows_list = get_yellows_list(test_words_list, response_patterns_list)\n",
    "greys_list = get_greys_list(test_words_list, response_patterns_list)\n",
    "leaf_eighth_candidates_list = []\n",
    "for word_str in words_list:\n",
    "    if all(map(lambda x: x in word_str, yellows_list)):\n",
    "        if all(map(lambda x: x not in word_str, greys_list)):\n",
    "            if is_greened(word_str, test_words_list, response_patterns_list):\n",
    "                leaf_eighth_candidates_list.append(word_str)\n",
    "print(f'list of possible solutions: ({len(leaf_eighth_candidates_list)}): {conjunctify_nouns(sorted(leaf_eighth_candidates_list))}')\n",
    "leaf_ninth_guess, max_score = get_best_word(leaf_eighth_candidates_list)\n",
    "print(f'NINTH MOVE: {leaf_ninth_guess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8fd7d3-7d89-42c6-a7ec-4797fcfca6d5",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "## Display the Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a716ee7d-8c1f-4c80-8402-650bf8f508a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def patternize_guess(word_str, pattern_str):\n",
    "    pre_str = '<span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:'\n",
    "    in_str = ';\">'\n",
    "    post_str = '</span>'\n",
    "    patternized_str = ''\n",
    "    for letter_str, letter_pattern in zip(word_str, pattern_str):\n",
    "        patternized_str += pre_str\n",
    "        if letter_pattern == 'G':\n",
    "            patternized_str += 'green'\n",
    "        elif letter_pattern == 'Y':\n",
    "            patternized_str += 'yellow'\n",
    "        else:\n",
    "            patternized_str += 'grey'\n",
    "        patternized_str += in_str + letter_str + post_str\n",
    "    \n",
    "    return patternized_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "85f85298-3ce0-44f3-afe0-e0327a2753c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from num2words import num2words\n",
    "\n",
    "def get_tr(ordinal, leaf_count=None, tree_count=None):\n",
    "    ordinal_str = num2words(ordinal, lang='en', to='ordinal')\n",
    "    previous_ordinal_str = num2words(ordinal-1, lang='en', to='ordinal')\n",
    "    if leaf_count is None:\n",
    "        leaf_count = eval(f'len(leaf_{previous_ordinal_str}_candidates_list)')\n",
    "    leaf_guess = eval(f'leaf_{ordinal_str}_guess')\n",
    "    leaf_pattern = eval(f'leaf_{ordinal_str}_response_pattern')\n",
    "    if tree_count is None:\n",
    "        tree_count = eval(f'len(tree_{previous_ordinal_str}_candidates_list)')\n",
    "    tree_guess = eval(f'tree_{ordinal_str}_guess')\n",
    "    tree_pattern = eval(f'tree_{ordinal_str}_response_pattern')\n",
    "    html_str = f'''<tr>\n",
    "        <td>{ordinal_str.title()}</td>\n",
    "        <td>{leaf_count:,}</td>\n",
    "        <td>{patternize_guess(leaf_guess, leaf_pattern)}</td>\n",
    "        <td>{tree_count:,}</td>\n",
    "        <td>{patternize_guess(tree_guess, tree_pattern)}</td>\n",
    "    </tr>'''\n",
    "    \n",
    "    return html_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "89bf24c8-c4e8-456c-bc0e-91c7c4ebefef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th rowspan=\"2\">Move</th>\n",
       "        <th colspan=\"2\" style=\"text-align:center\">Green Maximizer</th>\n",
       "        <th colspan=\"2\" style=\"text-align:center\">Branch Minimizer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th style=\"text-align:center\">Solutions</th>\n",
       "        <th style=\"text-align:center\">Guess</th>\n",
       "        <th style=\"text-align:center\">Solutions</th>\n",
       "        <th style=\"text-align:center\">Guess</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>First</td>\n",
       "        <td>12,972</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">r</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">o</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">s</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">e</span></td>\n",
       "        <td>12,972</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">r</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">e</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">l</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">s</span></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Second</td>\n",
       "        <td>801</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">l</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">y</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">i</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">n</span></td>\n",
       "        <td>126</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">n</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">i</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">t</span></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Third</td>\n",
       "        <td>40</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">u</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">f</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">a</span></td>\n",
       "        <td>10</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">o</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">n</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:yellow;\">k</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:grey;\">y</span></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Fourth</td>\n",
       "        <td>2</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "        <td>1</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Fifth</td>\n",
       "        <td>1</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "        <td>1</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Sixth</td>\n",
       "        <td>1</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "        <td>1</td>\n",
       "        <td><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">w</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">h</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">a</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">c</span><span style=\"font-family:Courier;font-size:3em;text-transform:uppercase;font-variant-numeric:tabular-nums lining-nums;background-color:green;\">k</span></td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "HTML(f'''<table>\n",
    "    <tr>\n",
    "        <th rowspan=\"2\">Move</th>\n",
    "        <th colspan=\"2\" style=\"text-align:center\">Green Maximizer</th>\n",
    "        <th colspan=\"2\" style=\"text-align:center\">Branch Minimizer</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align:center\">Solutions</th>\n",
    "        <th style=\"text-align:center\">Guess</th>\n",
    "        <th style=\"text-align:center\">Solutions</th>\n",
    "        <th style=\"text-align:center\">Guess</th>\n",
    "    </tr>\n",
    "    {get_tr(1, leaf_count=len(words_list), tree_count=len(words_list))}\n",
    "    {get_tr(2)}\n",
    "    {get_tr(3)}\n",
    "    {get_tr(4)}\n",
    "    {get_tr(5)}\n",
    "    {get_tr(6)}\n",
    "</table>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15656dd0-971c-4645-91f1-235c41c07088",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "# Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3624b53e-e885-4560-9e41-c0950d78be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_patterns_set = set(['xGxxx', 'xGxYx', 'xYYYY'])\n",
    "# mask_series = False\n",
    "# for test_word, response_pattern in zip(test_words_list, response_patterns_list):\n",
    "#     mask_series = mask_series | ((response_patterns_df.test_word == test_word) & (response_patterns_df.response_pattern == response_pattern))\n",
    "mask_series = response_patterns_df.response_pattern.isin(response_patterns_set)\n",
    "counts_df = response_patterns_df[mask_series].groupby('target_word').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec467754-bbb7-45c3-8d06-681538b3cbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_word</th>\n",
       "      <th>response_pattern</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jaffa</th>\n",
       "      <td>1862</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qajaq</th>\n",
       "      <td>1816</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mamma</th>\n",
       "      <td>1751</td>\n",
       "      <td>1751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baboo</th>\n",
       "      <td>1676</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kazoo</th>\n",
       "      <td>1667</td>\n",
       "      <td>1667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_word  response_pattern\n",
       "target_word                             \n",
       "jaffa             1862              1862\n",
       "qajaq             1816              1816\n",
       "mamma             1751              1751\n",
       "baboo             1676              1676\n",
       "kazoo             1667              1667"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "counts_df.sort_values('response_pattern', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359ebd7-eccc-4877-b485-0c8278414088",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if s.pickle_exists('english_letter_frequencies_df'):\n",
    "    letter_proportions_df = s.load_object('english_letter_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get proportions from word list\n",
    "    import collections\n",
    "\n",
    "    letters_list = []\n",
    "    for word_str in words_list:\n",
    "        letters_list += list(word_str)\n",
    "    counter = collections.Counter(letters_list)\n",
    "    letter_proportions_df = pd.DataFrame([{'letter_char': x, 'letter_count': y} for x, y in dict(counter).items()])\n",
    "    min_count = letter_proportions_df.letter_count.min()\n",
    "    letter_proportions_df['proportion'] = letter_proportions_df.letter_count.map(lambda x: x/min_count)\n",
    "    s.store_objects(english_letter_frequencies_df=letter_proportions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7998f7b-c11b-4fb6-b377-0714029ee27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "random.sample(words_list, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2e582-41a4-4883-816a-e3c4f9e32b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "letter_proportions_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60784307-9098-462e-9b60-8ebb82a74570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (letter_proportions_df.letter_char == 'e')\n",
    "letter_proportions_df[mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadc25d-db2c-40b6-80a9-85b46285a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "letter_proportions_df.sort_values('proportion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63baa5d4-f095-4634-b382-7258a0c60cf4",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8075915-b84c-44a1-8c90-1b2cb7c428b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern_groupby = response_patterns_df.groupby('response_pattern').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f1f5e-e291-497a-9fbd-a791017b579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern_groupby.sort_values('test_word', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df0c52f-37b7-4748-bbcc-0598b4e5a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = response_patterns_df.target_word.isin(candidates_list)\n",
    "pattern_groupby = response_patterns_df[mask_series].groupby('response_pattern').count().sort_values('test_word', ascending=False)\n",
    "pattern_groupby.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c92bd-88dd-41a7-be00-cf40facbdf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern_groupby.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341a1dd-5470-4010-8954-93112948b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = response_patterns_df.target_word.isin(candidates_list) & (response_patterns_df.response_pattern.isin(['GGYGY', 'GYGGY', 'GYxGG']))\n",
    "response_patterns_df[mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d2c1a-4069-405e-be63-99af23ddf162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = response_patterns_df.test_word.isin(['arise'])\n",
    "pattern_groupby = response_patterns_df[mask_series].groupby('response_pattern').count().sort_values('test_word', ascending=False)\n",
    "pattern_groupby.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53616476-00d4-4882-b418-d663e1f78d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_list = ['arise']\n",
    "pattern_groupby.loc[test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab0fa28-c499-487b-96a4-452050d82011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get words from GloVe: Global Vectors for Word Representation\n",
    "import re\n",
    "\n",
    "words_list = []\n",
    "file_path = r'D:\\Documents\\GitHub\\job-hunting\\data\\6B\\glove.6B.300d.txt'\n",
    "az_regex = re.compile('[^a-z]')\n",
    "with open(file_path, encoding='utf8') as infile:\n",
    "    for line in infile:\n",
    "        word_str = line.split()[0]\n",
    "        if (len(word_str) == 5) and not az_regex.search(word_str):\n",
    "            words_list.append(word_str)\n",
    "words_list.remove('aerio')\n",
    "words_list.remove('ioane')\n",
    "words_list.remove('eonia')\n",
    "words_list.remove('tabou')\n",
    "words_list.remove('tamou')\n",
    "words_list.remove('tarom')\n",
    "words_list.remove('tarmo')\n",
    "words_list.remove('marot')\n",
    "words_list.remove('marto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8dfa2b-5342-4ba3-a02c-a6c05f371a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_lists(candidate_word, colors_list, greys_list=None, yellows_list=None, greens_list=None):\n",
    "    if greys_list is None: greys_list = []\n",
    "    if yellows_list is None: yellows_list = []\n",
    "    if greens_list is None: greens_list = []\n",
    "    for color, index in zip(range(len(candidate_word)), colors_list):\n",
    "        if color == 'grey':\n",
    "            greys_list.append(candidate_word[index])\n",
    "        elif color == 'yellow':\n",
    "            yellows_list.append(candidate_word[index])\n",
    "        elif color == 'green':\n",
    "            greens_list.append(f\"(candidate_word[{index}] == '{candidate_word[index]}')\")\n",
    "    \n",
    "    return greys_list, yellows_list, greens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd75bab-b1a4-452d-8c8a-5b493daeea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_largest_equivalence_class(candidates_list, base_greys_list=None, base_yellows_list=None, base_greens_list=None):\n",
    "    if base_greys_list is None: base_greys_list = []\n",
    "    if base_yellows_list is None: base_yellows_list = []\n",
    "    if base_greens_list is None: base_greens_list = []\n",
    "    max_possibles_list = []\n",
    "    max_candidate_word = ''\n",
    "    for candidate_word in candidates_list:\n",
    "        possibles_list = []\n",
    "        for color1 in ['grey', 'yellow', 'green']:\n",
    "            for color2 in ['grey', 'yellow', 'green']:\n",
    "                for color3 in ['grey', 'yellow', 'green']:\n",
    "                    for color4 in ['grey', 'yellow', 'green']:\n",
    "                        for color5 in ['grey', 'yellow', 'green']:\n",
    "                            colors_list = [color1, color2, color3, color4, color5]\n",
    "                            greys_list, yellows_list, greens_list = build_lists(candidate_word, colors_list,\n",
    "                                                                                base_greys_list, base_yellows_list, base_greens_list)\n",
    "                            if all(map(lambda x: eval(x), greens_list)):\n",
    "                                if all(map(lambda x: x in word_str, yellows_list)):\n",
    "                                    if all(map(lambda x: x not in word_str, greys_list)):\n",
    "                                        possibles_list.append(candidate_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f74fde-8cb4-416f-b0b7-c1eadda5c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for word_str in candidates_list:\n",
    "    greys_list = ['a', 'i', 's']\n",
    "    yellows_list = ['r']\n",
    "    greens_list = [\"(candidate_word[4] == 'e')\"]\n",
    "    max_possibles_list = get_largest_equivalence_class(word_str, base_greys_list=greys_list, base_yellows_list=yellows_list, base_greens_list=greens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53706f0-4bd1-4d27-b4d0-57e5237cb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if s.pickle_exists('english_word_frequencies_df'):\n",
    "    word_proportions_df = s.load_object('english_word_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get words from the Wordle JavaScript\n",
    "    if s.pickle_exists('wordle_words_list'):\n",
    "        words_list = s.load_object('wordle_words_list')\n",
    "    else:\n",
    "\n",
    "        # Get words from the Wordle JavaScript\n",
    "        import requests\n",
    "\n",
    "        link = 'https://www.powerlanguage.co.uk/wordle/main.db1931a8.js'\n",
    "        f = requests.get(link)\n",
    "        commands_list = f.text.split(';')\n",
    "        list_str = commands_list[331].split(']')[0].split('[')[1]\n",
    "        words_list = eval(f'[{list_str}]')\n",
    "        s.store_objects(wordle_words_list=words_list)\n",
    "        \n",
    "    rows_list = [{'word_str': word_str, 'proportion_score': get_proportion_score(word_str)} for word_str in words_list]\n",
    "    word_proportions_df = pd.DataFrame(rows_list)\n",
    "    s.store_objects(english_word_frequencies_df=word_proportions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1a5d9-315a-4136-9fc9-7a7faf92c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_proportions_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b7266-269e-4978-93b4-e6538b27567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proportion_score_dict = word_proportions_df.set_index('word_str').proportion_score.to_dict()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "307a8a6e-86b1-4e11-a1f3-7d4e7aff9ae7",
   "metadata": {},
   "source": [
    "\n",
    "if s.pickle_exists('english_word_frequencies_df'):\n",
    "    word_proportions_df = s.load_object('english_word_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get words from the word list\n",
    "    if s.pickle_exists('glove_english_five_letter_words_list'):\n",
    "        words_list = s.load_object('glove_english_five_letter_words_list')\n",
    "    else:\n",
    "        \n",
    "        # Get words from GloVe: Global Vectors for Word Representation\n",
    "        import re\n",
    "        \n",
    "        words_list = []\n",
    "        file_path = r'D:\\Documents\\GitHub\\job-hunting\\data\\6B\\glove.6B.300d.txt'\n",
    "        az_regex = re.compile('[^a-z]')\n",
    "        with open(file_path, encoding='utf8') as infile:\n",
    "            for line in infile:\n",
    "                word_str = line.split()[0]\n",
    "                if (len(word_str) == 5) and not az_regex.search(word_str):\n",
    "                    words_list.append(word_str)\n",
    "        \n",
    "        words_list.remove('aerio')\n",
    "        words_list.remove('ioane')\n",
    "        words_list.remove('eonia')\n",
    "        words_list.remove('sunol')\n",
    "        words_list.remove('solun')\n",
    "        words_list.remove('skuld')\n",
    "        s.store_objects(glove_english_five_letter_words_list=words_list)\n",
    "    rows_list = [{'word_str': word_str, 'proportion_score': get_proportion_score(word_str)} for word_str in words_list]\n",
    "    word_proportions_df = pd.DataFrame(rows_list)\n",
    "    s.store_objects(english_word_frequencies_df=word_proportions_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b276b57-2ae0-4c93-96bf-bb0a4d1a5aec",
   "metadata": {},
   "source": [
    "\n",
    "if s.pickle_exists('popular_english_five_letter_words_list'):\n",
    "    words_list = s.load_object('popular_english_five_letter_words_list')\n",
    "else:\n",
    "    %run ../load_magic/soup.py\n",
    "\n",
    "    file_path = '../data/html/five_letter_words.html'\n",
    "    page_soup = get_page_soup(file_path)\n",
    "    words_list = []\n",
    "    for word_li in page_soup.select('li'):\n",
    "        word_str = word_li.text.lower()\n",
    "        words_list.append(word_str)\n",
    "    s.store_objects(popular_english_five_letter_words_list=words_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d71f6c15-e4c7-46d3-8ddd-e29644d9d536",
   "metadata": {},
   "source": [
    "\n",
    "if s.pickle_exists('english_letter_frequencies_df'):\n",
    "    letter_proportions_df = s.load_object('english_letter_frequencies_df')\n",
    "else:\n",
    "    \n",
    "    # Get proportions from cryptography web page\n",
    "    %run ../load_magic/dataframes.py\n",
    "\n",
    "    url = 'https://www3.nd.edu/~busiforc/handouts/cryptography/letterfrequencies.html'\n",
    "    dfs_list = get_page_tables(url, verbose=True)\n",
    "    letter_proportions_df = dfs_list[2].copy()\n",
    "    left_columns_list = [0, 1, 2]\n",
    "    left_df = letter_proportions_df[left_columns_list].rename(columns={0: 'letter_char', 1: 'frequency', 2: 'proportion'})\n",
    "    right_columns_list = [3, 4, 5]\n",
    "    right_df = letter_proportions_df[right_columns_list].rename(columns={3: 'letter_char', 4: 'frequency', 5: 'proportion'})\n",
    "    letter_proportions_df = pd.concat([left_df, right_df])\n",
    "    letter_proportions_df.letter_char = letter_proportions_df.letter_char.map(lambda x: x.lower())\n",
    "    def f(proportion):\n",
    "        if proportion == '(1)':\n",
    "            proportion = 1.0\n",
    "        else:\n",
    "            proportion = float(proportion)\n",
    "\n",
    "        return proportion\n",
    "    letter_proportions_df.proportion = letter_proportions_df.proportion.map(f)\n",
    "    s.store_objects(english_letter_frequencies_df=letter_proportions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff26a0-9736-401c-b115-e1aab7f4723e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
