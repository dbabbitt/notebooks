{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\ipynb\\Job Hunting Data Exploration.ipynb\n",
      "['s.attempt_to_pickle', 's.data_csv_folder', 's.data_folder', 's.encoding_type', 's.load_csv', 's.load_dataframes', 's.load_object', 's.save_dataframes', 's.saves_csv_folder', 's.saves_folder', 's.saves_pickle_folder', 's.store_objects']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Config', 'CountVectorizer', 'In', 'Out', 'RandomForestClassifier', 'SequenceMatcher', 'Storage', 'TfidfTransformer', '_', '__', '___', '__builtin__', '__builtins__', '__doc__', '__loader__', '__name__', '__nonzero__', '__package__', '__spec__', '_dh', '_i', '_i1', '_ih', '_ii', '_iii', '_oh', 'basic_quals_dict', 'check_4_doubles', 'check_for_typos', 'conjunctify_list', 'copyfile', 'csv', 'encoding', 'exit', 'get_classifier', 'get_data_structs_dataframe', 'get_datastructure_prediction', 'get_dir_tree', 'get_git_lfs_track_commands', 'get_importances', 'get_input_sample', 'get_ipython', 'get_module_version', 'get_notebook_path', 'get_specific_gitignore_files', 'get_struct_name', 'humanize_bytes', 'hunting_df', 'ipykernel', 'json', 'jupyter_config_dir', 'notebook_path', 'notebookapp', 'np', 'os', 'pd', 'pickle', 'preprocess_data', 'print_all_files_ending_starting_with', 'print_all_files_ending_with', 'print_all_files_starting_with', 'quit', 're', 'remove_empty_folders', 's', 'similar', 'subprocess', 'sys', 'time', 'urllib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "%run ../../load_magic/paths.py\n",
    "%run ../../load_magic/lists.py\n",
    "%run ../../load_magic/environment.py\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "%pprint\n",
    "\n",
    "notebook_path = get_notebook_path()\n",
    "print(notebook_path)\n",
    "\n",
    "s = Storage()\n",
    "print(['s.{}'.format(fn) for fn in dir(s) if not fn.startswith('_')])\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Needed extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_loc_computation(row_index, quals_list, basic_quals_dict):\n",
    "    print()\n",
    "    numerator_str_list = []\n",
    "    for qual_str in quals_list:\n",
    "        if qual_str in basic_quals_dict:\n",
    "            numerator_str_list.append(str(basic_quals_dict[qual_str]))\n",
    "        else:\n",
    "            numerator_str_list.append('000')\n",
    "    numerator_str = '+'.join(numerator_str_list)\n",
    "    print(\"hunting_df.loc[{}, 'percent_fit'] = ({})/{}\".format(row_index, numerator_str, len(quals_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions_and_counts(prediction_list, quals_list):\n",
    "    qual_count = 0\n",
    "    prediction_str = ''\n",
    "    for pred_array, qual_str in zip(prediction_list, quals_list):\n",
    "        prediction = pred_array[1]\n",
    "        prediction_str += '\\n{} {}'.format(prediction, qual_str)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return prediction_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_quals_str(prediction_list, quals_list, basic_quals_dict):\n",
    "    qual_count = 0\n",
    "    quals_str = ''\n",
    "    for pred_array, (i, qual_str) in zip(prediction_list, enumerate(quals_list)):\n",
    "        if qual_str in basic_quals_dict:\n",
    "            formatted_str = '\\nquals_list[{}] = \"{}\" ({})'\n",
    "        else:\n",
    "            formatted_str = '\\n*quals_list[{}] = \"{}\" ({})'\n",
    "        prediction = pred_array[1]\n",
    "        quals_str += formatted_str.format(i, qual_str, prediction)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return quals_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_fit_job(row_index, row_series, basic_quals_dict):\n",
    "    job_fitness = 0.0\n",
    "    job_description = row_series['Job Description']\n",
    "    quals_list = get_quals_list(job_description)\n",
    "    if len(quals_list):\n",
    "        prediction_list = list(predict_percent_fit(quals_list))\n",
    "        #prediction_str, qual_count = get_predictions_and_counts(prediction_list, quals_list)\n",
    "        quals_str, qual_count = get_quals_str(prediction_list, quals_list, basic_quals_dict)\n",
    "        job_fitness = qual_count/len(prediction_list)\n",
    "        if job_fitness > 0.8:\n",
    "            print('Basic Qualifications:{}'.format(quals_str))\n",
    "            #print(prediction_str)\n",
    "            print(job_fitness)\n",
    "            print_loc_computation(row_index, quals_list, basic_quals_dict)\n",
    "    \n",
    "    return quals_list, job_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_job_description(req_id):\n",
    "    match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "    job_description = hunting_df[match_series]['Job Description'].tolist()[0]\n",
    "    print(get_quals_list(job_description))\n",
    "    print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scanner_regex = re.compile(r'\\b[1-9a-zA-Z][0-9a-zA-Z]*( *[#\\+]{1,2}|\\b)')\n",
    "def regex_tokenizer(corpus):\n",
    "    \n",
    "    return [match.group() for match in re.finditer(scanner_regex, corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "\n",
    "printable_regex = re.compile('[^{}]+'.format(string.printable))\n",
    "def un_msword_ify(x):\n",
    "    msword_str = str(x)\n",
    "    msword_str = printable_regex.sub(r' ', msword_str).strip()\n",
    "    msword_str = re.sub(r'[^\\x00-\\x7f]+', r' ', msword_str).strip()\n",
    "    msword_str = re.sub(r' +', ' ', msword_str)\n",
    "    msword_str = re.sub(r'::', ':', msword_str)\n",
    "    msword_str = re.sub(r':$', '', msword_str)\n",
    "    msword_str = re.sub(r'^-', '', msword_str)\n",
    "    \n",
    "    return msword_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_list = ['Additional Qualifications?', 'Nice If You Have', 'Nice if you have', 'Nice if You Have',\n",
    "          'Additional Preferred Qualifications', 'Nice if you Have', 'Additional qualifications', 'Nice to Have']\n",
    "a_str = '({}):?'.format('|'.join(a_list))\n",
    "def get_quals_list(job_description):\n",
    "    job_description = un_msword_ify(job_description)\n",
    "    basic_quals = ''\n",
    "    quals_list = []\n",
    "    items_list = re.split('(Key Role|The Challenge):', job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        job_description = items_list[-1].strip()\n",
    "    items_list = re.split('[\\r\\n]+(Basic Qualifications?|You Have|You have):?', job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        job_description = items_list[-1].strip()\n",
    "    items_list = re.split(a_str, job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        basic_quals = items_list[0].strip()\n",
    "    else:\n",
    "        items_list = re.split('(Clearance|Build Your Career):', job_description, 0)\n",
    "        basic_quals = items_list[0].strip()\n",
    "    if basic_quals != '':\n",
    "        quals_list = [un_msword_ify(q) for q in re.split('[\\r\\n]+', basic_quals, 0)]\n",
    "        quals_list = [x for x in quals_list if x != '']\n",
    "    \n",
    "    return quals_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "req_id = 'R0081541'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "print(hunting_df[match_series].shape[0])\n",
    "percent_fit = hunting_df.loc[match_series, 'percent_fit'].tolist()[0]\n",
    "percent_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Big Data', 'Big Data Management', 'Cloud', 'Containerization', 'Data Architecture', 'Database Access', 'Database Design', 'Database Management', 'Deep Learning', 'Domain Knowledge', 'Information Management', 'Machine Learning', 'Metadata Repository', 'Organizational Understanding', 'Peer-Reviewed Publications', 'Programming', 'Prototyping', 'Query Tools', 'Repository Management', 'Requirements Analysis', 'Statistics', 'Technical Troubleshooting', 'Technological Innovation', 'Technology Research', 'Thought Leadership']\n",
      "Big Data\n",
      "\n",
      "Big Data Management\n",
      "\n",
      "Cloud\n",
      "\n",
      "Containerization\n",
      "\n",
      "Data Architecture\n",
      "\n",
      "Database Access\n",
      "\n",
      "Database Design\n",
      "\n",
      "Database Management\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "Domain Knowledge\n",
      "\n",
      "Information Management\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Metadata Repository\n",
      "\n",
      "Organizational Understanding\n",
      "\n",
      "Peer-Reviewed Publications\n",
      "\n",
      "Programming\n",
      "\n",
      "Prototyping\n",
      "\n",
      "Query Tools\n",
      "\n",
      "Repository Management\n",
      "\n",
      "Requirements Analysis\n",
      "\n",
      "Statistics\n",
      "\n",
      "Technical Troubleshooting\n",
      "\n",
      "Technological Innovation\n",
      "\n",
      "Technology Research\n",
      "\n",
      "Thought Leadership\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_job_description('R0081541')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5085</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hiring Manager</th>\n",
       "      <td>Data Scientist, Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Management Level</th>\n",
       "      <td>USA, MA, Boston (150 S Huntington Ave)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMT</th>\n",
       "      <td>HEALTH IMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition</th>\n",
       "      <td>R0081541 Data Scientist, Senior (Open)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Type</th>\n",
       "      <td>Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <td>Boston Cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time Type</th>\n",
       "      <td>2020-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting Title</th>\n",
       "      <td>Advanced Data Scientist/Researcher, Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Safi Recommendation</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recruiting Start Date</th>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Group</th>\n",
       "      <td>HEALTH ACCT GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition ID</th>\n",
       "      <td>R0081541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Type</th>\n",
       "      <td>Advanced Data Scientist/Researcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supervisory Organization</th>\n",
       "      <td>Supervisory Organization (Susmita Shrivastava ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearance Agency</th>\n",
       "      <td>Full time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location State/Province</th>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Furthest Stage</th>\n",
       "      <td>Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Manager</th>\n",
       "      <td>Susmita Shrivastava (592267)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location</th>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Description</th>\n",
       "      <td>Big Data\\n\\nBig Data Management\\n\\nCloud\\n\\nCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <td>CIVILIAN SERVICES GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Profile</th>\n",
       "      <td>Sold and Funded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family Group</th>\n",
       "      <td>Key Role:\\nProvide technical support for infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSO</th>\n",
       "      <td>Kimberly Rush (514249)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family</th>\n",
       "      <td>Advanced Data Scientist/Researcher, Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Status</th>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Title</th>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting</th>\n",
       "      <td>Data Scientist, Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location Country</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Required Clearance</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Recruiter</th>\n",
       "      <td>Emily Sylling (504033)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_fit</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_opportunity_application_emailed</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_remote_delivery</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manager_notes</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS Notes</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opportunity_application_email_date</th>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 5085\n",
       "Hiring Manager                                                 Data Scientist, Senior\n",
       "Management Level                               USA, MA, Boston (150 S Huntington Ave)\n",
       "IMT                                                                        HEALTH IMT\n",
       "Job Requisition                                R0081541 Data Scientist, Senior (Open)\n",
       "Job Requisition Type                                                        Associate\n",
       "Cluster                                                                Boston Cluster\n",
       "Time Type                                                                  2020-04-01\n",
       "Job Posting Title                       Advanced Data Scientist/Researcher, Associate\n",
       "Safi Recommendation                                                               NaN\n",
       "Recruiting Start Date                                                         Regular\n",
       "Account Group                                                       HEALTH ACCT GROUP\n",
       "Job Requisition ID                                                           R0081541\n",
       "Job Type                                           Advanced Data Scientist/Researcher\n",
       "Supervisory Organization            Supervisory Organization (Susmita Shrivastava ...\n",
       "Clearance Agency                                                            Full time\n",
       "Primary Location State/Province                              United States of America\n",
       "Furthest Stage                                                                 Review\n",
       "Resource Manager                                         Susmita Shrivastava (592267)\n",
       "Primary Location                                                        Massachusetts\n",
       "Job Description                     Big Data\\n\\nBig Data Management\\n\\nCloud\\n\\nCo...\n",
       "Group                                                         CIVILIAN SERVICES GROUP\n",
       "Job Profile                                                           Sold and Funded\n",
       "Job Family Group                    Key Role:\\nProvide technical support for infor...\n",
       "FSO                                                            Kimberly Rush (514249)\n",
       "Job Family                              Advanced Data Scientist/Researcher, Associate\n",
       "Job Requisition Status                                                           Open\n",
       "Business Title                                                             Technology\n",
       "Job Posting                                                    Data Scientist, Senior\n",
       "Primary Location Country                                                         None\n",
       "Required Clearance                                                               None\n",
       "Primary Recruiter                                              Emily Sylling (504033)\n",
       "percent_fit                                                                       0.4\n",
       "is_opportunity_application_emailed                                              False\n",
       "is_remote_delivery                                                                NaN\n",
       "manager_notes                                                                     NaN\n",
       "CS Notes                                                                          NaN\n",
       "opportunity_application_email_date                                                NaT"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hunting_df[match_series].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Manually note when the email has been sent\n",
    "req_id = 'R0071707'.strip()\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "date_str = '3/16/2020 11:58 AM'\n",
    "date_format = '%m/%d/%Y %H:%M %p'\n",
    "date_obj = datetime.strptime(date_str, date_format)\n",
    "print((datetime.now() - date_obj).days)\n",
    "hunting_df.loc[match_series, 'opportunity_application_email_date'] = pd.Timestamp(date_obj)\n",
    "s.store_objects(hunting_df=hunting_df)\n",
    "last_emailed_dict = s.load_object('last_emailed_dict')\n",
    "row_series = hunting_df.loc[match_series].iloc[0]\n",
    "hm_str = row_series['Hiring Manager']\n",
    "hm_email = clean_email(hm_str)\n",
    "pr_str = row_series['Primary Recruiter']\n",
    "pr_email = clean_email(pr_str)\n",
    "email_tuple = (hm_email, pr_email)\n",
    "print(email_tuple)\n",
    "for email in email_tuple:\n",
    "    if not email in last_emailed_dict:\n",
    "        last_emailed_dict[email] = pd.Timestamp(date_obj)\n",
    "s.store_objects(last_emailed_dict=last_emailed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Here's the managers and recruiters I have spammed in the last two weeks (and the last time I spammed them):\")\n",
    "emails_list = sorted(['{}: {}'.format(key, value.strftime('%B %d')) for key, value in last_emailed_dict.items()])\n",
    "print('\\n'.join(emails_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last_emailed_dict['Lee, David [USA] <544006@bah.com>'] = pd.Timestamp(date_obj)\n",
    "last_emailed_dict['Nida, Lori [USA] <594683@bah.com>'] = pd.Timestamp(date_obj)\n",
    "s.store_objects(last_emailed_dict=last_emailed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id_list = ['R0080204', 'R0081237', 'R0066222', 'R0081079', 'R0067642', 'R0074472', 'R0081024', 'R0080962', 'R0067023', 'R0079762',\n",
    "               'R0080544', 'R0080214', 'R0080461', 'R0080459', 'R0080211', 'R0072131', 'R0079065', 'R0077973', 'R0079049', 'R0059547', 'R0078739',\n",
    "               'R0079025', 'R0078760', 'R0078971', 'R0076252', 'R0074969', 'R0074087', 'R0072036', 'R0078549', 'R0078514', 'R0077918', 'R0078696',\n",
    "               'R0077836', 'R0076794', 'R0072831', 'R0076196', 'R0076889', 'R0076249', 'R0066218', 'R0076197', 'R0076199', 'R0072789']\n",
    "percent_fit_list = []\n",
    "for req_id in req_id_list:\n",
    "    match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "    if hunting_df[match_series].shape[0] == 1:\n",
    "        percent_fit = hunting_df.loc[match_series, 'percent_fit'].tolist()[0]\n",
    "        if percent_fit >= 0.8:\n",
    "            percent_fit_list.append(req_id)\n",
    "match_series = (hunting_df['Job Requisition ID'].isin(percent_fit_list))\n",
    "print_emails(match_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_emails(match_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id = 'R0080544'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'manager_notes'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(hunting_df.groupby('is_opportunity_application_emailed').count().T.max().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(hunting_df.groupby('is_remote_delivery').count().T.max().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    if ('RAZOR' in x):\n",
    "        match = True\n",
    "    else:\n",
    "        match = False\n",
    "    \n",
    "    return match\n",
    "match_series = hunting_df['Job Description'].map(f)\n",
    "if hunting_df[match_series].shape[0] > 0:\n",
    "    print(hunting_df[match_series].shape)\n",
    "    print(hunting_df[match_series].groupby('Required Clearance').count().T.max().sort_values(ascending=False))\n",
    "    hunting_df[match_series].head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df['is_remote_delivery'] == True) & (hunting_df['is_opportunity_application_emailed'] == True)\n",
    "columns_list = ['Management Level', 'Job Posting Title', 'Job Profile', 'Job Family Group', 'Primary Location',\n",
    "                'percent_fit']\n",
    "df = hunting_df[match_series][columns_list].copy()\n",
    "df.columns = ['Level', 'Title', 'Profile', 'Group', 'Location', 'Fit']\n",
    "df.sort_values(['Fit', 'Title'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id = 'R0079210'\n",
    "print_job_description(req_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    if re.search(r'\\bIAT\\b', str(x)):\n",
    "        results = True\n",
    "    else:\n",
    "        results = False\n",
    "    \n",
    "    return results\n",
    "\n",
    "match_series = basic_quals_df.qualification_str.map(f)\n",
    "for qual in basic_quals_df[match_series].qualification_str.tolist():\n",
    "    print('•\\t{} = {}'.format(qual, basic_quals_dict[qual]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_dict['Ability to operate independently and manage staff'] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id = 'R0079210'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "print(hunting_df[match_series]['percent_fit'].tolist())\n",
    "for row_index, row_series in hunting_df[match_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.loc[504, 'percent_fit'] = (1+1+1+1+0+1+1)/7\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id_list = ['R0073564', 'R0073583', 'R0073584', 'R0073585', 'R0073586']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df[match_series].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.index == 437)\n",
    "print(hunting_df[match_series]['Job Description'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.percent_fit >= 0.0)\n",
    "print(hunting_df[~match_series].sample(1)['Job Description'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(['hunting_df.{}'.format(fn) for fn in dir(hunting_df) if 'dup' in fn.lower()])\n",
    "match_series = hunting_df.duplicated(subset='Job Requisition ID', keep=False)\n",
    "print(hunting_df[match_series].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                'Job Posting Title', 'Recruiting Start Date', 'Account Group', 'Job Requisition ID', 'Job Type',\n",
    "                'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                'Resource Manager', 'Primary Location', 'Job Description', 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                'Required Clearance', 'Primary Recruiter']\n",
    "hunting_df = hunting_df.drop_duplicates(subset=columns_list, ignore_index=True)\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_list = hunting_df[match_series].index.tolist()\n",
    "first = idx_list[0]\n",
    "second = idx_list[1]\n",
    "columns_list = []\n",
    "for column_name in hunting_df.columns:\n",
    "    if hunting_df.loc[first, column_name] == hunting_df.loc[second, column_name]:\n",
    "        columns_list.append(column_name)\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = hunting_df.percent_fit.isnull()\n",
    "print(hunting_df[match_series].shape)\n",
    "req_id = hunting_df.loc[481, 'Job Requisition ID']\n",
    "print_job_description(req_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(['{}'.format(fn) for fn in hunting_df.columns if 'req' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_regex = re.compile(r'([^0-9A-Za-z\\+ \\/)(:,]+)-')\n",
    "for old_key in basic_quals_dict.keys():\n",
    "    match_obj = key_regex.search(old_key)\n",
    "    if match_obj:\n",
    "        print('\"{}\": {}'.format(match_obj.group(1), old_key))\n",
    "        #new_key = re.sub('^[?â-]+', '', old_key)\n",
    "        #print(new_key)\n",
    "        #basic_quals_dict[new_key] = basic_quals_dict.pop(old_key)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_regex = re.compile(r'\\s+$')\n",
    "old_key_list = basic_quals_dict.copy().keys()\n",
    "for old_key in old_key_list:\n",
    "    match_obj = key_regex.search(old_key)\n",
    "    if match_obj:\n",
    "        #print('\"{}\": {}'.format(match_obj.group(1), old_key))\n",
    "        new_key = re.sub(r'\\s+$', '', old_key)\n",
    "        #print(new_key)\n",
    "        basic_quals_dict[new_key] = basic_quals_dict.pop(old_key)\n",
    "        #print(old_key)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Run these to clear out the dataset for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                'Job Posting Title', 'Safi Recommendation', 'Recruiting Start Date', 'Account Group', 'Job Requisition ID',\n",
    "                'Job Type', 'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                'Resource Manager', 'Primary Location', 'Job Description', 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                'Required Clearance', 'Primary Recruiter', 'percent_fit', 'is_opportunity_application_emailed', 'opportunity_application_email_date',\n",
    "                'is_remote_delivery', 'manager_notes', 'CS Notes']\n",
    "hunting_df = pd.DataFrame([], columns=columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "[qual_str for qual_str in basic_quals_dict if 'python' in qual_str.lower()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "old_key = '3 years of experience with developing software in object-oriented and scripting languages, including MATLAB, C/C++, and Python'\n",
    "if old_key in basic_quals_dict:\n",
    "    basic_quals_dict.pop(old_key)\n",
    "req_id_list = ['R0069317']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'percent_fit'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Emailing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import win32com.client\n",
    "\n",
    "outlook = win32com.client.Dispatch('Outlook.Application').GetNamespace('MAPI')\n",
    "print(['outlook.{}'.format(fn) for fn in dir(outlook) if not fn.startswith('_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Manually score unscored jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.loc[436, 'percent_fit'] = (0+1+1+1+1+1)/6\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Study of the Safi recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "match_series = (hunting_df['Safi Recommendation'] == 1)\n",
    "[c[10:100].strip() for c in random.choices(population=hunting_df[match_series]['Job Description'].unique(), k=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(hunting_df=hunting_df)\n",
    "match_series = (hunting_df['Safi Recommendation'] == 1)\n",
    "hunting_df[match_series]['Primary Location State/Province'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Requisition'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Cluster'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Family'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Account Group'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Resource Manager'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Requisition Type'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Posting'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Hiring Manager'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['IMT'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Required Clearance'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Job Profile'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Management Level'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Clearance Agency'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Group'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Job Profile'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[cn for cn in columns_list if 'loca' in cn.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Primary Location'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Primary Recruiter'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Initial dataframe creation (don't run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting'\n",
    "file_name = 'Copy of Reqs Babbitt Applied to_Need Follow Up.3.19.2020.xlsx'\n",
    "file_path = os.path.join(hunting_dir, file_name)\n",
    "safi_df = pd.read_excel(file_path)\n",
    "hunting_df['CS Notes'] = ''\n",
    "for row_index, row_series in safi_df.iterrows():\n",
    "    req_id = row_series['Job Requisition ID']\n",
    "    cs_notes = row_series['CS Notes']\n",
    "    match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "    hunting_df.loc[match_series, 'CS Notes'] = cs_notes\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.is_opportunity_application_emailed == True) & hunting_df.is_remote_delivery.isnull()\n",
    "s.save_dataframes(unresponses_df=hunting_df[match_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = hunting_df.manager_notes.isnull()\n",
    "hunting_df.loc[match_series, 'manager_notes'] = ''\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for old_key in basic_quals_dict.keys():\n",
    "    basic_quals_dict[re.sub(r':$', '', str(old_key))] = basic_quals_dict.pop(old_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.is_for_university_recruiting == 1)\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                'Job Posting Title', 'Safi Recommendation', 'Recruiting Start Date', 'Account Group', 'Job Requisition ID',\n",
    "                'Job Type', 'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                'Resource Manager', 'Primary Location', 'Job Description', 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                'Required Clearance', 'Primary Recruiter', 'percent_fit', 'is_opportunity_application_emailed', 'opportunity_application_email_date', 'is_remote_delivery']\n",
    "hunting_df = hunting_df[columns_list]\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting'\n",
    "columns_list = []\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    #path = root.split(os.sep)\n",
    "    #print((len(path)-1) * '---', os.path.basename(root))\n",
    "    for file in files:\n",
    "        #print(len(path) * '---', file)\n",
    "        if file.endswith('.csv'):\n",
    "            print(file)\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, encoding='iso8859-1')\n",
    "                columns_list = list(set(columns_list) | set(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df = pd.DataFrame([], columns=columns_list)\n",
    "\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, encoding='iso8859-1')\n",
    "                hunting_df = pd.concat([hunting_df, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "command_str = '{sys.executable} -m pip install pyOutlook'.format(sys=sys)\n",
    "print(command_str)\n",
    "!{command_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Flag setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Posting', 'Job Requisition', 'Job Requisition ID',\n",
       "       'Job Requisition Status', 'Furthest Stage', 'Supervisory Organization',\n",
       "       'Group', 'Account Group', 'IMT', 'Cluster', 'Primary Recruiter',\n",
       "       'Resource Manager', 'Hiring Manager', 'Job Posting Title',\n",
       "       'Job Profile', 'Job Requisition Type', 'Management Level',\n",
       "       'Primary Location', 'Primary Location State/Province',\n",
       "       'Primary Location Country', 'Required Clearance', 'Clearance Agency',\n",
       "       'Time Type', 'Recruiting Start Date', 'Job Type', 'Job Family',\n",
       "       'Business Title', 'Job Family Group', 'Job Description',\n",
       "       'Job Profile Skills', 'percent_fit',\n",
       "       'is_opportunity_application_emailed',\n",
       "       'opportunity_application_email_date', 'is_remote_delivery',\n",
       "       'manager_notes', 'CS Notes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hunting_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = 'Primary Recruiter'\n",
    "last_name = 'Sallis'.lower()\n",
    "first_name = 'Michael'.lower()\n",
    "\n",
    "def f(x):\n",
    "    x = str(x).lower()\n",
    "    \n",
    "    return (first_name in x) and (last_name in x)\n",
    "\n",
    "column_name = 'Hiring Manager'\n",
    "last_name = 'Arunachalam'.lower()\n",
    "first_name = 'Siva'.lower()\n",
    "\n",
    "def g(x):\n",
    "    x = str(x).lower()\n",
    "    \n",
    "    return (first_name in x) and (last_name in x)\n",
    "\n",
    "match_series = hunting_df[column_name].map(f) & hunting_df[column_name].map(g)\n",
    "req_id_list = hunting_df[match_series]['Job Requisition ID'].tolist()\n",
    "formatted_str = 'Thanks for the feedback. I have marked all the reqs you are associated with ({}).'\n",
    "print(formatted_str.format(conjunctify_list(req_id_list)))\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Currently all our roles are local to the DC Metro Area.\n",
    "req_id = 'R0079210'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "location = hunting_df[match_series]['Primary Location'].tolist()[0]\n",
    "manager = hunting_df[match_series]['Hiring Manager'].tolist()[0]\n",
    "match_series = (hunting_df['Primary Location'] == location)\n",
    "print('Is she talking about the {} reqs in her location?'.format(hunting_df[match_series].shape[0]))\n",
    "match_series = (hunting_df['Hiring Manager'] == manager)\n",
    "print('Is she talking about the {} reqs she is managing?'.format(hunting_df[match_series].shape[0]))\n",
    "match_series = (hunting_df['Primary Location'] == location) & (hunting_df['Hiring Manager'] == manager)\n",
    "formatted_str = 'Thank you for the feedback. I am assuming you are talking about the {} reqs you are managing at your location ({}).'\n",
    "\n",
    "# Set remote delivery for this list of jobs\n",
    "req_id_list = hunting_df[match_series]['Job Requisition ID'].tolist()\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)\n",
    "print(formatted_str.format(hunting_df[match_series].shape[0], conjunctify_list(req_id_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = 'Hiring Manager'\n",
    "last_name = 'Cofrancesco'.lower()\n",
    "first_name = 'Elaine'.lower()\n",
    "\n",
    "def f(x):\n",
    "    x = str(x).lower()\n",
    "    \n",
    "    return (first_name in x) and (last_name in x)\n",
    "\n",
    "match_series = hunting_df[column_name].map(f)\n",
    "req_id_list = hunting_df[match_series]['Job Requisition ID'].tolist()\n",
    "formatted_str = 'Thanks for the feedback. Does this include all the reqs you are associated with ({})?'\n",
    "print(formatted_str.format(conjunctify_list(req_id_list)))\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_name = 'Hiring Manager'\n",
    "last_name = 'Jendzejec'.lower()\n",
    "first_name = 'Alexander'.lower()\n",
    "\n",
    "def f(x):\n",
    "    x = str(x).lower()\n",
    "    \n",
    "    return (first_name in x) and (last_name in x)\n",
    "\n",
    "match_series = hunting_df[column_name].map(f)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_name = 'Hiring Manager'\n",
    "last_name = 'ferraro'\n",
    "first_name = 'mike'\n",
    "\n",
    "def f(x):\n",
    "    x = str(x).lower()\n",
    "    \n",
    "    return (first_name in x) and (last_name in x)\n",
    "\n",
    "match_series = hunting_df[column_name].map(f)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set remote delivery for this list of jobs\n",
    "req_id_list = ['R0072627', 'R0072630', 'R0072685', 'R0072688', 'R0072699', 'R0072700', 'R0078787', 'R0078792', 'R0078793', 'R0072670',\n",
    "               'R0072672', 'R0078798', 'R0078799']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set remote delivery for this list of jobs\n",
    "req_id_list = ['R0073564', 'R0073583', 'R0073584', 'R0073585', 'R0073586']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = True\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set university recruiting for this job\n",
    "req_id = 'R0066388'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_for_university_recruiting'] = 1\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note you can't do this job from home\n",
    "req_id = 'R0064764'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note you can't do this job from home\n",
    "hunting_df.loc[83, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.index == 2616)\n",
    "hunting_df.loc[match_series, 'is_for_university_recruiting'] = 1\n",
    "hunting_df.loc[match_series, 'percent_fit'] = 0.0\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
