{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "%run ../../load_magic/paths.py\n",
    "%run ../../load_magic/lists.py\n",
    "%run ../../load_magic/environment.py\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "%pprint\n",
    "\n",
    "notebook_path = get_notebook_path()\n",
    "print(notebook_path)\n",
    "\n",
    "s = Storage()\n",
    "print(['s.{}'.format(fn) for fn in dir(s) if not fn.startswith('_')])\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Needed extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Email prep\n",
    "subject_str = '{}% fit: Internal Candidate, Dave Babbitt, for {}'\n",
    "concerns_str = 'One important question I have is if the work can be supported remotely or if this position is available for remote delivery '\n",
    "concerns_str += '(or something equivalent).'\n",
    "concerns_str += \" I don't want to move my family out of New England.\"\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "emails_dir = os.path.join(s.saves_folder, 'emails')\n",
    "os.makedirs(name=emails_dir, exist_ok=True)\n",
    "name_regex = re.compile(r'^([^(]+) \\(\\d+\\)\"')\n",
    "def clean_email(email_str):\n",
    "    match_obj = name_regex.search(email_str)\n",
    "    if match_obj:\n",
    "        email_str = match_obj.group(1)\n",
    "    names_list = re.split(r'\\s+', email_str, 0)\n",
    "    if len(names_list) >= 2:\n",
    "        first_name = names_list[0]\n",
    "        last_name = names_list[1]\n",
    "        email_str = '{}, {} [USA] <{}_{}@bah.com>'.format(last_name, first_name, last_name.lower(), first_name.lower())\n",
    "    \n",
    "    return email_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_percent_fit(row_series):\n",
    "    percent_fit = row_series['percent_fit']\n",
    "    if str(percent_fit) == 'nan':\n",
    "        percent_fit = 0\n",
    "    percent_fit = int(percent_fit*100)\n",
    "    \n",
    "    return percent_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_loc_computation(row_index, quals_list, basic_quals_dict):\n",
    "    print()\n",
    "    numerator_str_list = []\n",
    "    for qual_str in quals_list:\n",
    "        if qual_str in basic_quals_dict:\n",
    "            numerator_str_list.append(str(basic_quals_dict[qual_str]))\n",
    "        else:\n",
    "            numerator_str_list.append('000')\n",
    "    numerator_str = '+'.join(numerator_str_list)\n",
    "    print(\"hunting_df.loc[{}, 'percent_fit'] = ({})/{}\".format(row_index, numerator_str, len(quals_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions_and_counts(prediction_list, quals_list):\n",
    "    qual_count = 0\n",
    "    prediction_str = ''\n",
    "    for pred_array, qual_str in zip(prediction_list, quals_list):\n",
    "        prediction = pred_array[1]\n",
    "        prediction_str += '\\n{} {}'.format(prediction, qual_str)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return prediction_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_quals_str(prediction_list, quals_list, basic_quals_dict):\n",
    "    qual_count = 0\n",
    "    quals_str = ''\n",
    "    for pred_array, (i, qual_str) in zip(prediction_list, enumerate(quals_list)):\n",
    "        if qual_str in basic_quals_dict:\n",
    "            formatted_str = '\\nquals_list[{}] = \"{}\" ({})'\n",
    "        else:\n",
    "            formatted_str = '\\n*quals_list[{}] = \"{}\" ({})'\n",
    "        prediction = pred_array[1]\n",
    "        quals_str += formatted_str.format(i, qual_str, prediction)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return quals_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_fit_job(row_index, row_series, basic_quals_dict):\n",
    "    job_fitness = 0.0\n",
    "    job_description = row_series['Job Description']\n",
    "    quals_list = get_quals_list(job_description)\n",
    "    if len(quals_list):\n",
    "        prediction_list = list(predict_percent_fit(quals_list))\n",
    "        #prediction_str, qual_count = get_predictions_and_counts(prediction_list, quals_list)\n",
    "        quals_str, qual_count = get_quals_str(prediction_list, quals_list, basic_quals_dict)\n",
    "        job_fitness = qual_count/len(prediction_list)\n",
    "        if job_fitness > 0.8:\n",
    "            print('Basic Qualifications:{}'.format(quals_str))\n",
    "            #print(prediction_str)\n",
    "            print(job_fitness)\n",
    "            print_loc_computation(row_index, quals_list, basic_quals_dict)\n",
    "    \n",
    "    return quals_list, job_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qual_sum(qual_str):\n",
    "    results = '\"{}\"'.format(qual_str)\n",
    "    if qual_str in basic_quals_dict:\n",
    "        results = basic_quals_dict[qual_str]\n",
    "    else:\n",
    "        results = predict_percent_fit([qual_str])[0][1]\n",
    "        if results > 0.5:\n",
    "            results = 1.0\n",
    "        else:\n",
    "            results = 0.0\n",
    "    \n",
    "    return str(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_job_description(req_id):\n",
    "    match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "    job_description = hunting_df[match_series]['Job Description'].tolist()[0]\n",
    "    print(get_quals_list(job_description))\n",
    "    print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scanner_regex = re.compile(r'\\b[1-9a-zA-Z][0-9a-zA-Z]*( *[#\\+]{1,2}|\\b)')\n",
    "def regex_tokenizer(corpus):\n",
    "    \n",
    "    return [match.group() for match in re.finditer(scanner_regex, corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_list = ['Additional Qualifications?', 'Nice If You Have', 'Nice if you have', 'Nice if You Have',\n",
    "          'Additional Preferred Qualifications', 'Nice if you Have', 'Additional qualifications']\n",
    "a_str = '({}):?'.format('|'.join(a_list))\n",
    "def get_quals_list(job_description):\n",
    "    job_description = re.sub('Â', '', job_description)\n",
    "    basic_quals = ''\n",
    "    quals_list = []\n",
    "    items_list = re.split('(Key Role|The Challenge):', job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        job_description = items_list[-1].strip()\n",
    "    items_list = re.split('[\\r\\n]+(Basic Qualifications?|You Have|You have):?', job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        job_description = items_list[-1].strip()\n",
    "    items_list = re.split(a_str, job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        basic_quals = items_list[0].strip()\n",
    "    else:\n",
    "        items_list = re.split('(Clearance|Build Your Career):', job_description, 0)\n",
    "        basic_quals = items_list[0].strip()\n",
    "    if basic_quals != '':\n",
    "        quals_list = [re.sub(r'â¯', ' ', q) for q in re.split('[\\r\\n]+', basic_quals, 0)]\n",
    "        quals_list = [re.sub(r'^[?â-]+', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'[â-]+$', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '-', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '`', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '`', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '`', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(u'\\\\xa0', u' ', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'\\s+$', '', x) for x in quals_list]\n",
    "        quals_list = [x for x in quals_list if x != '']\n",
    "    \n",
    "    return quals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_emails(match_series):\n",
    "    for file_name in os.listdir(emails_dir):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(emails_dir, file_name)\n",
    "            os.remove(file_path)\n",
    "    for row_index, row_series in hunting_df[match_series].sort_values('percent_fit', ascending=False).iterrows():\n",
    "        req_str = row_series['Job Requisition']\n",
    "        percent_fit = get_percent_fit(row_series)\n",
    "        sents_list = ['I’m submitting my resume for {}.'.format(req_str),\n",
    "                      'I’ve reviewed the basic qualifications and believe I’m a good fit for this project.',\n",
    "                      'Below is a breakdown of the requirements and the amount of experience I have with each.',\n",
    "                      'I’m available at your convenience to discuss my qualifications and look forward to hearing from you.']\n",
    "        blurb_str = ' '.join(sents_list)\n",
    "        hm_str = row_series['Hiring Manager']\n",
    "        pr_str = row_series['Primary Recruiter']\n",
    "        job_description = row_series['Job Description']\n",
    "        quals_list = get_quals_list(job_description)\n",
    "        quals_str = '\\n•\\t' + '\\n•\\t'.join(quals_list)\n",
    "        file_path = os.path.join(emails_dir, '{}_email.txt'.format(row_series['Job Requisition ID'].strip()))\n",
    "        if not os.path.isfile(file_path):\n",
    "            with open(file_path, 'w', encoding=s.encoding_type) as io_wrapper:\n",
    "                print('', file=io_wrapper)\n",
    "                print('To: {}; {}'.format(clean_email(hm_str), clean_email(pr_str)), file=io_wrapper)\n",
    "                print('CC: Safi, Claudia [USA] <safi_claudia@bah.com>; Borrelli, Bill [USA] <Borrelli_Bill@bah.com>', file=io_wrapper)\n",
    "                print(subject_str.format(percent_fit, req_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Dear {},'.format(hm_str.split(' ')[0]), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('{}'.format(blurb_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Basic Qualifications:{}'.format(quals_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print(concerns_str, file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Attached: Dave_Babbitt_Resume_for_{}.pdf'.format('_'.join(re.split(r'[ \\\\\\/:\\*\\?\"><\\|]+', req_str, 0))),\n",
    "                      file=io_wrapper)\n",
    "            !\"{text_editor_path}\" \"{os.path.abspath(file_path)}\"\n",
    "    !start %windir%\\explorer.exe \"{os.path.abspath(emails_dir)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add new ORR to the hunting dataframe\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "jd_cn = 'Job Description'\n",
    "reqid_cn = 'Job Requisition ID'\n",
    "dupe_columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                     'Job Posting Title', 'Recruiting Start Date', 'Account Group', reqid_cn, 'Job Type',\n",
    "                     'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                     'Resource Manager', 'Primary Location', jd_cn, 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                     'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                     'Required Clearance', 'Primary Recruiter']\n",
    "columns_list = ['Job Posting', 'Job Requisition', reqid_cn, 'Job Requisition Status', 'Furthest Stage',\n",
    "                'Supervisory Organization', 'Group', 'Account Group', 'IMT', 'Cluster', 'FSO', 'Primary Recruiter',\n",
    "                'Resource Manager', 'Hiring Manager', 'Job Posting Title', 'Job Profile', 'Job Requisition Type',\n",
    "                'Management Level', 'Primary Location', 'Primary Location State/Province', 'Primary Location Country',\n",
    "                'Required Clearance', 'Clearance Agency', 'Time Type', 'Recruiting Start Date', 'Job Type', 'Job Family',\n",
    "                'Business Title', 'Job Family Group', jd_cn]\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting\\csv'\n",
    "def add_new_orr(file_name, hunting_df):\n",
    "    file_path = os.path.join(hunting_dir, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        !\"{text_editor_path}\" \"{os.path.abspath(file_path)}\"\n",
    "        df = pd.read_csv(file_path, header=0, skiprows=0, encoding='iso8859-1')\n",
    "        df.columns = columns_list\n",
    "        req_id_list = hunting_df[reqid_cn].unique().tolist()\n",
    "        match_series = (df[reqid_cn].isin(req_id_list))\n",
    "        hunting_df = pd.concat([hunting_df, df[~match_series]]).fillna({'is_opportunity_application_emailed': False})\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(u'\\\\xa0', u' ', x))\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(r'', \"'\", x))\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(r'', '—', x))\n",
    "        hunting_df = hunting_df.drop_duplicates(subset=dupe_columns_list, ignore_index=True)\n",
    "        hunting_df.reset_index(drop=True, inplace=True)\n",
    "        s.store_objects(hunting_df=hunting_df)\n",
    "        \n",
    "        return hunting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "def get_basic_quals(row_index):\n",
    "    match_series = (hunting_df.index == row_index)\n",
    "    for row_index, row_series in hunting_df[match_series].iterrows():\n",
    "        percent_fit = get_percent_fit(row_series)\n",
    "        job_description = row_series['Job Description']\n",
    "        quals_list = get_quals_list(job_description)\n",
    "        quals_str = get_quals_str(quals_list, basic_quals_dict)\n",
    "        if (quals_str != '') and (percent_fit == 0):\n",
    "            print('Basic Qualifications:{}'.format(quals_str))\n",
    "            print_loc_computation(row_index, quals_list, basic_quals_dict)\n",
    "    \n",
    "    return quals_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Create the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    \n",
    "    return 'python' in str(x).lower()\n",
    "\n",
    "match_series = hunting_df['Job Requisition Type'].isin(['Sold and Funded', 'Sold & Unfunded']) & hunting_df['Job Description'].map(f)\n",
    "match_series = match_series & (hunting_df.percent_fit >= 0.95) & ~hunting_df['is_opportunity_application_emailed']\n",
    "match_series = match_series & ~(hunting_df.is_remote_delivery == False)\n",
    "match_series = match_series & ~hunting_df['Required Clearance'].isin(['TS/SCI', 'TS/SCI w/CIP'])\n",
    "print(hunting_df[match_series].shape)\n",
    "print(hunting_df[match_series].groupby('Required Clearance').count().T.max().sort_values(ascending=False))\n",
    "hunting_df[match_series].head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_emails(match_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rebuild the datframe from the dictionary\n",
    "rows_list = [{'qualification_str': qualification_str, 'is_fit': is_fit} for qualification_str, is_fit in basic_quals_dict.items()]\n",
    "basic_quals_df = pd.DataFrame(rows_list)\n",
    "s.store_objects(basic_quals_df=basic_quals_df)\n",
    "\n",
    "# Re-transform the bag-of-words and tf-idf from the new manual scores\n",
    "sents_list = basic_quals_df.qualification_str.tolist()\n",
    "\n",
    "# Bag-of-words\n",
    "cv = CountVectorizer(lowercase=True, tokenizer=regex_tokenizer, token_pattern=r'\\b[1-9a-zA-Z][0-9a-zA-Z]*[#\\+]{0,2}', ngram_range=(1, 3))\n",
    "bow_matrix = cv.fit_transform(sents_list)\n",
    "s.store_objects(bq_cv_vocab=cv.vocabulary_)\n",
    "\n",
    "# Tf-idf, must get from BOW first\n",
    "tt = TfidfTransformer()\n",
    "tfidf_matrix = tt.fit_transform(bow_matrix)\n",
    "s.store_objects(bq_tt=tt)\n",
    "\n",
    "# Re-train the classifier\n",
    "X = tfidf_matrix.toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "fit_estimators_dict = s.load_object('fit_estimators_dict')\n",
    "#basic_quals_clf = RandomForestClassifier(n_estimators=997)\n",
    "#basic_quals_clf = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0, n_estimators=50, random_state=None)\n",
    "basic_quals_clf = fit_estimators_dict['LogisticRegression']\n",
    "basic_quals_clf.fit(X, y)\n",
    "s.store_objects(basic_quals_clf=basic_quals_clf)\n",
    "\n",
    "# Re-calibrate the inference engine\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "def predict_percent_fit(quals_list):\n",
    "    y_predict_proba = np.array([])\n",
    "    if len(quals_list):\n",
    "        X_test = bq_tt.transform(bq_cv.transform(quals_list)).toarray()\n",
    "        y_predict_proba = basic_quals_clf.predict_proba(X_test)\n",
    "    \n",
    "    return y_predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Look for a fit greater than 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "match_series = (hunting_df.percent_fit >= 0.0)\n",
    "for row_index, row_series in hunting_df[~match_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)\n",
    "    if job_fitness > 0.8:\n",
    "        if all(qual_str in basic_quals_dict for qual_str in quals_list):\n",
    "            hunting_df.loc[row_index, 'percent_fit'] = eval(' + '.join(map(qual_sum, quals_list))) / len(quals_list)\n",
    "            s.store_objects(hunting_df=hunting_df)\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        if len(quals_list):\n",
    "            hunting_df.loc[row_index, 'percent_fit'] = eval(' + '.join(map(qual_sum, quals_list))) / len(quals_list)\n",
    "            s.store_objects(hunting_df=hunting_df)\n",
    "print('{}/{} = {}% completed'.format(hunting_df[match_series].shape[0], hunting_df.shape[0],\n",
    "                                     int(100 * hunting_df[match_series].shape[0] / hunting_df.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[1]\n",
    "print(qualification_str)\n",
    "basic_quals_dict[qualification_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Rescore the quals dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "# Get the training data and models\n",
    "X = tfidf_matrix.toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "estimators_list = [AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0, n_estimators=50, random_state=None),\n",
    "                   BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
    "                                     n_estimators=10, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None,\n",
    "                                        max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=100, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None, learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "                                              max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                              min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                                              n_iter_no_change=None, presort='deprecated', random_state=None, subsample=1.0, tol=0.0001,\n",
    "                                              validation_fraction=0.1, verbose=0, warm_start=False),\n",
    "                   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features='auto',\n",
    "                                          max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                          min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "                                          oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                                      multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                                      warm_start=False),\n",
    "                   SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3,\n",
    "                       gamma='scale', kernel='rbf', max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001, verbose=False)]\n",
    "\n",
    "# Fit the data and add the duration and fitted models to lists\n",
    "fit_estimators_list = []\n",
    "training_durations_list = []\n",
    "for clf in estimators_list:\n",
    "    start_time = time.time()\n",
    "    fit_estimators_list.append(clf.fit(X, y))\n",
    "    stop_time = time.time()\n",
    "    training_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(estimators_list=fit_estimators_list, training_durations_list=training_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimators_list = s.load_object('estimators_list')\n",
    "inference_durations_list = []\n",
    "for clf in estimators_list:\n",
    "    clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "    basic_quals_df[clf_name] = np.nan\n",
    "    start_time = time.time()\n",
    "    for row_index, row_series in basic_quals_df.iterrows():\n",
    "        qualification_str = row_series.qualification_str\n",
    "        X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "        y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "        basic_quals_df.loc[row_index, clf_name] = y_predict_proba\n",
    "    stop_time = time.time()\n",
    "    inference_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(basic_quals_df=basic_quals_df, inference_durations_list=inference_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "s = Storage()\n",
    "\n",
    "estimators_list = s.load_object('estimators_list')\n",
    "clf = StackingClassifier(estimators=[(str(type(e)).split('.')[-1].split(\"'\")[0], e) for e in estimators_list],\n",
    "                         final_estimator=None, cv=None, stack_method='auto', n_jobs=None, passthrough=False, verbose=0)\n",
    "clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "basic_quals_df = s.load_object('basic_quals_df')\n",
    "basic_quals_df[clf_name] = np.nan\n",
    "fit_estimators_list = estimators_list.copy()\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "X = bq_tt.transform(bq_cv.transform(basic_quals_df.qualification_str.tolist())).toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "start_time = time.time()\n",
    "fit_estimators_list.append(clf.fit(X, y))\n",
    "stop_time = time.time()\n",
    "training_durations_list = s.load_object('training_durations_list')\n",
    "training_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(fit_estimators_list=fit_estimators_list, training_durations_list=training_durations_list)\n",
    "\n",
    "# Re-score the quals dataframe\n",
    "inference_durations_list = s.load_object('inference_durations_list')\n",
    "start_time = time.time()\n",
    "for row_index, row_series in basic_quals_df.iterrows():\n",
    "    qualification_str = row_series.qualification_str\n",
    "    X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "    y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "    basic_quals_df.loc[row_index, clf_name] = y_predict_proba\n",
    "stop_time = time.time()\n",
    "inference_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(basic_quals_df=basic_quals_df, inference_durations_list=inference_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf = VotingClassifier(estimators=[(str(type(e)).split('.')[-1].split(\"'\")[0], e) for e in estimators_list],\n",
    "                       voting='soft', weights=None, n_jobs=None, flatten_transform=True)\n",
    "clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "basic_quals_df[clf_name] = np.nan\n",
    "fit_estimators_list = s.load_object('fit_estimators_list')\n",
    "start_time = time.time()\n",
    "fit_estimators_list.append(clf.fit(X, y))\n",
    "stop_time = time.time()\n",
    "training_durations_list = s.load_object('training_durations_list')\n",
    "training_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(fit_estimators_list=fit_estimators_list, training_durations_list=training_durations_list)\n",
    "\n",
    "# Re-score the quals dataframe\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "inference_durations_list = s.load_object('inference_durations_list')\n",
    "start_time = time.time()\n",
    "for row_index, row_series in basic_quals_df.iterrows():\n",
    "    qualification_str = row_series.qualification_str\n",
    "    X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "    y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "    basic_quals_df.loc[row_index, clf_name] = y_predict_proba\n",
    "stop_time = time.time()\n",
    "inference_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(basic_quals_df=basic_quals_df, inference_durations_list=inference_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(basic_quals_df.columns.tolist())\n",
    "basic_quals_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import inspect\n",
    "\n",
    "metrics_list = ['accuracy_score', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision_score',\n",
    "                'balanced_accuracy_score', 'cohen_kappa_score', 'completeness_score', 'explained_variance_score',\n",
    "                'f1_score', 'fowlkes_mallows_score', 'homogeneity_score', 'jaccard_score', 'mutual_info_score',\n",
    "                'normalized_mutual_info_score', 'precision_score', 'r2_score', 'recall_score', 'roc_auc_score', 'v_measure_score']\n",
    "description_dict = {name: fn.__doc__.strip().split('\\n')[0] for name, fn in inspect.getmembers(sys.modules[__name__],\n",
    "                                                                                               inspect.isfunction) if name in metrics_list}\n",
    "for name, cls in inspect.getmembers(sys.modules[__name__], inspect.isclass):\n",
    "    if name in entropy_df.index:\n",
    "        description_dict[name] = cls.__doc__.strip().split('\\n')[0]\n",
    "s.store_objects(metrics_list=metrics_list, description_dict=description_dict)\n",
    "exec('from sklearn.metrics import {}'.format(', '.join(metrics_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "fit_estimators_list = s.load_object('fit_estimators_list')\n",
    "clf_name_list = [str(type(clf)).split('.')[-1].split(\"'\")[0] for clf in fit_estimators_list]\n",
    "basic_quals_df = s.load_object('basic_quals_df')\n",
    "y_true = basic_quals_df.is_fit.tolist()\n",
    "fit_match_series = (basic_quals_df.is_fit == 1)\n",
    "yes_list = basic_quals_df[fit_match_series].is_fit.tolist()\n",
    "no_list = basic_quals_df[~fit_match_series].is_fit.tolist()\n",
    "columns_list = ['clf_name', 'training_duration', 'inference_duration', 'boundary_diff', 'clf_yes_entropy', 'relative_yes_entropy'] + metrics_list\n",
    "rows_list = []\n",
    "training_durations_list = s.load_object('training_durations_list')\n",
    "inference_durations_list = s.load_object('inference_durations_list')\n",
    "for column_name, training_duration, inference_duration in zip(clf_name_list, training_durations_list, inference_durations_list):\n",
    "    yes_series = basic_quals_df[fit_match_series][column_name]\n",
    "    upper_bound = yes_series.min()\n",
    "    no_series = basic_quals_df[~fit_match_series][column_name]\n",
    "    lower_bound = no_series.max()\n",
    "    y_pred = []\n",
    "    for p in basic_quals_df[column_name]:\n",
    "        if p > 0.5:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    row_dict = {}\n",
    "    row_dict['clf_name'] = column_name\n",
    "    row_dict['training_duration'] = training_duration\n",
    "    row_dict['inference_duration'] = inference_duration\n",
    "    row_dict['boundary_diff'] = upper_bound-lower_bound\n",
    "    row_dict['clf_yes_entropy'] = entropy(pk=yes_series.tolist())\n",
    "    row_dict['relative_yes_entropy'] = entropy(pk=yes_list, qk=yes_series.tolist())\n",
    "    for metric_str in metrics_list:\n",
    "        try:\n",
    "            row_dict[metric_str] = eval('{}(y_true, basic_quals_df[column_name].tolist())'.format(metric_str))\n",
    "        except Exception as e1:\n",
    "            try:\n",
    "                row_dict[metric_str] = eval('{}(y_true, y_pred)'.format(metric_str))\n",
    "            except Exception as e2:\n",
    "                row_dict[metric_str] = np.nan\n",
    "    rows_list.append(row_dict)\n",
    "entropy_df = pd.DataFrame(rows_list, columns=columns_list).dropna(axis='columns', how='all')\n",
    "entropy_df.set_index('clf_name', drop=True, inplace=True)\n",
    "s.store_objects(entropy_df=entropy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['training_duration', 'inference_duration', 'balanced_accuracy_score', 'r2_score']\n",
    "entropy_df[columns_list].sort_values('balanced_accuracy_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entropy_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit_estimators_list = s.load_object('fit_estimators_list')\n",
    "fit_estimators_dict = {str(type(clf)).split('.')[-1].split(\"'\")[0]: clf for clf in fit_estimators_list}\n",
    "s.store_objects(fit_estimators_dict=fit_estimators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "\n",
    "s = Storage()\n",
    "entropy_df = s.load_object('entropy_df')\n",
    "metrics_list = s.load_object('metrics_list')\n",
    "custom_metrics_list = ['boundary_diff', 'clf_yes_entropy', 'relative_yes_entropy']\n",
    "columns_list = metrics_list + custom_metrics_list\n",
    "columns_list = [cn for cn, s in sorted([(cn, entropy_df[cn].std()) for cn in columns_list], key=lambda x: x[1], reverse=True)][:3]\n",
    "for metric in columns_list:\n",
    "    print('{}: {}'.format(metric, description_dict[metric]))\n",
    "AxesSubplot_obj = entropy_df[columns_list].sort_values('r2_score', ascending=True).plot.line(rot=45, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "description_dict = s.load_object('description_dict')\n",
    "columns_list = ['training_duration', 'inference_duration', 'balanced_accuracy_score', 'r2_score']\n",
    "for metric in columns_list:\n",
    "    if metric in description_dict:\n",
    "        print('{}: {}'.format(metric, description_dict[metric]))\n",
    "entropy_df = s.load_object('entropy_df')\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_yscale('log')\n",
    "AxesSubplot_obj = entropy_df[columns_list].sort_values('training_duration', ascending=True).plot.line(rot=45, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_list = s.load_object('metrics_list')\n",
    "columns_list = [cn for cn in metrics_list if 'accur' in cn.lower()]\n",
    "for metric in columns_list:\n",
    "    if metric in description_dict:\n",
    "        print('{}: {}'.format(metric, description_dict[metric]))\n",
    "AxesSubplot_obj = entropy_df[columns_list].sort_values('accuracy_score', ascending=True).plot.line(rot=45, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entropy_df[custom_metrics_list].sort_values('boundary_diff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for metric in custom_metrics_list:\n",
    "    if metric in description_dict:\n",
    "        print('{}: {}'.format(metric, description_dict[metric]))\n",
    "AxesSubplot_obj = entropy_df[custom_metrics_list].sort_values('boundary_diff', ascending=True).plot.line(rot=45, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Add Next ORR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = 'BAH1002 - Open Requisitions Report (ORR) 2020-02-21 09_03 EST.csv'\n",
    "print(file_name)\n",
    "hunting_df = add_new_orr(file_name, hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.tail(5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Flag setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note the email has been sent\n",
    "req_id = 'R0062296'.strip()\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set remote delivery for this list of jobs\n",
    "req_id_list = ['R0073564', 'R0073583', 'R0073584', 'R0073585', 'R0073586']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] == True\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set remote delivery for this one job\n",
    "req_id = 'R0069681'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] == False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set university recruiting for this job\n",
    "req_id = 'R0066388'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_for_university_recruiting'] = 1\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note you can't do this job from home\n",
    "req_id = 'R0064764'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note you can't do this job from home\n",
    "hunting_df.loc[83, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.index == 2616)\n",
    "hunting_df.loc[match_series, 'is_for_university_recruiting'] = 1\n",
    "hunting_df.loc[match_series, 'percent_fit'] = 0.0\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id = 'R0063832'\n",
    "print_job_description(req_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    if re.search(r'\\bIAT\\b', str(x)):\n",
    "        results = True\n",
    "    else:\n",
    "        results = False\n",
    "    \n",
    "    return results\n",
    "\n",
    "match_series = basic_quals_df.qualification_str.map(f)\n",
    "for qual in basic_quals_df[match_series].qualification_str.tolist():\n",
    "    print('•\\t{} = {}'.format(qual, basic_quals_dict[qual]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_dict['Ability to operate independently and manage staff'] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id = 'R0073507'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "print(hunting_df[match_series]['percent_fit'].tolist())\n",
    "for row_index, row_series in hunting_df[match_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.loc[504, 'percent_fit'] = (1+1+1+1+0+1+1)/7\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id_list = ['R0073564', 'R0073583', 'R0073584', 'R0073585', 'R0073586']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df[match_series].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.index == 437)\n",
    "print(hunting_df[match_series]['Job Description'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.percent_fit >= 0.0)\n",
    "print(hunting_df[~match_series].sample(1)['Job Description'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(['hunting_df.{}'.format(fn) for fn in dir(hunting_df) if 'dup' in fn.lower()])\n",
    "match_series = hunting_df.duplicated(subset='Job Requisition ID', keep=False)\n",
    "print(hunting_df[match_series].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                'Job Posting Title', 'Recruiting Start Date', 'Account Group', 'Job Requisition ID', 'Job Type',\n",
    "                'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                'Resource Manager', 'Primary Location', 'Job Description', 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                'Required Clearance', 'Primary Recruiter']\n",
    "hunting_df = hunting_df.drop_duplicates(subset=columns_list, ignore_index=True)\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_list = hunting_df[match_series].index.tolist()\n",
    "first = idx_list[0]\n",
    "second = idx_list[1]\n",
    "columns_list = []\n",
    "for column_name in hunting_df.columns:\n",
    "    if hunting_df.loc[first, column_name] == hunting_df.loc[second, column_name]:\n",
    "        columns_list.append(column_name)\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = hunting_df.percent_fit.isnull()\n",
    "print(hunting_df[match_series].shape)\n",
    "req_id = hunting_df.loc[481, 'Job Requisition ID']\n",
    "print_job_description(req_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(['{}'.format(fn) for fn in hunting_df.columns if 'req' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_regex = re.compile(r'([^0-9A-Za-z\\+ \\/)(:,]+)-')\n",
    "for old_key in basic_quals_dict.keys():\n",
    "    match_obj = key_regex.search(old_key)\n",
    "    if match_obj:\n",
    "        print('\"{}\": {}'.format(match_obj.group(1), old_key))\n",
    "        #new_key = re.sub('^[?â-]+', '', old_key)\n",
    "        #print(new_key)\n",
    "        #basic_quals_dict[new_key] = basic_quals_dict.pop(old_key)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_regex = re.compile(r'\\s+$')\n",
    "old_key_list = basic_quals_dict.copy().keys()\n",
    "for old_key in old_key_list:\n",
    "    match_obj = key_regex.search(old_key)\n",
    "    if match_obj:\n",
    "        #print('\"{}\": {}'.format(match_obj.group(1), old_key))\n",
    "        new_key = re.sub(r'\\s+$', '', old_key)\n",
    "        #print(new_key)\n",
    "        basic_quals_dict[new_key] = basic_quals_dict.pop(old_key)\n",
    "        #print(old_key)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Manually score unscored jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.loc[436, 'percent_fit'] = (0+1+1+1+1+1)/6\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Study of the Safi recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "match_series = (hunting_df['Safi Recommendation'] == 1)\n",
    "[c[10:100].strip() for c in random.choices(population=hunting_df[match_series]['Job Description'].unique(), k=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(hunting_df=hunting_df)\n",
    "match_series = (hunting_df['Safi Recommendation'] == 1)\n",
    "hunting_df[match_series]['Primary Location State/Province'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Requisition'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Cluster'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Family'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Account Group'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Resource Manager'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Requisition Type'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Posting'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Hiring Manager'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['IMT'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Required Clearance'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Job Profile'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Management Level'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Clearance Agency'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Group'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Job Profile'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[cn for cn in columns_list if 'loca' in cn.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Primary Location'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Primary Recruiter'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Initial dataframe creation (don't run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting'\n",
    "columns_list = []\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    #path = root.split(os.sep)\n",
    "    #print((len(path)-1) * '---', os.path.basename(root))\n",
    "    for file in files:\n",
    "        #print(len(path) * '---', file)\n",
    "        if file.endswith('.csv'):\n",
    "            print(file)\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, encoding='iso8859-1')\n",
    "                columns_list = list(set(columns_list) | set(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df = pd.DataFrame([], columns=columns_list)\n",
    "\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, encoding='iso8859-1')\n",
    "                hunting_df = pd.concat([hunting_df, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "command_str = '{sys.executable} -m pip install pyOutlook'.format(sys=sys)\n",
    "print(command_str)\n",
    "!{command_str}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
