{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\ipynb\\Job Hunting.ipynb\n",
      "['s.attempt_to_pickle', 's.data_csv_folder', 's.data_folder', 's.encoding_type', 's.load_csv', 's.load_dataframes', 's.load_object', 's.save_dataframes', 's.saves_csv_folder', 's.saves_folder', 's.saves_pickle_folder', 's.store_objects']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Config', 'In', 'Out', 'RandomForestClassifier', 'SequenceMatcher', 'Storage', '_', '__', '___', '__builtin__', '__builtins__', '__doc__', '__loader__', '__name__', '__nonzero__', '__package__', '__spec__', '_dh', '_i', '_i1', '_ih', '_ii', '_iii', '_oh', 'check_4_doubles', 'check_for_typos', 'conjunctify_list', 'copyfile', 'csv', 'encoding', 'exit', 'get_classifier', 'get_data_structs_df', 'get_datastructure_prediction', 'get_dir_tree', 'get_git_lfs_track_commands', 'get_importances', 'get_input_sample', 'get_ipython', 'get_module_version', 'get_notebook_path', 'get_specific_gitignore_files', 'get_struct_name', 'humanize_bytes', 'ipykernel', 'json', 'jupyter_config_dir', 'notebook_path', 'notebookapp', 'os', 'pd', 'pickle', 'preprocess_data', 'print_all_files_ending_starting_with', 'print_all_files_ending_with', 'print_all_files_starting_with', 'quit', 're', 'remove_empty_folders', 's', 'similar', 'subprocess', 'sys', 'time', 'urllib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "%run ../../load_magic/paths.py\n",
    "%run ../../load_magic/lists.py\n",
    "%run ../../load_magic/environment.py\n",
    "%pprint\n",
    "\n",
    "notebook_path = get_notebook_path()\n",
    "print(notebook_path)\n",
    "\n",
    "s = Storage()\n",
    "print(['s.{}'.format(fn) for fn in dir(s) if not fn.startswith('_')])\n",
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "applied_for_JRIDs = ['R0001165', 'R0000078', 'R0000364', '01222651', \n",
    "                     '01221549', '01219721', '01222378', '01222260',\n",
    "                     '01222212', 'R0001799', 'R0001743', 'R0002022']\n",
    "potential_JRIDs = ['01219721', '01222260', '01222378', '01222651', \n",
    "                   'R0001743', 'R0001799', 'R0002022']\n",
    "apply_for_list = list(set(potential_JRIDs) - set(applied_for_JRIDs))\n",
    "print(apply_for_list)\n",
    "len(apply_for_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting'\n",
    "!start %windir%\\explorer.exe \"{hunting_dir}\"\n",
    "if len(apply_for_list) == 0:\n",
    "    with open(hunting_dir + 'applied_for_JRIDs.pickle', 'wb') as handle:\n",
    "        pickle.dump(applied_for_JRIDs, handle, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#ValueError: time data '3/2/2017' does not match format '%Y-%m-%d %H:%M:%S'\n",
    "date_format = \"%m/%d/%Y\"\n",
    "date_column_list = ['Recruiting Start Date']\n",
    "date_parser = lambda x: None if x == 'nan' else pd.datetime.strptime(str(x), date_format)\n",
    "\n",
    "encoding = 'latin1'\n",
    "#encoding = 'iso8859-1'\n",
    "#encoding = 'utf-8'\n",
    "columns_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\577342\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    #path = root.split(os.sep)\n",
    "    #print((len(path)-1) * '---', os.path.basename(root))\n",
    "    for file in files:\n",
    "        #print(len(path) * '---', file)\n",
    "        if file.endswith('.csv'):\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, parse_dates=date_column_list, date_parser=date_parser, encoding=encoding)\n",
    "                columns_list = list(set(columns_list) | set(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "everybody_df = pd.DataFrame([], columns=columns_list)\n",
    "\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, parse_dates=date_column_list, date_parser=date_parser, encoding=encoding)\n",
    "                everybody_df = pd.concat([everybody_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "everybody_df['Cluster'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "everybody_df['Job Family'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "everybody_df['Account Group'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "everybody_df['Resource Manager'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "everybody_df['Job Requisition Type'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "everybody_df['Job Posting'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[c[10:40].strip() for c in random.choices(population=everybody_df['Job Description'].unique(), k=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.choices(population=everybody_df['Hiring Manager'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.choices(population=everybody_df['IMT'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.choices(population=everybody_df['Required Clearance'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.choices(population=everybody_df['Job Profile'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.choices(population=everybody_df['Management Level'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.choices(population=everybody_df['Clearance Agency'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.choices(population=everybody_df['Group'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "#print(['random.{}'.format(fn) for fn in dir(random) if not fn.startswith('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.choices(population=everybody_df['Job Profile'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.choices(population=everybody_df['Location'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.choices(population=everybody_df['Primary Recruiter'].unique(), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    derived_name = str(row['StudentLastName']) + \", \" + str(row['StudentFirstName']) + \" (\" + str(row['derived_event']) + \")\"\n",
    "    derived_name = derived_name.upper()\n",
    "    \n",
    "    return derived_name\n",
    "\n",
    "t0 = time.time()\n",
    "everybody_df['derived_name'] = everybody_df.apply(lambda row: f(row), axis=1)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = everybody_df['Required Clearance'].isin(['None', 'Secret', 'Confidential'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = everybody_df['Job Requisition ID'].isin(apply_for_list)\n",
    "everybody_df[match]['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "for column_name in blank_columns:\n",
    "    \n",
    "    # Get input row in dictionary format; key = col_name\n",
    "    row_dict = {}\n",
    "    row_dict['column_name'] = column_name\n",
    "    row_dict['count_blanks'] = everybody_df[column_name].isnull().sum()\n",
    "    row_dict['count_uniques'] = len(everybody_df[column_name].unique())\n",
    "    \n",
    "    rows_list.append(row_dict)\n",
    "\n",
    "blank_ranking_df = pd.DataFrame(rows_list, columns=['column_name', 'count_blanks', 'count_uniques'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
