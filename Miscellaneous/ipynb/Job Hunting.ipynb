{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\ipynb\\Job Hunting.ipynb\n",
      "['s.attempt_to_pickle', 's.data_csv_folder', 's.data_folder', 's.encoding_type', 's.load_csv', 's.load_dataframes', 's.load_object', 's.save_dataframes', 's.saves_csv_folder', 's.saves_folder', 's.saves_pickle_folder', 's.store_objects']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Config', 'CountVectorizer', 'In', 'Out', 'RandomForestClassifier', 'SequenceMatcher', 'Storage', 'TfidfTransformer', '_', '__', '___', '__builtin__', '__builtins__', '__doc__', '__loader__', '__name__', '__nonzero__', '__package__', '__spec__', '_dh', '_i', '_i1', '_ih', '_ii', '_iii', '_oh', 'basic_quals_dict', 'check_4_doubles', 'check_for_typos', 'conjunctify_list', 'copyfile', 'csv', 'encoding', 'exit', 'get_classifier', 'get_data_structs_df', 'get_datastructure_prediction', 'get_dir_tree', 'get_git_lfs_track_commands', 'get_importances', 'get_input_sample', 'get_ipython', 'get_module_version', 'get_notebook_path', 'get_specific_gitignore_files', 'get_struct_name', 'humanize_bytes', 'hunting_df', 'ipykernel', 'json', 'jupyter_config_dir', 'notebook_path', 'notebookapp', 'np', 'os', 'pd', 'pickle', 'preprocess_data', 'print_all_files_ending_starting_with', 'print_all_files_ending_with', 'print_all_files_starting_with', 'quit', 're', 'remove_empty_folders', 's', 'similar', 'subprocess', 'sys', 'time', 'urllib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "%run ../../load_magic/paths.py\n",
    "%run ../../load_magic/lists.py\n",
    "%run ../../load_magic/environment.py\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "%pprint\n",
    "\n",
    "notebook_path = get_notebook_path()\n",
    "print(notebook_path)\n",
    "\n",
    "s = Storage()\n",
    "print(['s.{}'.format(fn) for fn in dir(s) if not fn.startswith('_')])\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Needed extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Email prep\n",
    "subject_str = '{}% fit: Internal Candidate, Dave Babbitt, for {}'\n",
    "concerns_str = 'One important question I have is if the work can be supported remotely or if this position is available for remote delivery '\n",
    "concerns_str += '(or something equivalent).'\n",
    "concerns_str += \" I don't want to move my family out of New England.\"\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "emails_dir = os.path.join(s.saves_folder, 'emails')\n",
    "os.makedirs(name=emails_dir, exist_ok=True)\n",
    "name_regex = re.compile(r'^([^(]+) \\((\\d+)\\)')\n",
    "def clean_email(email_str):\n",
    "    match_obj = name_regex.search(email_str)\n",
    "    if match_obj:\n",
    "        email_str = match_obj.group(1).strip()\n",
    "        employee_id = match_obj.group(2).strip()\n",
    "        names_list = re.split(r'\\s+', email_str, 0)\n",
    "        if len(names_list) >= 2:\n",
    "            first_name = names_list[0]\n",
    "            last_name = names_list[1]\n",
    "            email_str = '{}, {} [USA] <{}@bah.com>'.format(last_name, first_name, employee_id)\n",
    "    \n",
    "    return email_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_percent_fit(row_series):\n",
    "    percent_fit = row_series['percent_fit']\n",
    "    if str(percent_fit) == 'nan':\n",
    "        percent_fit = 0\n",
    "    percent_fit = int(percent_fit*100)\n",
    "    \n",
    "    return percent_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_loc_computation(row_index, quals_list, basic_quals_dict):\n",
    "    print()\n",
    "    numerator_str_list = []\n",
    "    for qual_str in quals_list:\n",
    "        if qual_str in basic_quals_dict:\n",
    "            numerator_str_list.append(str(basic_quals_dict[qual_str]))\n",
    "        else:\n",
    "            numerator_str_list.append('000')\n",
    "    numerator_str = '+'.join(numerator_str_list)\n",
    "    print(\"hunting_df.loc[{}, 'percent_fit'] = ({})/{}\".format(row_index, numerator_str, len(quals_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions_and_counts(prediction_list, quals_list):\n",
    "    qual_count = 0\n",
    "    prediction_str = ''\n",
    "    for pred_array, qual_str in zip(prediction_list, quals_list):\n",
    "        prediction = pred_array[1]\n",
    "        prediction_str += '\\n{} {}'.format(prediction, qual_str)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return prediction_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_quals_str(prediction_list, quals_list, basic_quals_dict):\n",
    "    qual_count = 0\n",
    "    quals_str = ''\n",
    "    for pred_array, (i, qual_str) in zip(prediction_list, enumerate(quals_list)):\n",
    "        if qual_str in basic_quals_dict:\n",
    "            formatted_str = '\\nquals_list[{}] = \"{}\" ({})'\n",
    "        else:\n",
    "            formatted_str = '\\n*quals_list[{}] = \"{}\" ({})'\n",
    "        prediction = pred_array[1]\n",
    "        quals_str += formatted_str.format(i, qual_str, prediction)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return quals_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_fit_job(row_index, row_series, basic_quals_dict):\n",
    "    job_fitness = 0.0\n",
    "    job_description = row_series['Job Description']\n",
    "    quals_list = get_quals_list(job_description)\n",
    "    if len(quals_list):\n",
    "        prediction_list = list(predict_percent_fit(quals_list))\n",
    "        #prediction_str, qual_count = get_predictions_and_counts(prediction_list, quals_list)\n",
    "        quals_str, qual_count = get_quals_str(prediction_list, quals_list, basic_quals_dict)\n",
    "        job_fitness = qual_count/len(prediction_list)\n",
    "        if job_fitness > 0.8:\n",
    "            print('Basic Qualifications:{}'.format(quals_str))\n",
    "            #print(prediction_str)\n",
    "            print(job_fitness)\n",
    "            print_loc_computation(row_index, quals_list, basic_quals_dict)\n",
    "    \n",
    "    return quals_list, job_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qual_sum(qual_str):\n",
    "    results = '\"{}\"'.format(qual_str)\n",
    "    if qual_str in basic_quals_dict:\n",
    "        results = basic_quals_dict[qual_str]\n",
    "    else:\n",
    "        results = predict_percent_fit([qual_str])[0][1]\n",
    "        if results > 0.5:\n",
    "            results = 1.0\n",
    "        else:\n",
    "            results = 0.0\n",
    "    \n",
    "    return str(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_job_description(req_id):\n",
    "    match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "    job_description = hunting_df[match_series]['Job Description'].tolist()[0]\n",
    "    print(get_quals_list(job_description))\n",
    "    print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scanner_regex = re.compile(r'\\b[1-9a-zA-Z][0-9a-zA-Z]*( *[#\\+]{1,2}|\\b)')\n",
    "def regex_tokenizer(corpus):\n",
    "    \n",
    "    return [match.group() for match in re.finditer(scanner_regex, corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_list = ['Additional Qualifications?', 'Nice If You Have', 'Nice if you have', 'Nice if You Have',\n",
    "          'Additional Preferred Qualifications', 'Nice if you Have', 'Additional qualifications', 'Nice to Have']\n",
    "a_str = '({}):?'.format('|'.join(a_list))\n",
    "def get_quals_list(job_description):\n",
    "    job_description = re.sub('Â', '', job_description)\n",
    "    basic_quals = ''\n",
    "    quals_list = []\n",
    "    items_list = re.split('(Key Role|The Challenge):', job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        job_description = items_list[-1].strip()\n",
    "    items_list = re.split('[\\r\\n]+(Basic Qualifications?|You Have|You have):?', job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        job_description = items_list[-1].strip()\n",
    "    items_list = re.split(a_str, job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        basic_quals = items_list[0].strip()\n",
    "    else:\n",
    "        items_list = re.split('(Clearance|Build Your Career):', job_description, 0)\n",
    "        basic_quals = items_list[0].strip()\n",
    "    if basic_quals != '':\n",
    "        quals_list = [re.sub(r'â¯', ' ', q) for q in re.split('[\\r\\n]+', basic_quals, 0)]\n",
    "        quals_list = [re.sub(r'^[?â-]+', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'[â-]+$', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '-', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '`', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '`', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '`', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(u'\\\\xa0', u' ', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'\\s+$', '', x) for x in quals_list]\n",
    "        quals_list = [x for x in quals_list if x != '']\n",
    "    \n",
    "    return quals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_emails(match_series):\n",
    "    for file_name in os.listdir(emails_dir):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(emails_dir, file_name)\n",
    "            os.remove(file_path)\n",
    "    for row_index, row_series in hunting_df[match_series].sort_values('percent_fit', ascending=False).iterrows():\n",
    "        req_str = row_series['Job Requisition']\n",
    "        percent_fit = get_percent_fit(row_series)\n",
    "        sents_list = ['I’m submitting my resume for {}.'.format(req_str),\n",
    "                      'I’ve reviewed the basic qualifications and believe I’m a good fit for this project.',\n",
    "                      'Below is a breakdown of the requirements and the amount of experience I have with each.',\n",
    "                      'I’m available at your convenience to discuss my qualifications and look forward to hearing from you.']\n",
    "        blurb_str = ' '.join(sents_list)\n",
    "        hm_str = row_series['Hiring Manager']\n",
    "        pr_str = row_series['Primary Recruiter']\n",
    "        job_description = row_series['Job Description']\n",
    "        quals_list = get_quals_list(job_description)\n",
    "        quals_str = '\\n•\\t' + '\\n•\\t'.join(quals_list)\n",
    "        file_path = os.path.join(emails_dir, '{}_email.txt'.format(row_series['Job Requisition ID'].strip()))\n",
    "        if not os.path.isfile(file_path):\n",
    "            with open(file_path, 'w', encoding=s.encoding_type) as io_wrapper:\n",
    "                print('', file=io_wrapper)\n",
    "                print('To: {}; {}'.format(clean_email(hm_str), clean_email(pr_str)), file=io_wrapper)\n",
    "                print('CC: Safi, Claudia [USA] <safi_claudia@bah.com>; Borrelli, Bill [USA] <Borrelli_Bill@bah.com>', file=io_wrapper)\n",
    "                print(subject_str.format(percent_fit, req_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Dear {},'.format(hm_str.split(' ')[0]), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('{}'.format(blurb_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Basic Qualifications:{}'.format(quals_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print(concerns_str, file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Attached: Dave_Babbitt_Resume_for_{}.pdf'.format('_'.join(re.split(r'[ \\\\\\/:\\*\\?\"><\\|]+', req_str, 0))),\n",
    "                      file=io_wrapper)\n",
    "            !\"{text_editor_path}\" \"{os.path.abspath(file_path)}\"\n",
    "    !start %windir%\\explorer.exe \"{os.path.abspath(emails_dir)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add new ORR to the hunting dataframe\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "jd_cn = 'Job Description'\n",
    "reqid_cn = 'Job Requisition ID'\n",
    "dupe_columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                     'Job Posting Title', 'Recruiting Start Date', 'Account Group', reqid_cn, 'Job Type',\n",
    "                     'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                     'Resource Manager', 'Primary Location', jd_cn, 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                     'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                     'Required Clearance', 'Primary Recruiter']\n",
    "columns_list = ['Job Posting', 'Job Requisition', reqid_cn, 'Job Requisition Status', 'Furthest Stage',\n",
    "                'Supervisory Organization', 'Group', 'Account Group', 'IMT', 'Cluster', 'FSO', 'Primary Recruiter',\n",
    "                'Resource Manager', 'Hiring Manager', 'Job Posting Title', 'Job Profile', 'Job Requisition Type',\n",
    "                'Management Level', 'Primary Location', 'Primary Location State/Province', 'Primary Location Country',\n",
    "                'Required Clearance', 'Clearance Agency', 'Time Type', 'Recruiting Start Date', 'Job Type', 'Job Family',\n",
    "                'Business Title', 'Job Family Group', jd_cn]\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting\\csv'\n",
    "def add_new_orr(file_name, hunting_df):\n",
    "    file_path = os.path.join(hunting_dir, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        !\"{text_editor_path}\" \"{os.path.abspath(file_path)}\"\n",
    "        df = pd.read_csv(file_path, header=0, skiprows=0, encoding='iso8859-1')\n",
    "        df.columns = columns_list\n",
    "        req_id_list = hunting_df[reqid_cn].unique().tolist()\n",
    "        match_series = (df[reqid_cn].isin(req_id_list))\n",
    "        hunting_df = pd.concat([hunting_df, df[~match_series]]).fillna({'is_opportunity_application_emailed': False})\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(u'\\\\xa0', u' ', x))\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(r'', \"'\", x))\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(r'', '—', x))\n",
    "        hunting_df = hunting_df.drop_duplicates(subset=dupe_columns_list, ignore_index=True)\n",
    "        hunting_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return hunting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "def get_basic_quals(row_index):\n",
    "    match_series = (hunting_df.index == row_index)\n",
    "    for row_index, row_series in hunting_df[match_series].iterrows():\n",
    "        percent_fit = get_percent_fit(row_series)\n",
    "        job_description = row_series['Job Description']\n",
    "        quals_list = get_quals_list(job_description)\n",
    "        quals_str = get_quals_str(quals_list, basic_quals_dict)\n",
    "        if (quals_str != '') and (percent_fit == 0):\n",
    "            print('Basic Qualifications:{}'.format(quals_str))\n",
    "            print_loc_computation(row_index, quals_list, basic_quals_dict)\n",
    "    \n",
    "    return quals_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\basic_quals_df.pickle\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\bq_cv_vocab.pickle\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\bq_tt.pickle\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\basic_quals_clf.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Rebuild the datframe from the dictionary\n",
    "rows_list = [{'qualification_str': qualification_str, 'is_fit': is_fit} for qualification_str, is_fit in basic_quals_dict.items()]\n",
    "basic_quals_df = pd.DataFrame(rows_list)\n",
    "s.store_objects(basic_quals_df=basic_quals_df)\n",
    "\n",
    "# Re-transform the bag-of-words and tf-idf from the new manual scores\n",
    "sents_list = basic_quals_df.qualification_str.tolist()\n",
    "\n",
    "# Bag-of-words\n",
    "cv = CountVectorizer(lowercase=True, tokenizer=regex_tokenizer, token_pattern=r'\\b[1-9a-zA-Z][0-9a-zA-Z]*[#\\+]{0,2}', ngram_range=(1, 3))\n",
    "bow_matrix = cv.fit_transform(sents_list)\n",
    "s.store_objects(bq_cv_vocab=cv.vocabulary_)\n",
    "\n",
    "# Tf-idf, must get from BOW first\n",
    "tt = TfidfTransformer()\n",
    "tfidf_matrix = tt.fit_transform(bow_matrix)\n",
    "s.store_objects(bq_tt=tt)\n",
    "\n",
    "# Re-train the classifier\n",
    "X = tfidf_matrix.toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "fit_estimators_dict = s.load_object('fit_estimators_dict')\n",
    "#basic_quals_clf = RandomForestClassifier(n_estimators=997)\n",
    "#basic_quals_clf = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0, n_estimators=50, random_state=None)\n",
    "basic_quals_clf = fit_estimators_dict['LogisticRegression']\n",
    "basic_quals_clf.fit(X, y)\n",
    "s.store_objects(basic_quals_clf=basic_quals_clf)\n",
    "\n",
    "# Re-calibrate the inference engine\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "def predict_percent_fit(quals_list):\n",
    "    y_predict_proba = np.array([])\n",
    "    if len(quals_list):\n",
    "        X_test = bq_tt.transform(bq_cv.transform(quals_list)).toarray()\n",
    "        y_predict_proba = basic_quals_clf.predict_proba(X_test)\n",
    "    \n",
    "    return y_predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Look for a fit greater than 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4550/4550 = 100% completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "match_series = (hunting_df.percent_fit >= 0.0)\n",
    "for row_index, row_series in hunting_df[~match_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)\n",
    "    if job_fitness > 0.8:\n",
    "        if all(qual_str in basic_quals_dict for qual_str in quals_list):\n",
    "            hunting_df.loc[row_index, 'percent_fit'] = eval(' + '.join(map(qual_sum, quals_list))) / len(quals_list)\n",
    "            s.store_objects(hunting_df=hunting_df)\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        if len(quals_list):\n",
    "            hunting_df.loc[row_index, 'percent_fit'] = eval(' + '.join(map(qual_sum, quals_list))) / len(quals_list)\n",
    "            s.store_objects(hunting_df=hunting_df)\n",
    "print('{}/{} = {}% completed'.format(hunting_df[match_series].shape[0], hunting_df.shape[0],\n",
    "                                     int(100 * hunting_df[match_series].shape[0] / hunting_df.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA or BS degree in Mathematics, Systems Engineering, Physics, Engineering, or Information Technology and 2+ years of experience in a professional work environment or MA or MS degree in Mathematics, Systems Engineering, Physics, Engineering, or Information Technology\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\basic_quals_dict.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[5]\n",
    "print(qualification_str)\n",
    "basic_quals_dict[qualification_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Create the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 34)\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def f(x):\n",
    "    \n",
    "    return 'python' in str(x).lower()\n",
    "\n",
    "def g(x):\n",
    "    \n",
    "    return 'polygraph' in str(x).lower()\n",
    "\n",
    "ds_regex = re.compile(r'data *scien')\n",
    "ml_regex = re.compile(r'machine *learning|\\bML\\b')\n",
    "def ff(x):\n",
    "    x = str(x).lower()\n",
    "    if ds_regex.search(x) or ml_regex.search(x) or ('python' in x):\n",
    "        match = True\n",
    "    else:\n",
    "        match = False\n",
    "    \n",
    "    return match\n",
    "\n",
    "match_series = hunting_df['Job Requisition Type'].isin(['Sold and Funded', 'Sold & Unfunded'])\n",
    "#match_series = match_series & hunting_df['Job Description'].map(f)\n",
    "match_series = match_series & hunting_df['Job Description'].map(ff)\n",
    "match_series = match_series & (hunting_df.percent_fit >= 0.85) & ~hunting_df['is_opportunity_application_emailed']\n",
    "match_series = match_series & ~(hunting_df.is_remote_delivery == False)\n",
    "match_series = match_series & ~hunting_df['Required Clearance'].isin(['TS/SCI', 'TS/SCI w/CIP', 'TS/SCI w/FSP'])\n",
    "match_series = match_series & ~hunting_df['Job Description'].map(g)\n",
    "print(hunting_df[match_series].shape)\n",
    "print(hunting_df[match_series].groupby('Required Clearance').count().T.max().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series].head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_emails(match_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually note the email has been sent\n",
    "req_id = 'R0079562'.strip()\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Flag setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "match_series = (hunting_df.is_for_university_recruiting == 1)\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set remote delivery for this one job\n",
    "req_id = 'R0079562'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for the feedback. Does this include all the reqs you are associated with (R0073027, R0070871, R0068426, R0068420, R0071491, R0071062, R0060915, R0065648, R0068421, R0080382, R0080458, R0080385, R0080383, and R0080384)?\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_name = 'Hiring Manager'\n",
    "last_name = 'Knapp'.lower()\n",
    "first_name = 'Justin'.lower()\n",
    "\n",
    "def f(x):\n",
    "    x = str(x).lower()\n",
    "    \n",
    "    return (first_name in x) and (last_name in x)\n",
    "\n",
    "match_series = hunting_df[column_name].map(f)\n",
    "req_id_list = hunting_df[match_series]['Job Requisition ID'].tolist()\n",
    "formatted_str = 'Thanks for the feedback. Does this include all the reqs you are associated with ({})?'\n",
    "print(formatted_str.format(conjunctify_list(req_id_list)))\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for the feedback. Does this include all the reqs you are associated with (R0080347)?\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_name = 'Hiring Manager'\n",
    "last_name = 'Cofrancesco'.lower()\n",
    "first_name = 'Elaine'.lower()\n",
    "\n",
    "def f(x):\n",
    "    x = str(x).lower()\n",
    "    \n",
    "    return (first_name in x) and (last_name in x)\n",
    "\n",
    "match_series = hunting_df[column_name].map(f)\n",
    "req_id_list = hunting_df[match_series]['Job Requisition ID'].tolist()\n",
    "formatted_str = 'Thanks for the feedback. Does this include all the reqs you are associated with ({})?'\n",
    "print(formatted_str.format(conjunctify_list(req_id_list)))\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_name = 'Hiring Manager'\n",
    "last_name = 'Jendzejec'.lower()\n",
    "first_name = 'Alexander'.lower()\n",
    "\n",
    "def f(x):\n",
    "    x = str(x).lower()\n",
    "    \n",
    "    return (first_name in x) and (last_name in x)\n",
    "\n",
    "match_series = hunting_df[column_name].map(f)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_name = 'Hiring Manager'\n",
    "last_name = 'ferraro'\n",
    "first_name = 'mike'\n",
    "\n",
    "def f(x):\n",
    "    x = str(x).lower()\n",
    "    \n",
    "    return (first_name in x) and (last_name in x)\n",
    "\n",
    "match_series = hunting_df[column_name].map(f)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set remote delivery for this list of jobs\n",
    "req_id_list = ['R0072627', 'R0072630', 'R0072685', 'R0072688', 'R0072699', 'R0072700', 'R0078787', 'R0078792', 'R0078793', 'R0072670',\n",
    "               'R0072672', 'R0078798', 'R0078799']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set remote delivery for this list of jobs\n",
    "req_id_list = ['R0073564', 'R0073583', 'R0073584', 'R0073585', 'R0073586']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = True\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set university recruiting for this job\n",
    "req_id = 'R0066388'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_for_university_recruiting'] = 1\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note you can't do this job from home\n",
    "req_id = 'R0064764'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note you can't do this job from home\n",
    "hunting_df.loc[83, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.index == 2616)\n",
    "hunting_df.loc[match_series, 'is_for_university_recruiting'] = 1\n",
    "hunting_df.loc[match_series, 'percent_fit'] = 0.0\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_opportunity_application_emailed\n",
      "False    4396\n",
      "True      154\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(hunting_df.groupby('is_opportunity_application_emailed').count().T.max().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_remote_delivery\n",
      "False    65\n",
      "True      6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(hunting_df.groupby('is_remote_delivery').count().T.max().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    if ('RAZOR' in x):\n",
    "        match = True\n",
    "    else:\n",
    "        match = False\n",
    "    \n",
    "    return match\n",
    "match_series = hunting_df['Job Description'].map(f)\n",
    "if hunting_df[match_series].shape[0] > 0:\n",
    "    print(hunting_df[match_series].shape)\n",
    "    print(hunting_df[match_series].groupby('Required Clearance').count().T.max().sort_values(ascending=False))\n",
    "    hunting_df[match_series].head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type', 'Job Posting Title', 'Safi Recommendation', 'Recruiting Start Date', 'Account Group', 'Job Requisition ID', 'Job Type', 'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage', 'Resource Manager', 'Primary Location', 'Job Description', 'Group', 'Job Profile', 'Job Family Group', 'FSO', 'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country', 'Required Clearance', 'Primary Recruiter', 'percent_fit', 'is_opportunity_application_emailed', 'is_remote_delivery', 'is_for_university_recruiting']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hunting_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Title</th>\n",
       "      <th>Profile</th>\n",
       "      <th>Group</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Bot Development Analyst</td>\n",
       "      <td>Ops Res Analyst Mid</td>\n",
       "      <td>Consulting &amp; Mission Operations</td>\n",
       "      <td>USA, TX, San Antonio (112 E Pecan St)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist Mid</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USA, NC, Fayetteville (4200 Morganton Rd Suite...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Full Stack Developer Mid</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USA, NC, Fayetteville (4200 Morganton Rd Suite...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer Mid</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USA, NC, Fayetteville (4200 Morganton Rd Suite...</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer Mid</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USA, NC, Fayetteville (4200 Morganton Rd Suite...</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer Mid</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USA, NC, Fayetteville (4200 Morganton Rd Suite...</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Level                    Title                   Profile  \\\n",
       "4263  Senior Consultant  Bot Development Analyst       Ops Res Analyst Mid   \n",
       "475   Senior Consultant           Data Scientist        Data Scientist Mid   \n",
       "1390  Senior Consultant       Software Developer  Full Stack Developer Mid   \n",
       "428   Senior Consultant            Data Engineer         Data Engineer Mid   \n",
       "426   Senior Consultant            Data Engineer         Data Engineer Mid   \n",
       "427   Senior Consultant            Data Engineer         Data Engineer Mid   \n",
       "\n",
       "                                Group  \\\n",
       "4263  Consulting & Mission Operations   \n",
       "475                        Technology   \n",
       "1390                       Technology   \n",
       "428                        Technology   \n",
       "426                        Technology   \n",
       "427                        Technology   \n",
       "\n",
       "                                               Location       Fit  \n",
       "4263              USA, TX, San Antonio (112 E Pecan St)  1.000000  \n",
       "475   USA, NC, Fayetteville (4200 Morganton Rd Suite...  1.000000  \n",
       "1390  USA, NC, Fayetteville (4200 Morganton Rd Suite...  1.000000  \n",
       "428   USA, NC, Fayetteville (4200 Morganton Rd Suite...  0.857143  \n",
       "426   USA, NC, Fayetteville (4200 Morganton Rd Suite...  0.833333  \n",
       "427   USA, NC, Fayetteville (4200 Morganton Rd Suite...  0.833333  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "match_series = (hunting_df['is_remote_delivery'] == True) & (hunting_df['is_opportunity_application_emailed'] == True)\n",
    "columns_list = ['Management Level', 'Job Posting Title', 'Job Profile', 'Job Family Group', 'Primary Location',\n",
    "                'percent_fit']\n",
    "df = hunting_df[match_series][columns_list].copy()\n",
    "df.columns = ['Level', 'Title', 'Profile', 'Group', 'Location', 'Fit']\n",
    "df.sort_values(['Fit', 'Title'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Experience with creating Web-based visualizations', 'Experience with developing front-end software for data visualizations or data entry', 'Ability to forward deploy for up to 12 months', 'Secret clearance', 'BA or BS degree']\n",
      "The Challenge:\n",
      "Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors — from fraud detection, to cancer research, to national intelligence — you know the answers are in the data.\n",
      "\n",
      "We have an opportunity for you to use your analytical skills to improve the warfighters capabilities. You'll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You'll support processing of structured, unstructured, and semi-structured data to derive patterns, trends, and correlations and enable entity extraction, disambiguation and other data-related support using appropriate data science tools and techniques. Employ techniques and theories drawn from many fields within the broad areas of mathematics, statistics, operations research, information science, and computer science, including signal processing, probability models, machine learning, statistical learning, pattern recognition and learning, predictive analytics, uncertainty modeling, and artificial intelligence. You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good to assist in accomplishing the mission. This position includes work that will be completed internationally, including the MENA region.\n",
      "\n",
      "Empower change with us.\n",
      "\n",
      "You Have:\n",
      "-Experience with creating Web-based visualizations\n",
      "-Experience with developing front-end software for data visualizations or data entry\n",
      "-Ability to forward deploy for up to 12 months\n",
      "-Secret clearance\n",
      "-BA or BS degree\n",
      "\n",
      "Nice If You Have:\n",
      "-3+ years of experience as a data scientist\n",
      "-Experience with development, modification, and application of computer modeling and programming applications to analyze and solve mathematical and scientific problems\n",
      "-Experience with building statistical models and developing machine learning algorithms\n",
      "-Experience in working with a Data Scientist team\n",
      "-Experience with programming languages, including Python, R, Scala, and Java\n",
      "-Experience with big data technologies, including HDFS, Hadoop, and Spark\n",
      "-Experience with deep learning paradigms and frameworks\n",
      "-Ability to convert data into a business story\n",
      "-Possession of excellent data visualization skills\n",
      "\n",
      "Clearance:\n",
      "Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.\n",
      "\n",
      "Build Your Career:\n",
      " At Booz Allen, we know the power of analytics and we're dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you'll have the chance to:\n",
      "access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\n",
      "change the world with the Data Science Bowl—the world's premier data science for social good competition\n",
      "participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\n",
      "\n",
      "You'll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, onsite boot camps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We'll help you develop the career you want as you chart your own course for success.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "req_id = 'R0073585'\n",
    "print_job_description(req_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    if re.search(r'\\bIAT\\b', str(x)):\n",
    "        results = True\n",
    "    else:\n",
    "        results = False\n",
    "    \n",
    "    return results\n",
    "\n",
    "match_series = basic_quals_df.qualification_str.map(f)\n",
    "for qual in basic_quals_df[match_series].qualification_str.tolist():\n",
    "    print('•\\t{} = {}'.format(qual, basic_quals_dict[qual]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_dict['Ability to operate independently and manage staff'] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id = 'R0073507'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "print(hunting_df[match_series]['percent_fit'].tolist())\n",
    "for row_index, row_series in hunting_df[match_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.loc[504, 'percent_fit'] = (1+1+1+1+0+1+1)/7\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id_list = ['R0073564', 'R0073583', 'R0073584', 'R0073585', 'R0073586']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df[match_series].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.index == 437)\n",
    "print(hunting_df[match_series]['Job Description'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.percent_fit >= 0.0)\n",
    "print(hunting_df[~match_series].sample(1)['Job Description'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(['hunting_df.{}'.format(fn) for fn in dir(hunting_df) if 'dup' in fn.lower()])\n",
    "match_series = hunting_df.duplicated(subset='Job Requisition ID', keep=False)\n",
    "print(hunting_df[match_series].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                'Job Posting Title', 'Recruiting Start Date', 'Account Group', 'Job Requisition ID', 'Job Type',\n",
    "                'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                'Resource Manager', 'Primary Location', 'Job Description', 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                'Required Clearance', 'Primary Recruiter']\n",
    "hunting_df = hunting_df.drop_duplicates(subset=columns_list, ignore_index=True)\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_list = hunting_df[match_series].index.tolist()\n",
    "first = idx_list[0]\n",
    "second = idx_list[1]\n",
    "columns_list = []\n",
    "for column_name in hunting_df.columns:\n",
    "    if hunting_df.loc[first, column_name] == hunting_df.loc[second, column_name]:\n",
    "        columns_list.append(column_name)\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = hunting_df.percent_fit.isnull()\n",
    "print(hunting_df[match_series].shape)\n",
    "req_id = hunting_df.loc[481, 'Job Requisition ID']\n",
    "print_job_description(req_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(['{}'.format(fn) for fn in hunting_df.columns if 'req' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_regex = re.compile(r'([^0-9A-Za-z\\+ \\/)(:,]+)-')\n",
    "for old_key in basic_quals_dict.keys():\n",
    "    match_obj = key_regex.search(old_key)\n",
    "    if match_obj:\n",
    "        print('\"{}\": {}'.format(match_obj.group(1), old_key))\n",
    "        #new_key = re.sub('^[?â-]+', '', old_key)\n",
    "        #print(new_key)\n",
    "        #basic_quals_dict[new_key] = basic_quals_dict.pop(old_key)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_regex = re.compile(r'\\s+$')\n",
    "old_key_list = basic_quals_dict.copy().keys()\n",
    "for old_key in old_key_list:\n",
    "    match_obj = key_regex.search(old_key)\n",
    "    if match_obj:\n",
    "        #print('\"{}\": {}'.format(match_obj.group(1), old_key))\n",
    "        new_key = re.sub(r'\\s+$', '', old_key)\n",
    "        #print(new_key)\n",
    "        basic_quals_dict[new_key] = basic_quals_dict.pop(old_key)\n",
    "        #print(old_key)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Add Next ORR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAH1002 - Open Requisitions Report (ORR) 2020-03-13 09_02 EDT.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_name = 'BAH1002 - Open Requisitions Report (ORR) 2020-03-13 09_02 EDT.csv'\n",
    "print(file_name)\n",
    "hunting_df = add_new_orr(file_name, hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4545</th>\n",
       "      <th>4546</th>\n",
       "      <th>4547</th>\n",
       "      <th>4548</th>\n",
       "      <th>4549</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hiring Manager</th>\n",
       "      <td>Eric Jones | Eric R Jones (552060)</td>\n",
       "      <td>Joseph Hall (504630)</td>\n",
       "      <td>Patrick Ward (522638)</td>\n",
       "      <td>Kent Friederich (535762)</td>\n",
       "      <td>Justin Knapp (522001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Management Level</th>\n",
       "      <td>Associate</td>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMT</th>\n",
       "      <td>NMC ENG &amp; TECH IMT</td>\n",
       "      <td>ARMY WEAPONS IMT</td>\n",
       "      <td>ARMY ISE IMT</td>\n",
       "      <td>ARMY SOLDIER IMT</td>\n",
       "      <td>JHT IMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition</th>\n",
       "      <td>R0080659 Undersea Systems Expert (Open)</td>\n",
       "      <td>R0080210 Vehicle Electrical Engineer (Open)</td>\n",
       "      <td>R0079045 Voice Network Solution Architect (Open)</td>\n",
       "      <td>R0079571 Warehouse Specialist (Open)</td>\n",
       "      <td>R0080384 Web Developer, Senior (Open)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Type</th>\n",
       "      <td>Capability Building</td>\n",
       "      <td>Sold and Funded</td>\n",
       "      <td>Contingent</td>\n",
       "      <td>Contingent</td>\n",
       "      <td>Contingent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <td>San Diego Cluster</td>\n",
       "      <td>Huntsville Cluster</td>\n",
       "      <td>Wash Metro Cluster</td>\n",
       "      <td>Wash Metro Cluster</td>\n",
       "      <td>Wash Metro Cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time Type</th>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting Title</th>\n",
       "      <td>Undersea Systems Expert</td>\n",
       "      <td>Vehicle Electrical Engineer</td>\n",
       "      <td>Voice Network Solution Architect</td>\n",
       "      <td>Warehouse Specialist</td>\n",
       "      <td>Web Developer, Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Safi Recommendation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recruiting Start Date</th>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>2020-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Group</th>\n",
       "      <td>NMC ACCT GROUP</td>\n",
       "      <td>ARMY ACCT GROUP</td>\n",
       "      <td>ARMY ACCT GROUP</td>\n",
       "      <td>ARMY ACCT GROUP</td>\n",
       "      <td>JHT ACCT GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition ID</th>\n",
       "      <td>R0080659</td>\n",
       "      <td>R0080210</td>\n",
       "      <td>R0079045</td>\n",
       "      <td>R0079571</td>\n",
       "      <td>R0080384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Type</th>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supervisory Organization</th>\n",
       "      <td>Supervisory Organization (Eric Jones | Eric R ...</td>\n",
       "      <td>Supervisory Organization (Joseph Hall (504630))</td>\n",
       "      <td>Supervisory Organization (Patrick Ward (522638))</td>\n",
       "      <td>Supervisory Organization (Kent Friederich (535...</td>\n",
       "      <td>Supervisory Organization (Justin Knapp (522001))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearance Agency</th>\n",
       "      <td>DOD</td>\n",
       "      <td>DOD</td>\n",
       "      <td>DOD</td>\n",
       "      <td>DOD</td>\n",
       "      <td>FBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location State/Province</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Furthest Stage</th>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Manager</th>\n",
       "      <td>Kristen Cooper (609973)</td>\n",
       "      <td>Jessica McCann (602189)</td>\n",
       "      <td>Kathryn Kirkman | Cayt Kirkman (527258)</td>\n",
       "      <td>Neil Kramer (542022)</td>\n",
       "      <td>Emily Sylling (504033)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location</th>\n",
       "      <td>USA, WA, Keyport (610 Dowell St)</td>\n",
       "      <td>USA, MI, Warren (6501 E 11 Mile Rd)</td>\n",
       "      <td>USA, VA, Alexandria (6361 Walker Ln)</td>\n",
       "      <td>USA, VA, Fort Belvoir (10099 Gunston Rd)</td>\n",
       "      <td>USA, VA, Quantico (Bldg 27958A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Description</th>\n",
       "      <td>Key Role:\\nEvaluate the operation of marine ve...</td>\n",
       "      <td>The Challenge:\\nWhat if you could use your eng...</td>\n",
       "      <td>Key Role:\\nMaintain oversight and responsibili...</td>\n",
       "      <td>Key Role:\\nAnalyze the development and impleme...</td>\n",
       "      <td>The Challenge:\\nAre you looking for an opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "      <td>CIVILIAN SERVICES GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Profile</th>\n",
       "      <td>Naval Engineer Sr</td>\n",
       "      <td>Electrical Engineer Mid</td>\n",
       "      <td>IT Infra Program Manager Sr</td>\n",
       "      <td>Logistics Analyst Mid</td>\n",
       "      <td>Full Stack Developer Sr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family Group</th>\n",
       "      <td>Engineering &amp; Science Professional</td>\n",
       "      <td>Engineering &amp; Science Professional</td>\n",
       "      <td>Engineering &amp; Science Professional</td>\n",
       "      <td>Engineering &amp; Science Professional</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSO</th>\n",
       "      <td>E&amp;S</td>\n",
       "      <td>E&amp;S</td>\n",
       "      <td>E&amp;S</td>\n",
       "      <td>E&amp;S</td>\n",
       "      <td>Digital Solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family</th>\n",
       "      <td>Aerospace &amp; Ocean Engineer</td>\n",
       "      <td>Electrical and Electronics Engineer</td>\n",
       "      <td>IT Infrastructure Program Manager</td>\n",
       "      <td>Life Cycle and Operational Logistics Professional</td>\n",
       "      <td>Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Status</th>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Title</th>\n",
       "      <td>Naval Engineer Sr</td>\n",
       "      <td>Electrical Engineer Mid</td>\n",
       "      <td>IT Infra Program Manager Sr</td>\n",
       "      <td>Logistics Analyst Mid</td>\n",
       "      <td>Full Stack Developer Sr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting</th>\n",
       "      <td>Undersea Systems Expert</td>\n",
       "      <td>Vehicle Electrical Engineer</td>\n",
       "      <td>Voice Network Solution Architect</td>\n",
       "      <td>Warehouse Specialist</td>\n",
       "      <td>Web Developer, Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location Country</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Required Clearance</th>\n",
       "      <td>Top Secret</td>\n",
       "      <td>Secret</td>\n",
       "      <td>Secret</td>\n",
       "      <td>Secret</td>\n",
       "      <td>Top Secret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Recruiter</th>\n",
       "      <td>Kristen Cooper (609973)</td>\n",
       "      <td>Jessica McCann (602189)</td>\n",
       "      <td>Jonathan Reid (900148)[C]</td>\n",
       "      <td>Ilissa Manes (838264)[C]</td>\n",
       "      <td>Danielle Barbarite (594951)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_fit</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_opportunity_application_emailed</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_remote_delivery</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_for_university_recruiting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 4545  \\\n",
       "Hiring Manager                                     Eric Jones | Eric R Jones (552060)   \n",
       "Management Level                                                            Associate   \n",
       "IMT                                                                NMC ENG & TECH IMT   \n",
       "Job Requisition                               R0080659 Undersea Systems Expert (Open)   \n",
       "Job Requisition Type                                              Capability Building   \n",
       "Cluster                                                             San Diego Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                             Undersea Systems Expert   \n",
       "Safi Recommendation                                                               NaN   \n",
       "Recruiting Start Date                                                      2020-03-11   \n",
       "Account Group                                                          NMC ACCT GROUP   \n",
       "Job Requisition ID                                                           R0080659   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization            Supervisory Organization (Eric Jones | Eric R ...   \n",
       "Clearance Agency                                                                  DOD   \n",
       "Primary Location State/Province                                            Washington   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                              Kristen Cooper (609973)   \n",
       "Primary Location                                     USA, WA, Keyport (610 Dowell St)   \n",
       "Job Description                     Key Role:\\nEvaluate the operation of marine ve...   \n",
       "Group                                                            GLOBAL DEFENSE GROUP   \n",
       "Job Profile                                                         Naval Engineer Sr   \n",
       "Job Family Group                                   Engineering & Science Professional   \n",
       "FSO                                                                               E&S   \n",
       "Job Family                                                 Aerospace & Ocean Engineer   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                      Naval Engineer Sr   \n",
       "Job Posting                                                   Undersea Systems Expert   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                         Top Secret   \n",
       "Primary Recruiter                                             Kristen Cooper (609973)   \n",
       "percent_fit                                                                       NaN   \n",
       "is_opportunity_application_emailed                                              False   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 4546  \\\n",
       "Hiring Manager                                                   Joseph Hall (504630)   \n",
       "Management Level                                                    Senior Consultant   \n",
       "IMT                                                                  ARMY WEAPONS IMT   \n",
       "Job Requisition                           R0080210 Vehicle Electrical Engineer (Open)   \n",
       "Job Requisition Type                                                  Sold and Funded   \n",
       "Cluster                                                            Huntsville Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                         Vehicle Electrical Engineer   \n",
       "Safi Recommendation                                                               NaN   \n",
       "Recruiting Start Date                                                      2020-03-05   \n",
       "Account Group                                                         ARMY ACCT GROUP   \n",
       "Job Requisition ID                                                           R0080210   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization              Supervisory Organization (Joseph Hall (504630))   \n",
       "Clearance Agency                                                                  DOD   \n",
       "Primary Location State/Province                                              Michigan   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                              Jessica McCann (602189)   \n",
       "Primary Location                                  USA, MI, Warren (6501 E 11 Mile Rd)   \n",
       "Job Description                     The Challenge:\\nWhat if you could use your eng...   \n",
       "Group                                                            GLOBAL DEFENSE GROUP   \n",
       "Job Profile                                                   Electrical Engineer Mid   \n",
       "Job Family Group                                   Engineering & Science Professional   \n",
       "FSO                                                                               E&S   \n",
       "Job Family                                        Electrical and Electronics Engineer   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                Electrical Engineer Mid   \n",
       "Job Posting                                               Vehicle Electrical Engineer   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             Secret   \n",
       "Primary Recruiter                                             Jessica McCann (602189)   \n",
       "percent_fit                                                                       NaN   \n",
       "is_opportunity_application_emailed                                              False   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 4547  \\\n",
       "Hiring Manager                                                  Patrick Ward (522638)   \n",
       "Management Level                                                            Associate   \n",
       "IMT                                                                      ARMY ISE IMT   \n",
       "Job Requisition                      R0079045 Voice Network Solution Architect (Open)   \n",
       "Job Requisition Type                                                       Contingent   \n",
       "Cluster                                                            Wash Metro Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                    Voice Network Solution Architect   \n",
       "Safi Recommendation                                                               NaN   \n",
       "Recruiting Start Date                                                      2020-02-19   \n",
       "Account Group                                                         ARMY ACCT GROUP   \n",
       "Job Requisition ID                                                           R0079045   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization             Supervisory Organization (Patrick Ward (522638))   \n",
       "Clearance Agency                                                                  DOD   \n",
       "Primary Location State/Province                                              Virginia   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                              Kathryn Kirkman | Cayt Kirkman (527258)   \n",
       "Primary Location                                 USA, VA, Alexandria (6361 Walker Ln)   \n",
       "Job Description                     Key Role:\\nMaintain oversight and responsibili...   \n",
       "Group                                                            GLOBAL DEFENSE GROUP   \n",
       "Job Profile                                               IT Infra Program Manager Sr   \n",
       "Job Family Group                                   Engineering & Science Professional   \n",
       "FSO                                                                               E&S   \n",
       "Job Family                                          IT Infrastructure Program Manager   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                            IT Infra Program Manager Sr   \n",
       "Job Posting                                          Voice Network Solution Architect   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             Secret   \n",
       "Primary Recruiter                                           Jonathan Reid (900148)[C]   \n",
       "percent_fit                                                                       NaN   \n",
       "is_opportunity_application_emailed                                              False   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 4548  \\\n",
       "Hiring Manager                                               Kent Friederich (535762)   \n",
       "Management Level                                                    Senior Consultant   \n",
       "IMT                                                                  ARMY SOLDIER IMT   \n",
       "Job Requisition                                  R0079571 Warehouse Specialist (Open)   \n",
       "Job Requisition Type                                                       Contingent   \n",
       "Cluster                                                            Wash Metro Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                                Warehouse Specialist   \n",
       "Safi Recommendation                                                               NaN   \n",
       "Recruiting Start Date                                                      2020-02-25   \n",
       "Account Group                                                         ARMY ACCT GROUP   \n",
       "Job Requisition ID                                                           R0079571   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization            Supervisory Organization (Kent Friederich (535...   \n",
       "Clearance Agency                                                                  DOD   \n",
       "Primary Location State/Province                                              Virginia   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                                 Neil Kramer (542022)   \n",
       "Primary Location                             USA, VA, Fort Belvoir (10099 Gunston Rd)   \n",
       "Job Description                     Key Role:\\nAnalyze the development and impleme...   \n",
       "Group                                                            GLOBAL DEFENSE GROUP   \n",
       "Job Profile                                                     Logistics Analyst Mid   \n",
       "Job Family Group                                   Engineering & Science Professional   \n",
       "FSO                                                                               E&S   \n",
       "Job Family                          Life Cycle and Operational Logistics Professional   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                  Logistics Analyst Mid   \n",
       "Job Posting                                                      Warehouse Specialist   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             Secret   \n",
       "Primary Recruiter                                            Ilissa Manes (838264)[C]   \n",
       "percent_fit                                                                       NaN   \n",
       "is_opportunity_application_emailed                                              False   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 4549  \n",
       "Hiring Manager                                                  Justin Knapp (522001)  \n",
       "Management Level                                                            Associate  \n",
       "IMT                                                                           JHT IMT  \n",
       "Job Requisition                                 R0080384 Web Developer, Senior (Open)  \n",
       "Job Requisition Type                                                       Contingent  \n",
       "Cluster                                                            Wash Metro Cluster  \n",
       "Time Type                                                                   Full time  \n",
       "Job Posting Title                                               Web Developer, Senior  \n",
       "Safi Recommendation                                                               NaN  \n",
       "Recruiting Start Date                                                      2020-03-06  \n",
       "Account Group                                                          JHT ACCT GROUP  \n",
       "Job Requisition ID                                                           R0080384  \n",
       "Job Type                                                                      Regular  \n",
       "Supervisory Organization             Supervisory Organization (Justin Knapp (522001))  \n",
       "Clearance Agency                                                                  FBI  \n",
       "Primary Location State/Province                                              Virginia  \n",
       "Furthest Stage                                                                 Review  \n",
       "Resource Manager                                               Emily Sylling (504033)  \n",
       "Primary Location                                      USA, VA, Quantico (Bldg 27958A)  \n",
       "Job Description                     The Challenge:\\nAre you looking for an opportu...  \n",
       "Group                                                         CIVILIAN SERVICES GROUP  \n",
       "Job Profile                                                   Full Stack Developer Sr  \n",
       "Job Family Group                                                           Technology  \n",
       "FSO                                                                 Digital Solutions  \n",
       "Job Family                                                       Software Engineering  \n",
       "Job Requisition Status                                                           Open  \n",
       "Business Title                                                Full Stack Developer Sr  \n",
       "Job Posting                                                     Web Developer, Senior  \n",
       "Primary Location Country                                     United States of America  \n",
       "Required Clearance                                                         Top Secret  \n",
       "Primary Recruiter                                         Danielle Barbarite (594951)  \n",
       "percent_fit                                                                       NaN  \n",
       "is_opportunity_application_emailed                                              False  \n",
       "is_remote_delivery                                                                NaN  \n",
       "is_for_university_recruiting                                                      NaN  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hunting_df.tail(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Emailing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "com_error",
     "evalue": "(-2146959355, 'Server execution failed', None, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36m_GetGoodDispatch\u001b[1;34m(IDispatch, clsctx)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                         \u001b[0mIDispatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpythoncom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIDispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mpythoncom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mole_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147221021, 'Operation unavailable', None, None)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-619894352018>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwin32com\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutlook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwin32com\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Outlook.Application'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetNamespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MAPI'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'outlook.{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutlook\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\win32com\\client\\__init__.py\u001b[0m in \u001b[0;36mDispatch\u001b[1;34m(dispatch, userName, resultCLSID, typeinfo, UnicodeToString, clsctx)\u001b[0m\n\u001b[0;32m     93\u001b[0m   \"\"\"\n\u001b[0;32m     94\u001b[0m   \u001b[1;32massert\u001b[0m \u001b[0mUnicodeToString\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"this is deprecated and will go away\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m   \u001b[0mdispatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_GetGoodDispatchAndUserName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muserName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclsctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m__WrapDispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresultCLSID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypeinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclsctx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclsctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36m_GetGoodDispatchAndUserName\u001b[1;34m(IDispatch, userName, clsctx)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[0muserName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_GetGoodDispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIDispatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclsctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_GetDescInvokeType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvoke_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36m_GetGoodDispatch\u001b[1;34m(IDispatch, clsctx)\u001b[0m\n\u001b[0;32m     89\u001b[0m                         \u001b[0mIDispatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpythoncom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIDispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mpythoncom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mole_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m                         \u001b[0mIDispatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpythoncom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCoCreateInstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIDispatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclsctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpythoncom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIID_IDispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[1;31m# may already be a wrapped class.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2146959355, 'Server execution failed', None, None)"
     ]
    }
   ],
   "source": [
    "\n",
    "import win32com.client\n",
    "\n",
    "outlook = win32com.client.Dispatch('Outlook.Application').GetNamespace('MAPI')\n",
    "print(['outlook.{}'.format(fn) for fn in dir(outlook) if not fn.startswith('_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Rescore the quals dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "# Get the training data and models\n",
    "X = tfidf_matrix.toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "estimators_list = [AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0, n_estimators=50, random_state=None),\n",
    "                   BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
    "                                     n_estimators=10, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None,\n",
    "                                        max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=100, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None, learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "                                              max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                              min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                                              n_iter_no_change=None, presort='deprecated', random_state=None, subsample=1.0, tol=0.0001,\n",
    "                                              validation_fraction=0.1, verbose=0, warm_start=False),\n",
    "                   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features='auto',\n",
    "                                          max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                          min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "                                          oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                                      multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                                      warm_start=False),\n",
    "                   SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3,\n",
    "                       gamma='scale', kernel='rbf', max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001, verbose=False)]\n",
    "\n",
    "# Fit the data and add the duration and fitted models to lists\n",
    "fit_estimators_list = []\n",
    "training_durations_list = []\n",
    "for clf in estimators_list:\n",
    "    start_time = time.time()\n",
    "    fit_estimators_list.append(clf.fit(X, y))\n",
    "    stop_time = time.time()\n",
    "    training_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(estimators_list=fit_estimators_list, training_durations_list=training_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimators_list = s.load_object('estimators_list')\n",
    "inference_durations_list = []\n",
    "for clf in estimators_list:\n",
    "    clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "    basic_quals_df[clf_name] = np.nan\n",
    "    start_time = time.time()\n",
    "    for row_index, row_series in basic_quals_df.iterrows():\n",
    "        qualification_str = row_series.qualification_str\n",
    "        X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "        y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "        basic_quals_df.loc[row_index, clf_name] = y_predict_proba\n",
    "    stop_time = time.time()\n",
    "    inference_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(basic_quals_df=basic_quals_df, inference_durations_list=inference_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "s = Storage()\n",
    "\n",
    "estimators_list = s.load_object('estimators_list')\n",
    "clf = StackingClassifier(estimators=[(str(type(e)).split('.')[-1].split(\"'\")[0], e) for e in estimators_list],\n",
    "                         final_estimator=None, cv=None, stack_method='auto', n_jobs=None, passthrough=False, verbose=0)\n",
    "clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "basic_quals_df = s.load_object('basic_quals_df')\n",
    "basic_quals_df[clf_name] = np.nan\n",
    "fit_estimators_list = estimators_list.copy()\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "X = bq_tt.transform(bq_cv.transform(basic_quals_df.qualification_str.tolist())).toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "start_time = time.time()\n",
    "fit_estimators_list.append(clf.fit(X, y))\n",
    "stop_time = time.time()\n",
    "training_durations_list = s.load_object('training_durations_list')\n",
    "training_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(fit_estimators_list=fit_estimators_list, training_durations_list=training_durations_list)\n",
    "\n",
    "# Re-score the quals dataframe\n",
    "inference_durations_list = s.load_object('inference_durations_list')\n",
    "start_time = time.time()\n",
    "for row_index, row_series in basic_quals_df.iterrows():\n",
    "    qualification_str = row_series.qualification_str\n",
    "    X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "    y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "    basic_quals_df.loc[row_index, clf_name] = y_predict_proba\n",
    "stop_time = time.time()\n",
    "inference_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(basic_quals_df=basic_quals_df, inference_durations_list=inference_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf = VotingClassifier(estimators=[(str(type(e)).split('.')[-1].split(\"'\")[0], e) for e in estimators_list],\n",
    "                       voting='soft', weights=None, n_jobs=None, flatten_transform=True)\n",
    "clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "basic_quals_df[clf_name] = np.nan\n",
    "fit_estimators_list = s.load_object('fit_estimators_list')\n",
    "start_time = time.time()\n",
    "fit_estimators_list.append(clf.fit(X, y))\n",
    "stop_time = time.time()\n",
    "training_durations_list = s.load_object('training_durations_list')\n",
    "training_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(fit_estimators_list=fit_estimators_list, training_durations_list=training_durations_list)\n",
    "\n",
    "# Re-score the quals dataframe\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "inference_durations_list = s.load_object('inference_durations_list')\n",
    "start_time = time.time()\n",
    "for row_index, row_series in basic_quals_df.iterrows():\n",
    "    qualification_str = row_series.qualification_str\n",
    "    X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "    y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "    basic_quals_df.loc[row_index, clf_name] = y_predict_proba\n",
    "stop_time = time.time()\n",
    "inference_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(basic_quals_df=basic_quals_df, inference_durations_list=inference_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(basic_quals_df.columns.tolist())\n",
    "basic_quals_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import inspect\n",
    "\n",
    "metrics_list = ['accuracy_score', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision_score',\n",
    "                'balanced_accuracy_score', 'cohen_kappa_score', 'completeness_score', 'explained_variance_score',\n",
    "                'f1_score', 'fowlkes_mallows_score', 'homogeneity_score', 'jaccard_score', 'mutual_info_score',\n",
    "                'normalized_mutual_info_score', 'precision_score', 'r2_score', 'recall_score', 'roc_auc_score', 'v_measure_score']\n",
    "description_dict = {name: fn.__doc__.strip().split('\\n')[0] for name, fn in inspect.getmembers(sys.modules[__name__],\n",
    "                                                                                               inspect.isfunction) if name in metrics_list}\n",
    "for name, cls in inspect.getmembers(sys.modules[__name__], inspect.isclass):\n",
    "    if name in entropy_df.index:\n",
    "        description_dict[name] = cls.__doc__.strip().split('\\n')[0]\n",
    "s.store_objects(metrics_list=metrics_list, description_dict=description_dict)\n",
    "exec('from sklearn.metrics import {}'.format(', '.join(metrics_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "fit_estimators_list = s.load_object('fit_estimators_list')\n",
    "clf_name_list = [str(type(clf)).split('.')[-1].split(\"'\")[0] for clf in fit_estimators_list]\n",
    "basic_quals_df = s.load_object('basic_quals_df')\n",
    "y_true = basic_quals_df.is_fit.tolist()\n",
    "fit_match_series = (basic_quals_df.is_fit == 1)\n",
    "yes_list = basic_quals_df[fit_match_series].is_fit.tolist()\n",
    "no_list = basic_quals_df[~fit_match_series].is_fit.tolist()\n",
    "columns_list = ['clf_name', 'training_duration', 'inference_duration', 'boundary_diff', 'clf_yes_entropy', 'relative_yes_entropy'] + metrics_list\n",
    "rows_list = []\n",
    "training_durations_list = s.load_object('training_durations_list')\n",
    "inference_durations_list = s.load_object('inference_durations_list')\n",
    "for column_name, training_duration, inference_duration in zip(clf_name_list, training_durations_list, inference_durations_list):\n",
    "    yes_series = basic_quals_df[fit_match_series][column_name]\n",
    "    upper_bound = yes_series.min()\n",
    "    no_series = basic_quals_df[~fit_match_series][column_name]\n",
    "    lower_bound = no_series.max()\n",
    "    y_pred = []\n",
    "    for p in basic_quals_df[column_name]:\n",
    "        if p > 0.5:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    row_dict = {}\n",
    "    row_dict['clf_name'] = column_name\n",
    "    row_dict['training_duration'] = training_duration\n",
    "    row_dict['inference_duration'] = inference_duration\n",
    "    row_dict['boundary_diff'] = upper_bound-lower_bound\n",
    "    row_dict['clf_yes_entropy'] = entropy(pk=yes_series.tolist())\n",
    "    row_dict['relative_yes_entropy'] = entropy(pk=yes_list, qk=yes_series.tolist())\n",
    "    for metric_str in metrics_list:\n",
    "        try:\n",
    "            row_dict[metric_str] = eval('{}(y_true, basic_quals_df[column_name].tolist())'.format(metric_str))\n",
    "        except Exception as e1:\n",
    "            try:\n",
    "                row_dict[metric_str] = eval('{}(y_true, y_pred)'.format(metric_str))\n",
    "            except Exception as e2:\n",
    "                row_dict[metric_str] = np.nan\n",
    "    rows_list.append(row_dict)\n",
    "entropy_df = pd.DataFrame(rows_list, columns=columns_list).dropna(axis='columns', how='all')\n",
    "entropy_df.set_index('clf_name', drop=True, inplace=True)\n",
    "s.store_objects(entropy_df=entropy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['training_duration', 'inference_duration', 'balanced_accuracy_score', 'r2_score']\n",
    "entropy_df[columns_list].sort_values('balanced_accuracy_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entropy_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit_estimators_list = s.load_object('fit_estimators_list')\n",
    "fit_estimators_dict = {str(type(clf)).split('.')[-1].split(\"'\")[0]: clf for clf in fit_estimators_list}\n",
    "s.store_objects(fit_estimators_dict=fit_estimators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "\n",
    "s = Storage()\n",
    "entropy_df = s.load_object('entropy_df')\n",
    "metrics_list = s.load_object('metrics_list')\n",
    "custom_metrics_list = ['boundary_diff', 'clf_yes_entropy', 'relative_yes_entropy']\n",
    "columns_list = metrics_list + custom_metrics_list\n",
    "columns_list = [cn for cn, s in sorted([(cn, entropy_df[cn].std()) for cn in columns_list], key=lambda x: x[1], reverse=True)][:3]\n",
    "for metric in columns_list:\n",
    "    print('{}: {}'.format(metric, description_dict[metric]))\n",
    "AxesSubplot_obj = entropy_df[columns_list].sort_values('r2_score', ascending=True).plot.line(rot=45, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "description_dict = s.load_object('description_dict')\n",
    "columns_list = ['training_duration', 'inference_duration', 'balanced_accuracy_score', 'r2_score']\n",
    "for metric in columns_list:\n",
    "    if metric in description_dict:\n",
    "        print('{}: {}'.format(metric, description_dict[metric]))\n",
    "entropy_df = s.load_object('entropy_df')\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_yscale('log')\n",
    "AxesSubplot_obj = entropy_df[columns_list].sort_values('training_duration', ascending=True).plot.line(rot=45, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_list = s.load_object('metrics_list')\n",
    "columns_list = [cn for cn in metrics_list if 'accur' in cn.lower()]\n",
    "for metric in columns_list:\n",
    "    if metric in description_dict:\n",
    "        print('{}: {}'.format(metric, description_dict[metric]))\n",
    "AxesSubplot_obj = entropy_df[columns_list].sort_values('accuracy_score', ascending=True).plot.line(rot=45, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entropy_df[custom_metrics_list].sort_values('boundary_diff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for metric in custom_metrics_list:\n",
    "    if metric in description_dict:\n",
    "        print('{}: {}'.format(metric, description_dict[metric]))\n",
    "AxesSubplot_obj = entropy_df[custom_metrics_list].sort_values('boundary_diff', ascending=True).plot.line(rot=45, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Manually score unscored jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.loc[436, 'percent_fit'] = (0+1+1+1+1+1)/6\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Study of the Safi recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "match_series = (hunting_df['Safi Recommendation'] == 1)\n",
    "[c[10:100].strip() for c in random.choices(population=hunting_df[match_series]['Job Description'].unique(), k=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(hunting_df=hunting_df)\n",
    "match_series = (hunting_df['Safi Recommendation'] == 1)\n",
    "hunting_df[match_series]['Primary Location State/Province'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Requisition'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Cluster'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Family'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Account Group'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Resource Manager'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Requisition Type'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Posting'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Hiring Manager'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['IMT'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Required Clearance'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Job Profile'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Management Level'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Clearance Agency'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Group'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Job Profile'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[cn for cn in columns_list if 'loca' in cn.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Primary Location'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Primary Recruiter'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Initial dataframe creation (don't run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                'Job Posting Title', 'Safi Recommendation', 'Recruiting Start Date', 'Account Group', 'Job Requisition ID',\n",
    "                'Job Type', 'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                'Resource Manager', 'Primary Location', 'Job Description', 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                'Required Clearance', 'Primary Recruiter', 'percent_fit', 'is_opportunity_application_emailed', 'is_remote_delivery']\n",
    "hunting_df = hunting_df[columns_list]\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\csv\\unresponses_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "match_series = (hunting_df.is_opportunity_application_emailed == True) & hunting_df.is_remote_delivery.isnull()\n",
    "s.save_dataframes(unresponses_df=hunting_df[match_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting'\n",
    "columns_list = []\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    #path = root.split(os.sep)\n",
    "    #print((len(path)-1) * '---', os.path.basename(root))\n",
    "    for file in files:\n",
    "        #print(len(path) * '---', file)\n",
    "        if file.endswith('.csv'):\n",
    "            print(file)\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, encoding='iso8859-1')\n",
    "                columns_list = list(set(columns_list) | set(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df = pd.DataFrame([], columns=columns_list)\n",
    "\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, encoding='iso8859-1')\n",
    "                hunting_df = pd.concat([hunting_df, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "command_str = '{sys.executable} -m pip install pyOutlook'.format(sys=sys)\n",
    "print(command_str)\n",
    "!{command_str}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
