{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\ipynb\\Job Hunting.ipynb\n",
      "['s.attempt_to_pickle', 's.data_csv_folder', 's.data_folder', 's.encoding_type', 's.load_csv', 's.load_dataframes', 's.load_object', 's.save_dataframes', 's.saves_csv_folder', 's.saves_folder', 's.saves_pickle_folder', 's.store_objects']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AdaBoostClassifier', 'Config', 'CountVectorizer', 'In', 'Out', 'RandomForestClassifier', 'SequenceMatcher', 'Storage', 'TfidfTransformer', '_', '__', '___', '__builtin__', '__builtins__', '__doc__', '__loader__', '__name__', '__nonzero__', '__package__', '__spec__', '_dh', '_i', '_i1', '_ih', '_ii', '_iii', '_oh', 'basic_quals_clf', 'basic_quals_df', 'basic_quals_dict', 'bq_cv_vocab', 'bq_tt', 'check_4_doubles', 'check_for_typos', 'conjunctify_list', 'copyfile', 'csv', 'encoding', 'exit', 'get_classifier', 'get_data_structs_df', 'get_datastructure_prediction', 'get_dir_tree', 'get_git_lfs_track_commands', 'get_importances', 'get_input_sample', 'get_ipython', 'get_module_version', 'get_notebook_path', 'get_specific_gitignore_files', 'get_struct_name', 'humanize_bytes', 'hunting_df', 'ipykernel', 'json', 'jupyter_config_dir', 'notebook_path', 'notebookapp', 'np', 'os', 'pd', 'pickle', 'preprocess_data', 'print_all_files_ending_starting_with', 'print_all_files_ending_with', 'print_all_files_starting_with', 'quit', 're', 'remove_empty_folders', 's', 'similar', 'subprocess', 'sys', 'time', 'train_test_split', 'urllib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "%run ../../load_magic/paths.py\n",
    "%run ../../load_magic/lists.py\n",
    "%run ../../load_magic/environment.py\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%pprint\n",
    "\n",
    "notebook_path = get_notebook_path()\n",
    "print(notebook_path)\n",
    "\n",
    "s = Storage()\n",
    "print(['s.{}'.format(fn) for fn in dir(s) if not fn.startswith('_')])\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "basic_quals_df = s.load_object('basic_quals_df')\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "basic_quals_clf = s.load_object('basic_quals_clf')\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Needed extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Email prep\n",
    "subject_str = '{}% fit: Internal Candidate, Dave Babbitt, for {}'\n",
    "concerns_str = 'One important question I have is if the work can be supported remotely or if this position is available for remote delivery '\n",
    "concerns_str += '(or something equivalent).'\n",
    "concerns_str += \" I don't want to move my family out of New England.\"\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "emails_dir = os.path.join(s.saves_folder, 'emails')\n",
    "os.makedirs(name=emails_dir, exist_ok=True)\n",
    "name_regex = re.compile(r'^([^(]+) \\(\\d+\\)\"')\n",
    "def clean_email(email_str):\n",
    "    match_obj = name_regex.search(email_str)\n",
    "    if match_obj:\n",
    "        email_str = match_obj.group(1)\n",
    "    names_list = re.split(r'\\s+', email_str, 0)\n",
    "    if len(names_list) >= 2:\n",
    "        first_name = names_list[0]\n",
    "        last_name = names_list[1]\n",
    "        email_str = '{}, {} [USA] <{}_{}@bah.com>'.format(last_name, first_name, last_name.lower(), first_name.lower())\n",
    "    \n",
    "    return email_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_percent_fit(row_series):\n",
    "    percent_fit = row_series['percent_fit']\n",
    "    if str(percent_fit) == 'nan':\n",
    "        percent_fit = 0\n",
    "    percent_fit = int(percent_fit*100)\n",
    "    \n",
    "    return percent_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_loc_computation(row_index, quals_list, basic_quals_dict):\n",
    "    print()\n",
    "    numerator_str_list = []\n",
    "    for qual_str in quals_list:\n",
    "        if qual_str in basic_quals_dict:\n",
    "            numerator_str_list.append(str(basic_quals_dict[qual_str]))\n",
    "        else:\n",
    "            numerator_str_list.append('000')\n",
    "    numerator_str = '+'.join(numerator_str_list)\n",
    "    print(\"hunting_df.loc[{}, 'percent_fit'] = ({})/{}\".format(row_index, numerator_str, len(quals_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions_and_counts(prediction_list, quals_list):\n",
    "    qual_count = 0\n",
    "    prediction_str = ''\n",
    "    for pred_array, qual_str in zip(prediction_list, quals_list):\n",
    "        prediction = pred_array[1]\n",
    "        prediction_str += '\\n{} {}'.format(prediction, qual_str)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return prediction_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_quals_str(prediction_list, quals_list, basic_quals_dict):\n",
    "    qual_count = 0\n",
    "    quals_str = ''\n",
    "    for pred_array, (i, qual_str) in zip(prediction_list, enumerate(quals_list)):\n",
    "        if qual_str in basic_quals_dict:\n",
    "            formatted_str = '\\nquals_list[{}] = \"{}\" ({})'\n",
    "        else:\n",
    "            formatted_str = '\\n*quals_list[{}] = \"{}\" ({})'\n",
    "        prediction = pred_array[1]\n",
    "        quals_str += formatted_str.format(i, qual_str, prediction)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return quals_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_fit_job(row_index, row_series, basic_quals_dict):\n",
    "    job_fitness = 0.0\n",
    "    job_description = row_series['Job Description']\n",
    "    quals_list = get_quals_list(job_description)\n",
    "    if len(quals_list):\n",
    "        prediction_list = list(predict_percent_fit(quals_list))\n",
    "        #prediction_str, qual_count = get_predictions_and_counts(prediction_list, quals_list)\n",
    "        quals_str, qual_count = get_quals_str(prediction_list, quals_list, basic_quals_dict)\n",
    "        job_fitness = qual_count/len(prediction_list)\n",
    "        if job_fitness > 0.8:\n",
    "            print('Basic Qualifications:{}'.format(quals_str))\n",
    "            #print(prediction_str)\n",
    "            print(job_fitness)\n",
    "            print_loc_computation(row_index, quals_list, basic_quals_dict)\n",
    "    \n",
    "    return quals_list, job_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qual_sum(qual_str):\n",
    "    results = '\"{}\"'.format(qual_str)\n",
    "    if qual_str in basic_quals_dict:\n",
    "        results = basic_quals_dict[qual_str]\n",
    "    else:\n",
    "        results = predict_percent_fit([qual_str])[0][1]\n",
    "        if results > 0.5:\n",
    "            results = 1.0\n",
    "        else:\n",
    "            results = 0.0\n",
    "    \n",
    "    return str(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_job_description(req_id):\n",
    "    match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "    job_description = hunting_df[match_series]['Job Description'].tolist()[0]\n",
    "    print(get_quals_list(job_description))\n",
    "    print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scanner_regex = re.compile(r'\\b[1-9a-zA-Z][0-9a-zA-Z]*( *[#\\+]{1,2}|\\b)')\n",
    "def regex_tokenizer(corpus):\n",
    "    \n",
    "    return [match.group() for match in re.finditer(scanner_regex, corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_list = ['Additional Qualifications?', 'Nice If You Have', 'Nice if you have', 'Nice if You Have',\n",
    "          'Additional Preferred Qualifications', 'Nice if you Have', 'Additional qualifications']\n",
    "a_str = '({}):?'.format('|'.join(a_list))\n",
    "def get_quals_list(job_description):\n",
    "    job_description = re.sub('Â', '', job_description)\n",
    "    basic_quals = ''\n",
    "    quals_list = []\n",
    "    items_list = re.split('(Key Role|The Challenge):', job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        job_description = items_list[-1].strip()\n",
    "    items_list = re.split('[\\r\\n]+(Basic Qualifications?|You Have|You have):?', job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        job_description = items_list[-1].strip()\n",
    "    items_list = re.split(a_str, job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        basic_quals = items_list[0].strip()\n",
    "    else:\n",
    "        items_list = re.split('(Clearance|Build Your Career):', job_description, 0)\n",
    "        basic_quals = items_list[0].strip()\n",
    "    if basic_quals != '':\n",
    "        quals_list = [re.sub(r'â¯', ' ', q) for q in re.split('[\\r\\n]+', basic_quals, 0)]\n",
    "        quals_list = [re.sub(r'^[?â-]+', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'[â-]+$', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '-', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '`', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(u'\\\\xa0', u' ', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'\\s+$', '', x) for x in quals_list]\n",
    "        quals_list = [x for x in quals_list if x != '']\n",
    "    \n",
    "    return quals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_emails(match_series):\n",
    "    for file_name in os.listdir(emails_dir):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(emails_dir, file_name)\n",
    "            os.remove(file_path)\n",
    "    for row_index, row_series in hunting_df[match_series].sort_values('percent_fit', ascending=False).iterrows():\n",
    "        req_str = row_series['Job Requisition']\n",
    "        percent_fit = get_percent_fit(row_series)\n",
    "        sents_list = ['I’m submitting my resume for {}.'.format(req_str),\n",
    "                      'I’ve reviewed the basic qualifications and believe I’m a good fit for this project.',\n",
    "                      'Below is a breakdown of the requirements and the amount of experience I have with each.',\n",
    "                      'I’m available at your convenience to discuss my qualifications and look forward to hearing from you.']\n",
    "        blurb_str = ' '.join(sents_list)\n",
    "        hm_str = row_series['Hiring Manager']\n",
    "        pr_str = row_series['Primary Recruiter']\n",
    "        job_description = row_series['Job Description']\n",
    "        quals_list = get_quals_list(job_description)\n",
    "        quals_str = '\\n•\\t' + '\\n•\\t'.join(quals_list)\n",
    "        file_path = os.path.join(emails_dir, '{}_email.txt'.format(row_series['Job Requisition ID'].strip()))\n",
    "        if not os.path.isfile(file_path):\n",
    "            with open(file_path, 'w', encoding=s.encoding_type) as io_wrapper:\n",
    "                print('', file=io_wrapper)\n",
    "                print('To: {}; {}'.format(clean_email(hm_str), clean_email(pr_str)), file=io_wrapper)\n",
    "                print('CC: Safi, Claudia [USA] <safi_claudia@bah.com>; Borrelli, Bill [USA] <Borrelli_Bill@bah.com>', file=io_wrapper)\n",
    "                print(subject_str.format(percent_fit, req_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Dear {},'.format(hm_str.split(' ')[0]), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('{}'.format(blurb_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Basic Qualifications:{}'.format(quals_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print(concerns_str, file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Attached: Dave_Babbitt_Resume_for_{}.pdf'.format('_'.join(re.split(r'[ \\\\\\/:\\*\\?\"><\\|]+', req_str, 0))),\n",
    "                      file=io_wrapper)\n",
    "            !\"{text_editor_path}\" \"{os.path.abspath(file_path)}\"\n",
    "    !start %windir%\\explorer.exe \"{os.path.abspath(emails_dir)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\basic_quals_df.pickle\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\bq_cv_vocab.pickle\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\bq_tt.pickle\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\basic_quals_clf.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Rebuild the datframe from the dictionary\n",
    "rows_list = [{'qualification_str': qualification_str, 'is_fit': is_fit} for qualification_str, is_fit in basic_quals_dict.items()]\n",
    "basic_quals_df = pd.DataFrame(rows_list)\n",
    "s.store_objects(basic_quals_df=basic_quals_df)\n",
    "\n",
    "# Re-transform the bag-of-words and tf-idf from the new manual scores\n",
    "sents_list = basic_quals_df.qualification_str.tolist()\n",
    "\n",
    "# Bag-of-words\n",
    "cv = CountVectorizer(lowercase=True, tokenizer=regex_tokenizer, token_pattern=r'\\b[1-9a-zA-Z][0-9a-zA-Z]*[#\\+]{0,2}', ngram_range=(1, 2))\n",
    "bow_matrix = cv.fit_transform(sents_list)\n",
    "s.store_objects(bq_cv_vocab=cv.vocabulary_)\n",
    "\n",
    "# Tf-idf, must get from BOW first\n",
    "tt = TfidfTransformer()\n",
    "tfidf_matrix = tt.fit_transform(bow_matrix)\n",
    "s.store_objects(bq_tt=tt)\n",
    "\n",
    "# Re-train the classifier\n",
    "X = tfidf_matrix.toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "basic_quals_clf = RandomForestClassifier(n_estimators=997)\n",
    "#basic_quals_clf = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=RandomForestClassifier(n_estimators=997),\n",
    "#                                     learning_rate=1.0, n_estimators=50, random_state=None)\n",
    "basic_quals_clf.fit(X, y)\n",
    "s.store_objects(basic_quals_clf=basic_quals_clf)\n",
    "\n",
    "# Re-calibrate the inference engine\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "def predict_percent_fit(quals_list):\n",
    "    y_predict_proba = np.array([])\n",
    "    if len(quals_list):\n",
    "        X_test = bq_tt.transform(bq_cv.transform(quals_list)).toarray()\n",
    "        y_predict_proba = basic_quals_clf.predict_proba(X_test)\n",
    "    \n",
    "    return y_predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Look for a fit greater than 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Qualifications:\n",
      "quals_list[0] = \"5+ years of experience with IT\" (0.6639919759277834)\n",
      "quals_list[1] = \"Experience with building Python assessment features\" (0.6288866599799399)\n",
      "quals_list[2] = \"Experience with adding new Jenkins and Maven plugins\" (0.31795386158475425)\n",
      "quals_list[3] = \"Ability to collaborate with others effectively\" (0.6619859578736209)\n",
      "quals_list[4] = \"Ability to learn new concepts and technologies quickly\" (0.720160481444333)\n",
      "quals_list[5] = \"Ability to travel up to 70% of the time\" (0.7151454363089268)\n",
      "quals_list[6] = \"HS diploma or GED\" (0.831494483450351)\n",
      "0.8571428571428571\n",
      "\n",
      "hunting_df.loc[185, 'percent_fit'] = (1+0+0+1+1+1+1)/7\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n",
      "Basic Qualifications:\n",
      "*quals_list[0] = \"2+ years of experience with Azure, AWS, or Google Cloud platforms\" (0.6529588766298897)\n",
      "*quals_list[1] = \"2+ years of experience in a systems engineering or systems administration role\" (0.4247743229689067)\n",
      "*quals_list[2] = \"Experience with administering Windows- and Linux-based systems\" (0.7191574724172518)\n",
      "*quals_list[3] = \"Ability to script in a language such as Bash or Python\" (0.8234704112337011)\n",
      "quals_list[4] = \"Ability to obtain a security clearance\" (0.8375125376128385)\n",
      "quals_list[5] = \"BA or BS degree\" (0.8886659979939819)\n",
      "0.8333333333333334\n",
      "\n",
      "hunting_df.loc[187, 'percent_fit'] = (000+000+000+000+1+1)/6\n",
      "413/3310 = 12% completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "match_series = (hunting_df.percent_fit >= 0.0)\n",
    "for row_index, row_series in hunting_df[~match_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)\n",
    "    if job_fitness > 0.8:\n",
    "        if all(qual_str in basic_quals_dict for qual_str in quals_list):\n",
    "            hunting_df.loc[row_index, 'percent_fit'] = eval(' + '.join(map(qual_sum, quals_list))) / len(quals_list)\n",
    "            s.store_objects(hunting_df=hunting_df)\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        if len(quals_list):\n",
    "            hunting_df.loc[row_index, 'percent_fit'] = eval(' + '.join(map(qual_sum, quals_list))) / len(quals_list)\n",
    "            s.store_objects(hunting_df=hunting_df)\n",
    "print('{}/{} = {}% completed'.format(hunting_df[match_series].shape[0], hunting_df.shape[0],\n",
    "                                     int(100 * hunting_df[match_series].shape[0] / hunting_df.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ability to script in a language such as Bash or Python\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\basic_quals_dict.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[3]\n",
    "print(qualification_str)\n",
    "basic_quals_dict[qualification_str] = 1\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Manually score unscored jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.loc[436, 'percent_fit'] = (0+1+1+1+1+1)/6\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Rescore the quals dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "X = tfidf_matrix.toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "estimators_list = [AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0, n_estimators=50, random_state=None),\n",
    "                   BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
    "                                     n_estimators=10, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None,\n",
    "                                        max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=100, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None, learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "                                              max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                              min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                                              n_iter_no_change=None, presort='deprecated', random_state=None, subsample=1.0, tol=0.0001,\n",
    "                                              validation_fraction=0.1, verbose=0, warm_start=False),\n",
    "                   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features='auto',\n",
    "                                          max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                          min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "                                          oob_score=False, random_state=None, verbose=0, warm_start=False)]\n",
    "estimators_list = [clf.fit(X, y) for clf in estimators_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for clf in estimators_list:\n",
    "    clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "    basic_quals_df[clf_name] = np.nan\n",
    "    for row_index, row_series in basic_quals_df.iterrows():\n",
    "        qualification_str = row_series.qualification_str\n",
    "        X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "        y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "        basic_quals_df.loc[row_index, clf_name] = y_predict_proba\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = sklearn.ensemble.StackingClassifier(estimators=[(str(type(e)).split('.')[-1].split(\"'\")[0], e) for e in estimators_list],\n",
    "                                          final_estimator=None, cv=None, stack_method='auto', n_jobs=None, passthrough=False, verbose=0)\n",
    "clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "basic_quals_df[clf_name] = np.nan\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Re-score the quals dataframe\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "for row_index, row_series in basic_quals_df.iterrows():\n",
    "    qualification_str = row_series.qualification_str\n",
    "    X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "    y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "    basic_quals_df.loc[row_index, clf_name] = y_predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = sklearn.ensemble.VotingClassifier(estimators=[(str(type(e)).split('.')[-1].split(\"'\")[0], e) for e in estimators_list],\n",
    "                                        voting='soft', weights=None, n_jobs=None, flatten_transform=True)\n",
    "clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "basic_quals_df[clf_name] = np.nan\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Re-score the quals dataframe\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "for row_index, row_series in basic_quals_df.iterrows():\n",
    "    qualification_str = row_series.qualification_str\n",
    "    X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "    y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "    basic_quals_df.loc[row_index, clf_name] = y_predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['qualification_str', 'is_fit', 'AdaBoostClassifier', 'BaggingClassifier', 'ExtraTreesClassifier',\n",
    "                'GradientBoostingClassifier', 'RandomForestClassifier', 'StackingClassifier', 'VotingClassifier']\n",
    "basic_quals_df = basic_quals_df[columns_list]\n",
    "s.store_objects(basic_quals_df=basic_quals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "clf_name_list = [clf for clf in basic_quals_df.columns if clf.endswith('Classifier')]\n",
    "pk_list = basic_quals_df.is_fit.tolist()\n",
    "columns_list = ['clf_name', 'boundary_diff', 'clf_entropy', 'relative_entropy']\n",
    "rows_list = []\n",
    "for column_name in clf_name_list:\n",
    "    match_series = (basic_quals_df.is_fit == 1)\n",
    "    upper_bound = basic_quals_df[match_series][column_name].min()\n",
    "    match_series = (basic_quals_df.is_fit == 0)\n",
    "    lower_bound = basic_quals_df[match_series][column_name].max()\n",
    "    qk_list = basic_quals_df[column_name].tolist()\n",
    "    row_dict = {}\n",
    "    row_dict['clf_name'] = column_name\n",
    "    row_dict['boundary_diff'] = upper_bound-lower_bound\n",
    "    row_dict['clf_entropy'] = entropy(pk=qk_list)\n",
    "    row_dict['relative_entropy'] = entropy(pk=pk_list, qk=qk_list)\n",
    "    rows_list.append(row_dict)\n",
    "entropy_df = pd.DataFrame(rows_list, columns=columns_list)\n",
    "entropy_df.sort_values('clf_entropy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (basic_quals_df.is_fit == 1)\n",
    "basic_quals_df[match_series]['predict_proba'].min()\n",
    "#basic_quals_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (basic_quals_df.is_fit == 0)\n",
    "basic_quals_df[match_series]['predict_proba'].max()\n",
    "#basic_quals_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Create the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    \n",
    "    return 'python' in str(x).lower()\n",
    "\n",
    "match_series = hunting_df['Job Requisition Type'].isin(['Sold and Funded', 'Sold & Unfunded']) & hunting_df['Job Description'].map(f)\n",
    "match_series = match_series & (hunting_df.percent_fit >= 0.85) & ~hunting_df['is_opportunity_application_emailed']\n",
    "match_series = match_series & ~(hunting_df.is_remote_delivery == False)\n",
    "match_series = match_series & ~hunting_df['Required Clearance'].isin(['TS/SCI', 'TS/SCI w/CIP'])\n",
    "print(hunting_df[match_series].shape)\n",
    "print(hunting_df[match_series].groupby('Required Clearance').count().T.max().sort_values(ascending=False))\n",
    "hunting_df[match_series].head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_emails(match_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Flag setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note the email has been sent\n",
    "req_id = 'R0062296'.strip()\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set remote delivery for this list of jobs\n",
    "req_id_list = ['R0073564', 'R0073583', 'R0073584', 'R0073585', 'R0073586']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] == True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set remote delivery for this one job\n",
    "req_id = 'R0069681'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] == False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set university recruiting for this job\n",
    "req_id = 'R0066388'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_for_university_recruiting'] = 1\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note you can't do this job from home\n",
    "req_id = 'R0064764'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note you can't do this job from home\n",
    "hunting_df.loc[83, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.index == 2616)\n",
    "hunting_df.loc[match_series, 'is_for_university_recruiting'] = 1\n",
    "hunting_df.loc[match_series, 'percent_fit'] = 0.0\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_dict['Ability to operate independently and manage staff'] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id = 'R0073507'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "print(hunting_df[match_series]['percent_fit'].tolist())\n",
    "for row_index, row_series in hunting_df[match_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.loc[504, 'percent_fit'] = (1+1+1+1+0+1+1)/7\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>475</th>\n",
       "      <th>1390</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hiring Manager</th>\n",
       "      <td>John Brandom (568067)</td>\n",
       "      <td>John Brandom (568067)</td>\n",
       "      <td>John Brandom (568067)</td>\n",
       "      <td>John Brandom (568067)</td>\n",
       "      <td>John Brandom (568067)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Management Level</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Senior Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMT</th>\n",
       "      <td>JCC IMT</td>\n",
       "      <td>JCC IMT</td>\n",
       "      <td>JCC IMT</td>\n",
       "      <td>JCC IMT</td>\n",
       "      <td>JCC IMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition</th>\n",
       "      <td>R0073583 Data Engineer (Open)</td>\n",
       "      <td>R0073584 Data Engineer (Open)</td>\n",
       "      <td>R0073564 Data Engineer (Open)</td>\n",
       "      <td>R0073585 Data Scientist (Open)</td>\n",
       "      <td>R0073586 Software Developer (Open)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Type</th>\n",
       "      <td>Sold and Funded</td>\n",
       "      <td>Sold and Funded</td>\n",
       "      <td>Sold and Funded</td>\n",
       "      <td>Sold and Funded</td>\n",
       "      <td>Sold and Funded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <td>Fayetteville Cluster</td>\n",
       "      <td>Fayetteville Cluster</td>\n",
       "      <td>Fayetteville Cluster</td>\n",
       "      <td>Fayetteville Cluster</td>\n",
       "      <td>Fayetteville Cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time Type</th>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting Title</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Software Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Safi Recommendation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recruiting Start Date</th>\n",
       "      <td>11/20/2019</td>\n",
       "      <td>11/20/2019</td>\n",
       "      <td>11/20/2019</td>\n",
       "      <td>11/20/2019</td>\n",
       "      <td>11/20/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Group</th>\n",
       "      <td>JCC ACCT GROUP</td>\n",
       "      <td>JCC ACCT GROUP</td>\n",
       "      <td>JCC ACCT GROUP</td>\n",
       "      <td>JCC ACCT GROUP</td>\n",
       "      <td>JCC ACCT GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition ID</th>\n",
       "      <td>R0073583</td>\n",
       "      <td>R0073584</td>\n",
       "      <td>R0073564</td>\n",
       "      <td>R0073585</td>\n",
       "      <td>R0073586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Type</th>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supervisory Organization</th>\n",
       "      <td>Supervisory Organization (John Brandom (568067))</td>\n",
       "      <td>Supervisory Organization (John Brandom (568067))</td>\n",
       "      <td>Supervisory Organization (John Brandom (568067))</td>\n",
       "      <td>Supervisory Organization (John Brandom (568067))</td>\n",
       "      <td>Supervisory Organization (John Brandom (568067))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearance Agency</th>\n",
       "      <td>DOD SCI</td>\n",
       "      <td>DOD</td>\n",
       "      <td>DOD</td>\n",
       "      <td>DOD</td>\n",
       "      <td>DOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location State/Province</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>North Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Furthest Stage</th>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "      <td>Interview</td>\n",
       "      <td>Interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Manager</th>\n",
       "      <td>Beth Mellott (510067)</td>\n",
       "      <td>Beth Mellott (510067)</td>\n",
       "      <td>Beth Mellott (510067)</td>\n",
       "      <td>Beth Mellott (510067)</td>\n",
       "      <td>Beth Mellott (510067)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location</th>\n",
       "      <td>USA, NC, Fayetteville (4200 Morganton Rd Suite...</td>\n",
       "      <td>USA, NC, Fayetteville (4200 Morganton Rd Suite...</td>\n",
       "      <td>USA, NC, Fayetteville (4200 Morganton Rd Suite...</td>\n",
       "      <td>USA, NC, Fayetteville (4200 Morganton Rd Suite...</td>\n",
       "      <td>USA, NC, Fayetteville (4200 Morganton Rd Suite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Description</th>\n",
       "      <td>Key Role:\\nSupport configuration and ingestion...</td>\n",
       "      <td>Key Role:\\nSupport configuration and ingestion...</td>\n",
       "      <td>Key Role:\\nSupport the configuration and inges...</td>\n",
       "      <td>The Challenge:\\nAre you excited at the prospec...</td>\n",
       "      <td>The Challenge:\\nAre you looking for an opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Profile</th>\n",
       "      <td>Data Engineer Mid</td>\n",
       "      <td>Data Engineer Mid</td>\n",
       "      <td>Data Engineer Mid</td>\n",
       "      <td>Data Scientist Mid</td>\n",
       "      <td>Full Stack Developer Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family Group</th>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSO</th>\n",
       "      <td>Digital Solutions</td>\n",
       "      <td>Digital Solutions</td>\n",
       "      <td>Digital Solutions</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>Digital Solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family</th>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Status</th>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Title</th>\n",
       "      <td>Data Engineer Mid</td>\n",
       "      <td>Data Engineer Mid</td>\n",
       "      <td>Data Engineer Mid</td>\n",
       "      <td>Data Scientist Mid</td>\n",
       "      <td>Full Stack Developer Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Software Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location Country</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Required Clearance</th>\n",
       "      <td>TS/SCI</td>\n",
       "      <td>Secret</td>\n",
       "      <td>Secret</td>\n",
       "      <td>Secret</td>\n",
       "      <td>Secret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Recruiter</th>\n",
       "      <td>Alexander Mosiniak (900620)[C]</td>\n",
       "      <td>Alexander Mosiniak (900620)[C]</td>\n",
       "      <td>Alexander Mosiniak (900620)[C]</td>\n",
       "      <td>Alexander Mosiniak (900620)[C]</td>\n",
       "      <td>Alexander Mosiniak (900620)[C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_fit</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_opportunity_application_emailed</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_remote_delivery</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_for_university_recruiting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 426   \\\n",
       "Hiring Manager                                                  John Brandom (568067)   \n",
       "Management Level                                                    Senior Consultant   \n",
       "IMT                                                                           JCC IMT   \n",
       "Job Requisition                                         R0073583 Data Engineer (Open)   \n",
       "Job Requisition Type                                                  Sold and Funded   \n",
       "Cluster                                                          Fayetteville Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                                       Data Engineer   \n",
       "Safi Recommendation                                                                 0   \n",
       "Recruiting Start Date                                                      11/20/2019   \n",
       "Account Group                                                          JCC ACCT GROUP   \n",
       "Job Requisition ID                                                           R0073583   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization             Supervisory Organization (John Brandom (568067))   \n",
       "Clearance Agency                                                              DOD SCI   \n",
       "Primary Location State/Province                                        North Carolina   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                                Beth Mellott (510067)   \n",
       "Primary Location                    USA, NC, Fayetteville (4200 Morganton Rd Suite...   \n",
       "Job Description                     Key Role:\\nSupport configuration and ingestion...   \n",
       "Group                                                            GLOBAL DEFENSE GROUP   \n",
       "Job Profile                                                         Data Engineer Mid   \n",
       "Job Family Group                                                           Technology   \n",
       "FSO                                                                 Digital Solutions   \n",
       "Job Family                                                           Data Engineering   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                      Data Engineer Mid   \n",
       "Job Posting                                                             Data Engineer   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             TS/SCI   \n",
       "Primary Recruiter                                      Alexander Mosiniak (900620)[C]   \n",
       "percent_fit                                                                  0.833333   \n",
       "is_opportunity_application_emailed                                               True   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 427   \\\n",
       "Hiring Manager                                                  John Brandom (568067)   \n",
       "Management Level                                                    Senior Consultant   \n",
       "IMT                                                                           JCC IMT   \n",
       "Job Requisition                                         R0073584 Data Engineer (Open)   \n",
       "Job Requisition Type                                                  Sold and Funded   \n",
       "Cluster                                                          Fayetteville Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                                       Data Engineer   \n",
       "Safi Recommendation                                                                 0   \n",
       "Recruiting Start Date                                                      11/20/2019   \n",
       "Account Group                                                          JCC ACCT GROUP   \n",
       "Job Requisition ID                                                           R0073584   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization             Supervisory Organization (John Brandom (568067))   \n",
       "Clearance Agency                                                                  DOD   \n",
       "Primary Location State/Province                                        North Carolina   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                                Beth Mellott (510067)   \n",
       "Primary Location                    USA, NC, Fayetteville (4200 Morganton Rd Suite...   \n",
       "Job Description                     Key Role:\\nSupport configuration and ingestion...   \n",
       "Group                                                            GLOBAL DEFENSE GROUP   \n",
       "Job Profile                                                         Data Engineer Mid   \n",
       "Job Family Group                                                           Technology   \n",
       "FSO                                                                 Digital Solutions   \n",
       "Job Family                                                           Data Engineering   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                      Data Engineer Mid   \n",
       "Job Posting                                                             Data Engineer   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             Secret   \n",
       "Primary Recruiter                                      Alexander Mosiniak (900620)[C]   \n",
       "percent_fit                                                                  0.833333   \n",
       "is_opportunity_application_emailed                                               True   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 428   \\\n",
       "Hiring Manager                                                  John Brandom (568067)   \n",
       "Management Level                                                    Senior Consultant   \n",
       "IMT                                                                           JCC IMT   \n",
       "Job Requisition                                         R0073564 Data Engineer (Open)   \n",
       "Job Requisition Type                                                  Sold and Funded   \n",
       "Cluster                                                          Fayetteville Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                                       Data Engineer   \n",
       "Safi Recommendation                                                                 0   \n",
       "Recruiting Start Date                                                      11/20/2019   \n",
       "Account Group                                                          JCC ACCT GROUP   \n",
       "Job Requisition ID                                                           R0073564   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization             Supervisory Organization (John Brandom (568067))   \n",
       "Clearance Agency                                                                  DOD   \n",
       "Primary Location State/Province                                        North Carolina   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                                Beth Mellott (510067)   \n",
       "Primary Location                    USA, NC, Fayetteville (4200 Morganton Rd Suite...   \n",
       "Job Description                     Key Role:\\nSupport the configuration and inges...   \n",
       "Group                                                            GLOBAL DEFENSE GROUP   \n",
       "Job Profile                                                         Data Engineer Mid   \n",
       "Job Family Group                                                           Technology   \n",
       "FSO                                                                 Digital Solutions   \n",
       "Job Family                                                           Data Engineering   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                      Data Engineer Mid   \n",
       "Job Posting                                                             Data Engineer   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             Secret   \n",
       "Primary Recruiter                                      Alexander Mosiniak (900620)[C]   \n",
       "percent_fit                                                                  0.857143   \n",
       "is_opportunity_application_emailed                                               True   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 475   \\\n",
       "Hiring Manager                                                  John Brandom (568067)   \n",
       "Management Level                                                    Senior Consultant   \n",
       "IMT                                                                           JCC IMT   \n",
       "Job Requisition                                        R0073585 Data Scientist (Open)   \n",
       "Job Requisition Type                                                  Sold and Funded   \n",
       "Cluster                                                          Fayetteville Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                                      Data Scientist   \n",
       "Safi Recommendation                                                                 0   \n",
       "Recruiting Start Date                                                      11/20/2019   \n",
       "Account Group                                                          JCC ACCT GROUP   \n",
       "Job Requisition ID                                                           R0073585   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization             Supervisory Organization (John Brandom (568067))   \n",
       "Clearance Agency                                                                  DOD   \n",
       "Primary Location State/Province                                        North Carolina   \n",
       "Furthest Stage                                                              Interview   \n",
       "Resource Manager                                                Beth Mellott (510067)   \n",
       "Primary Location                    USA, NC, Fayetteville (4200 Morganton Rd Suite...   \n",
       "Job Description                     The Challenge:\\nAre you excited at the prospec...   \n",
       "Group                                                            GLOBAL DEFENSE GROUP   \n",
       "Job Profile                                                        Data Scientist Mid   \n",
       "Job Family Group                                                           Technology   \n",
       "FSO                                                                         Analytics   \n",
       "Job Family                                                             Data Scientist   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                     Data Scientist Mid   \n",
       "Job Posting                                                            Data Scientist   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             Secret   \n",
       "Primary Recruiter                                      Alexander Mosiniak (900620)[C]   \n",
       "percent_fit                                                                         1   \n",
       "is_opportunity_application_emailed                                               True   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 1390  \n",
       "Hiring Manager                                                  John Brandom (568067)  \n",
       "Management Level                                                    Senior Consultant  \n",
       "IMT                                                                           JCC IMT  \n",
       "Job Requisition                                    R0073586 Software Developer (Open)  \n",
       "Job Requisition Type                                                  Sold and Funded  \n",
       "Cluster                                                          Fayetteville Cluster  \n",
       "Time Type                                                                   Full time  \n",
       "Job Posting Title                                                  Software Developer  \n",
       "Safi Recommendation                                                                 0  \n",
       "Recruiting Start Date                                                      11/20/2019  \n",
       "Account Group                                                          JCC ACCT GROUP  \n",
       "Job Requisition ID                                                           R0073586  \n",
       "Job Type                                                                      Regular  \n",
       "Supervisory Organization             Supervisory Organization (John Brandom (568067))  \n",
       "Clearance Agency                                                                  DOD  \n",
       "Primary Location State/Province                                        North Carolina  \n",
       "Furthest Stage                                                              Interview  \n",
       "Resource Manager                                                Beth Mellott (510067)  \n",
       "Primary Location                    USA, NC, Fayetteville (4200 Morganton Rd Suite...  \n",
       "Job Description                     The Challenge:\\nAre you looking for an opportu...  \n",
       "Group                                                            GLOBAL DEFENSE GROUP  \n",
       "Job Profile                                                  Full Stack Developer Mid  \n",
       "Job Family Group                                                           Technology  \n",
       "FSO                                                                 Digital Solutions  \n",
       "Job Family                                                       Software Engineering  \n",
       "Job Requisition Status                                                           Open  \n",
       "Business Title                                               Full Stack Developer Mid  \n",
       "Job Posting                                                        Software Developer  \n",
       "Primary Location Country                                     United States of America  \n",
       "Required Clearance                                                             Secret  \n",
       "Primary Recruiter                                      Alexander Mosiniak (900620)[C]  \n",
       "percent_fit                                                                         1  \n",
       "is_opportunity_application_emailed                                               True  \n",
       "is_remote_delivery                                                                NaN  \n",
       "is_for_university_recruiting                                                      NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "req_id_list = ['R0073564', 'R0073583', 'R0073584', 'R0073585', 'R0073586']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df[match_series].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df['Job Description'] = hunting_df['Job Description'].map(lambda x: re.sub(r'', \"'\", x))\n",
    "hunting_df['Job Description'] = hunting_df['Job Description'].map(lambda x: re.sub(r'', '—', x))\n",
    "s.store_objects(hunting_df=hunting_df)\n",
    "req_id = 'R0073585'\n",
    "print_job_description(req_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.index == 437)\n",
    "print(hunting_df[match_series]['Job Description'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.percent_fit >= 0.0)\n",
    "print(hunting_df[~match_series].sample(1)['Job Description'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(['hunting_df.{}'.format(fn) for fn in dir(hunting_df) if 'dup' in fn.lower()])\n",
    "match_series = hunting_df.duplicated(subset='Job Requisition ID', keep=False)\n",
    "print(hunting_df[match_series].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                'Job Posting Title', 'Recruiting Start Date', 'Account Group', 'Job Requisition ID', 'Job Type',\n",
    "                'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                'Resource Manager', 'Primary Location', 'Job Description', 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                'Required Clearance', 'Primary Recruiter']\n",
    "hunting_df = hunting_df.drop_duplicates(subset=columns_list, ignore_index=True)\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_list = hunting_df[match_series].index.tolist()\n",
    "first = idx_list[0]\n",
    "second = idx_list[1]\n",
    "columns_list = []\n",
    "for column_name in hunting_df.columns:\n",
    "    if hunting_df.loc[first, column_name] == hunting_df.loc[second, column_name]:\n",
    "        columns_list.append(column_name)\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = hunting_df.percent_fit.isnull()\n",
    "print(hunting_df[match_series].shape)\n",
    "req_id = hunting_df.loc[481, 'Job Requisition ID']\n",
    "print_job_description(req_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(['{}'.format(fn) for fn in hunting_df.columns if 'req' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_regex = re.compile(r'([^0-9A-Za-z\\+ \\/)(:,]+)-')\n",
    "for old_key in basic_quals_dict.keys():\n",
    "    match_obj = key_regex.search(old_key)\n",
    "    if match_obj:\n",
    "        print('\"{}\": {}'.format(match_obj.group(1), old_key))\n",
    "        #new_key = re.sub('^[?â-]+', '', old_key)\n",
    "        #print(new_key)\n",
    "        #basic_quals_dict[new_key] = basic_quals_dict.pop(old_key)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_regex = re.compile(r'\\s+$')\n",
    "old_key_list = basic_quals_dict.copy().keys()\n",
    "for old_key in old_key_list:\n",
    "    match_obj = key_regex.search(old_key)\n",
    "    if match_obj:\n",
    "        #print('\"{}\": {}'.format(match_obj.group(1), old_key))\n",
    "        new_key = re.sub(r'\\s+$', '', old_key)\n",
    "        #print(new_key)\n",
    "        basic_quals_dict[new_key] = basic_quals_dict.pop(old_key)\n",
    "        #print(old_key)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add new ORR to the hunting dataframe\n",
    "file_name = 'BAH1002 - Open Requisitions Report (ORR) 2020-02-14 09_03 EST.csv'\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "jd_cn = 'Job Description'\n",
    "reqid_cn = 'Job Requisition ID'\n",
    "dupe_columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                     'Job Posting Title', 'Recruiting Start Date', 'Account Group', reqid_cn, 'Job Type',\n",
    "                     'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                     'Resource Manager', 'Primary Location', jd_cn, 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                     'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                     'Required Clearance', 'Primary Recruiter']\n",
    "columns_list = ['Job Posting', 'Job Requisition', reqid_cn, 'Job Requisition Status', 'Furthest Stage',\n",
    "                'Supervisory Organization', 'Group', 'Account Group', 'IMT', 'Cluster', 'FSO', 'Primary Recruiter',\n",
    "                'Resource Manager', 'Hiring Manager', 'Job Posting Title', 'Job Profile', 'Job Requisition Type',\n",
    "                'Management Level', 'Primary Location', 'Primary Location State/Province', 'Primary Location Country',\n",
    "                'Required Clearance', 'Clearance Agency', 'Time Type', 'Recruiting Start Date', 'Job Type', 'Job Family',\n",
    "                'Business Title', 'Job Family Group', jd_cn]\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting\\csv'\n",
    "def add_new_orr(file_name):\n",
    "    file_path = os.path.join(hunting_dir, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        !\"{text_editor_path}\" \"{os.path.abspath(file_path)}\"\n",
    "        df = pd.read_csv(file_path, header=0, skiprows=0, encoding='iso8859-1')\n",
    "        df.columns = columns_list\n",
    "        req_id_list = hunting_df[reqid_cn].unique().tolist()\n",
    "        match_series = (df[reqid_cn].isin(req_id_list))\n",
    "        hunting_df = pd.concat([hunting_df, df[~match_series]]).fillna({'is_opportunity_application_emailed': False})\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(u'\\\\xa0', u' ', x))\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(r'', \"'\", x))\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(r'', '—', x))\n",
    "        hunting_df = hunting_df.drop_duplicates(subset=dupe_columns_list, ignore_index=True)\n",
    "        hunting_df.reset_index(drop=True, inplace=True)\n",
    "        s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "def get_basic_quals(row_index):\n",
    "    match_series = (hunting_df.index == row_index)\n",
    "    for row_index, row_series in hunting_df[match_series].iterrows():\n",
    "        percent_fit = get_percent_fit(row_series)\n",
    "        job_description = row_series['Job Description']\n",
    "        quals_list = get_quals_list(job_description)\n",
    "        quals_str = get_quals_str(quals_list, basic_quals_dict)\n",
    "        if (quals_str != '') and (percent_fit == 0):\n",
    "            print('Basic Qualifications:{}'.format(quals_str))\n",
    "            print_loc_computation(row_index, quals_list, basic_quals_dict)\n",
    "    \n",
    "    return quals_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Study of the Safi recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "match_series = (hunting_df['Safi Recommendation'] == 1)\n",
    "[c[10:100].strip() for c in random.choices(population=hunting_df[match_series]['Job Description'].unique(), k=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(hunting_df=hunting_df)\n",
    "match_series = (hunting_df['Safi Recommendation'] == 1)\n",
    "hunting_df[match_series]['Primary Location State/Province'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Requisition'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Cluster'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Family'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Account Group'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Resource Manager'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Requisition Type'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Posting'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Hiring Manager'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['IMT'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Required Clearance'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Job Profile'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Management Level'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Clearance Agency'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Group'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Job Profile'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[cn for cn in columns_list if 'loca' in cn.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Primary Location'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Primary Recruiter'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Initial dataframe creation (don't run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting'\n",
    "columns_list = []\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    #path = root.split(os.sep)\n",
    "    #print((len(path)-1) * '---', os.path.basename(root))\n",
    "    for file in files:\n",
    "        #print(len(path) * '---', file)\n",
    "        if file.endswith('.csv'):\n",
    "            print(file)\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, encoding='iso8859-1')\n",
    "                columns_list = list(set(columns_list) | set(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df = pd.DataFrame([], columns=columns_list)\n",
    "\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, encoding='iso8859-1')\n",
    "                hunting_df = pd.concat([hunting_df, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "command_str = '{sys.executable} -m pip install pyOutlook'.format(sys=sys)\n",
    "print(command_str)\n",
    "!{command_str}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
