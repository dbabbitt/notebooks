{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Load needed libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n",
      "D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\ipynb\\Job Hunting.ipynb\n",
      "['s.attempt_to_pickle', 's.data_csv_folder', 's.data_folder', 's.encoding_type', 's.load_csv', 's.load_dataframes', 's.load_object', 's.save_dataframes', 's.saves_csv_folder', 's.saves_folder', 's.saves_pickle_folder', 's.store_objects']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Config', 'CountVectorizer', 'In', 'Out', 'RandomForestClassifier', 'SequenceMatcher', 'Storage', 'TfidfTransformer', '_', '__', '___', '__builtin__', '__builtins__', '__doc__', '__loader__', '__name__', '__nonzero__', '__package__', '__spec__', '_dh', '_i', '_i1', '_ih', '_ii', '_iii', '_oh', 'basic_quals_dict', 'check_4_doubles', 'check_for_typos', 'conjunctify_list', 'copyfile', 'csv', 'encoding', 'exit', 'get_classifier', 'get_data_structs_df', 'get_datastructure_prediction', 'get_dir_tree', 'get_git_lfs_track_commands', 'get_importances', 'get_input_sample', 'get_ipython', 'get_module_version', 'get_notebook_path', 'get_specific_gitignore_files', 'get_struct_name', 'humanize_bytes', 'hunting_df', 'ipykernel', 'json', 'jupyter_config_dir', 'notebook_path', 'notebookapp', 'np', 'os', 'pd', 'pickle', 'preprocess_data', 'print_all_files_ending_starting_with', 'print_all_files_ending_with', 'print_all_files_starting_with', 'quit', 're', 'remove_empty_folders', 's', 'similar', 'subprocess', 'sys', 'time', 'urllib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "%run ../../load_magic/paths.py\n",
    "%run ../../load_magic/lists.py\n",
    "%run ../../load_magic/environment.py\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "%pprint\n",
    "\n",
    "notebook_path = get_notebook_path()\n",
    "print(notebook_path)\n",
    "\n",
    "s = Storage()\n",
    "print(['s.{}'.format(fn) for fn in dir(s) if not fn.startswith('_')])\n",
    "hunting_df = s.load_object('hunting_df')\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Needed extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Email prep\n",
    "subject_str = '{}% fit: Internal Candidate, Dave Babbitt, for {}'\n",
    "concerns_str = 'One important question I have is if the work can be supported remotely or if this position is available for remote delivery '\n",
    "concerns_str += '(or something equivalent).'\n",
    "concerns_str += \" I don't want to move my family out of New England.\"\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "emails_dir = os.path.join(s.saves_folder, 'emails')\n",
    "os.makedirs(name=emails_dir, exist_ok=True)\n",
    "name_regex = re.compile(r'^([^(]+) \\(\\d+\\)\"')\n",
    "def clean_email(email_str):\n",
    "    match_obj = name_regex.search(email_str)\n",
    "    if match_obj:\n",
    "        email_str = match_obj.group(1)\n",
    "    names_list = re.split(r'\\s+', email_str, 0)\n",
    "    if len(names_list) >= 2:\n",
    "        first_name = names_list[0]\n",
    "        last_name = names_list[1]\n",
    "        email_str = '{}, {} [USA] <{}_{}@bah.com>'.format(last_name, first_name, last_name.lower(), first_name.lower())\n",
    "    \n",
    "    return email_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_percent_fit(row_series):\n",
    "    percent_fit = row_series['percent_fit']\n",
    "    if str(percent_fit) == 'nan':\n",
    "        percent_fit = 0\n",
    "    percent_fit = int(percent_fit*100)\n",
    "    \n",
    "    return percent_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_loc_computation(row_index, quals_list, basic_quals_dict):\n",
    "    print()\n",
    "    numerator_str_list = []\n",
    "    for qual_str in quals_list:\n",
    "        if qual_str in basic_quals_dict:\n",
    "            numerator_str_list.append(str(basic_quals_dict[qual_str]))\n",
    "        else:\n",
    "            numerator_str_list.append('000')\n",
    "    numerator_str = '+'.join(numerator_str_list)\n",
    "    print(\"hunting_df.loc[{}, 'percent_fit'] = ({})/{}\".format(row_index, numerator_str, len(quals_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions_and_counts(prediction_list, quals_list):\n",
    "    qual_count = 0\n",
    "    prediction_str = ''\n",
    "    for pred_array, qual_str in zip(prediction_list, quals_list):\n",
    "        prediction = pred_array[1]\n",
    "        prediction_str += '\\n{} {}'.format(prediction, qual_str)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return prediction_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_quals_str(prediction_list, quals_list, basic_quals_dict):\n",
    "    qual_count = 0\n",
    "    quals_str = ''\n",
    "    for pred_array, (i, qual_str) in zip(prediction_list, enumerate(quals_list)):\n",
    "        if qual_str in basic_quals_dict:\n",
    "            formatted_str = '\\nquals_list[{}] = \"{}\" ({})'\n",
    "        else:\n",
    "            formatted_str = '\\n*quals_list[{}] = \"{}\" ({})'\n",
    "        prediction = pred_array[1]\n",
    "        quals_str += formatted_str.format(i, qual_str, prediction)\n",
    "        if prediction > 0.5:\n",
    "            qual_count += 1\n",
    "    \n",
    "    return quals_str, qual_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_fit_job(row_index, row_series, basic_quals_dict):\n",
    "    job_fitness = 0.0\n",
    "    job_description = row_series['Job Description']\n",
    "    quals_list = get_quals_list(job_description)\n",
    "    if len(quals_list):\n",
    "        prediction_list = list(predict_percent_fit(quals_list))\n",
    "        #prediction_str, qual_count = get_predictions_and_counts(prediction_list, quals_list)\n",
    "        quals_str, qual_count = get_quals_str(prediction_list, quals_list, basic_quals_dict)\n",
    "        job_fitness = qual_count/len(prediction_list)\n",
    "        if job_fitness > 0.8:\n",
    "            print('Basic Qualifications:{}'.format(quals_str))\n",
    "            #print(prediction_str)\n",
    "            print(job_fitness)\n",
    "            print_loc_computation(row_index, quals_list, basic_quals_dict)\n",
    "    \n",
    "    return quals_list, job_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qual_sum(qual_str):\n",
    "    results = '\"{}\"'.format(qual_str)\n",
    "    if qual_str in basic_quals_dict:\n",
    "        results = basic_quals_dict[qual_str]\n",
    "    else:\n",
    "        results = predict_percent_fit([qual_str])[0][1]\n",
    "        if results > 0.5:\n",
    "            results = 1.0\n",
    "        else:\n",
    "            results = 0.0\n",
    "    \n",
    "    return str(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_job_description(req_id):\n",
    "    match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "    job_description = hunting_df[match_series]['Job Description'].tolist()[0]\n",
    "    print(get_quals_list(job_description))\n",
    "    print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scanner_regex = re.compile(r'\\b[1-9a-zA-Z][0-9a-zA-Z]*( *[#\\+]{1,2}|\\b)')\n",
    "def regex_tokenizer(corpus):\n",
    "    \n",
    "    return [match.group() for match in re.finditer(scanner_regex, corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_list = ['Additional Qualifications?', 'Nice If You Have', 'Nice if you have', 'Nice if You Have',\n",
    "          'Additional Preferred Qualifications', 'Nice if you Have', 'Additional qualifications', 'Nice to Have']\n",
    "a_str = '({}):?'.format('|'.join(a_list))\n",
    "def get_quals_list(job_description):\n",
    "    job_description = re.sub('Â', '', job_description)\n",
    "    basic_quals = ''\n",
    "    quals_list = []\n",
    "    items_list = re.split('(Key Role|The Challenge):', job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        job_description = items_list[-1].strip()\n",
    "    items_list = re.split('[\\r\\n]+(Basic Qualifications?|You Have|You have):?', job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        job_description = items_list[-1].strip()\n",
    "    items_list = re.split(a_str, job_description, 0)\n",
    "    if len(items_list) > 1:\n",
    "        basic_quals = items_list[0].strip()\n",
    "    else:\n",
    "        items_list = re.split('(Clearance|Build Your Career):', job_description, 0)\n",
    "        basic_quals = items_list[0].strip()\n",
    "    if basic_quals != '':\n",
    "        quals_list = [re.sub(r'â¯', ' ', q) for q in re.split('[\\r\\n]+', basic_quals, 0)]\n",
    "        quals_list = [re.sub(r'^[?â-]+', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'[â-]+$', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '-', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '`', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '`', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '`', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'â', '', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(u'\\\\xa0', u' ', x).strip() for x in quals_list]\n",
    "        quals_list = [re.sub(r'\\s+$', '', x) for x in quals_list]\n",
    "        quals_list = [x for x in quals_list if x != '']\n",
    "    \n",
    "    return quals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_emails(match_series):\n",
    "    for file_name in os.listdir(emails_dir):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(emails_dir, file_name)\n",
    "            os.remove(file_path)\n",
    "    for row_index, row_series in hunting_df[match_series].sort_values('percent_fit', ascending=False).iterrows():\n",
    "        req_str = row_series['Job Requisition']\n",
    "        percent_fit = get_percent_fit(row_series)\n",
    "        sents_list = ['I’m submitting my resume for {}.'.format(req_str),\n",
    "                      'I’ve reviewed the basic qualifications and believe I’m a good fit for this project.',\n",
    "                      'Below is a breakdown of the requirements and the amount of experience I have with each.',\n",
    "                      'I’m available at your convenience to discuss my qualifications and look forward to hearing from you.']\n",
    "        blurb_str = ' '.join(sents_list)\n",
    "        hm_str = row_series['Hiring Manager']\n",
    "        pr_str = row_series['Primary Recruiter']\n",
    "        job_description = row_series['Job Description']\n",
    "        quals_list = get_quals_list(job_description)\n",
    "        quals_str = '\\n•\\t' + '\\n•\\t'.join(quals_list)\n",
    "        file_path = os.path.join(emails_dir, '{}_email.txt'.format(row_series['Job Requisition ID'].strip()))\n",
    "        if not os.path.isfile(file_path):\n",
    "            with open(file_path, 'w', encoding=s.encoding_type) as io_wrapper:\n",
    "                print('', file=io_wrapper)\n",
    "                print('To: {}; {}'.format(clean_email(hm_str), clean_email(pr_str)), file=io_wrapper)\n",
    "                print('CC: Safi, Claudia [USA] <safi_claudia@bah.com>; Borrelli, Bill [USA] <Borrelli_Bill@bah.com>', file=io_wrapper)\n",
    "                print(subject_str.format(percent_fit, req_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Dear {},'.format(hm_str.split(' ')[0]), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('{}'.format(blurb_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Basic Qualifications:{}'.format(quals_str), file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print(concerns_str, file=io_wrapper)\n",
    "                print('', file=io_wrapper)\n",
    "                print('Attached: Dave_Babbitt_Resume_for_{}.pdf'.format('_'.join(re.split(r'[ \\\\\\/:\\*\\?\"><\\|]+', req_str, 0))),\n",
    "                      file=io_wrapper)\n",
    "            !\"{text_editor_path}\" \"{os.path.abspath(file_path)}\"\n",
    "    !start %windir%\\explorer.exe \"{os.path.abspath(emails_dir)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add new ORR to the hunting dataframe\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "jd_cn = 'Job Description'\n",
    "reqid_cn = 'Job Requisition ID'\n",
    "dupe_columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                     'Job Posting Title', 'Recruiting Start Date', 'Account Group', reqid_cn, 'Job Type',\n",
    "                     'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                     'Resource Manager', 'Primary Location', jd_cn, 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                     'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                     'Required Clearance', 'Primary Recruiter']\n",
    "columns_list = ['Job Posting', 'Job Requisition', reqid_cn, 'Job Requisition Status', 'Furthest Stage',\n",
    "                'Supervisory Organization', 'Group', 'Account Group', 'IMT', 'Cluster', 'FSO', 'Primary Recruiter',\n",
    "                'Resource Manager', 'Hiring Manager', 'Job Posting Title', 'Job Profile', 'Job Requisition Type',\n",
    "                'Management Level', 'Primary Location', 'Primary Location State/Province', 'Primary Location Country',\n",
    "                'Required Clearance', 'Clearance Agency', 'Time Type', 'Recruiting Start Date', 'Job Type', 'Job Family',\n",
    "                'Business Title', 'Job Family Group', jd_cn]\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting\\csv'\n",
    "def add_new_orr(file_name, hunting_df):\n",
    "    file_path = os.path.join(hunting_dir, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        !\"{text_editor_path}\" \"{os.path.abspath(file_path)}\"\n",
    "        df = pd.read_csv(file_path, header=0, skiprows=0, encoding='iso8859-1')\n",
    "        df.columns = columns_list\n",
    "        req_id_list = hunting_df[reqid_cn].unique().tolist()\n",
    "        match_series = (df[reqid_cn].isin(req_id_list))\n",
    "        hunting_df = pd.concat([hunting_df, df[~match_series]]).fillna({'is_opportunity_application_emailed': False})\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(u'\\\\xa0', u' ', x))\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(r'', \"'\", x))\n",
    "        hunting_df[jd_cn] = hunting_df[jd_cn].map(lambda x: re.sub(r'', '—', x))\n",
    "        hunting_df = hunting_df.drop_duplicates(subset=dupe_columns_list, ignore_index=True)\n",
    "        hunting_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return hunting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_dict = s.load_object('basic_quals_dict')\n",
    "def get_basic_quals(row_index):\n",
    "    match_series = (hunting_df.index == row_index)\n",
    "    for row_index, row_series in hunting_df[match_series].iterrows():\n",
    "        percent_fit = get_percent_fit(row_series)\n",
    "        job_description = row_series['Job Description']\n",
    "        quals_list = get_quals_list(job_description)\n",
    "        quals_str = get_quals_str(quals_list, basic_quals_dict)\n",
    "        if (quals_str != '') and (percent_fit == 0):\n",
    "            print('Basic Qualifications:{}'.format(quals_str))\n",
    "            print_loc_computation(row_index, quals_list, basic_quals_dict)\n",
    "    \n",
    "    return quals_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Create the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 35)\n",
      "Required Clearance\n",
      "Secret                                2\n",
      "Eligibility Determination Timeline    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3994</th>\n",
       "      <th>4006</th>\n",
       "      <th>4008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hiring Manager</th>\n",
       "      <td>Gregory Dupier (514538)</td>\n",
       "      <td>Robin Rudy (509009)</td>\n",
       "      <td>Sivakumar Arunachalam | Siva Arunachalam (608203)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Management Level</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Senior Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMT</th>\n",
       "      <td>DIGITAL IMT</td>\n",
       "      <td>JHT IMT</td>\n",
       "      <td>JCC IMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition</th>\n",
       "      <td>R0080116 Data Analyst (Open)</td>\n",
       "      <td>R0080071 Data Scientist (Open)</td>\n",
       "      <td>R0079006 Data Scientist, Mid (Open)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Type</th>\n",
       "      <td>Sold and Funded</td>\n",
       "      <td>Sold and Funded</td>\n",
       "      <td>Sold and Funded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <td>Aberdeen Cluster</td>\n",
       "      <td>Wash Metro Cluster</td>\n",
       "      <td>Wash Metro Cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time Type</th>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting Title</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist, Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Safi Recommendation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recruiting Start Date</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>2020-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Group</th>\n",
       "      <td>FSO ACCT GROUP</td>\n",
       "      <td>JHT ACCT GROUP</td>\n",
       "      <td>JCC ACCT GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition ID</th>\n",
       "      <td>R0080116</td>\n",
       "      <td>R0080071</td>\n",
       "      <td>R0079006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Type</th>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supervisory Organization</th>\n",
       "      <td>Supervisory Organization (Gregory Dupier (5145...</td>\n",
       "      <td>Supervisory Organization (Robin Rudy (509009))</td>\n",
       "      <td>Supervisory Organization (Sivakumar Arunachala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearance Agency</th>\n",
       "      <td>DOD</td>\n",
       "      <td>Other</td>\n",
       "      <td>DOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location State/Province</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Furthest Stage</th>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Manager</th>\n",
       "      <td>Neil Kramer (542022)</td>\n",
       "      <td>Emily Sylling (504033)</td>\n",
       "      <td>Emily Sylling (504033)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location</th>\n",
       "      <td>USA, MD, Belcamp (4692 Millennium Dr)</td>\n",
       "      <td>USA, VA, McLean (8283 Greensboro Dr, Hamilton)</td>\n",
       "      <td>USA, VA, Herndon (575 Herndon Pkwy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Description</th>\n",
       "      <td>Key Role:\\nApply expertise in quantitative ana...</td>\n",
       "      <td>The Challenge:\\nAre you excited at the prospec...</td>\n",
       "      <td>The Challenge:\\nAre you excited at the prospec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <td>STRATEGIC INNOVATION GROUP</td>\n",
       "      <td>CIVILIAN SERVICES GROUP</td>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Profile</th>\n",
       "      <td>Data Analyst Mid</td>\n",
       "      <td>Data Scientist Mid</td>\n",
       "      <td>Data Scientist Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family Group</th>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSO</th>\n",
       "      <td>Digital Solutions</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family</th>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Status</th>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Title</th>\n",
       "      <td>Data Analyst Mid</td>\n",
       "      <td>Data Scientist Mid</td>\n",
       "      <td>Data Scientist Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist, Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location Country</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Required Clearance</th>\n",
       "      <td>Secret</td>\n",
       "      <td>Eligibility Determination Timeline</td>\n",
       "      <td>Secret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Recruiter</th>\n",
       "      <td>Joseph Rossano (605895)</td>\n",
       "      <td>Nicole Vertescher (900454)[C]</td>\n",
       "      <td>Lori Nida (594683)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_fit</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_opportunity_application_emailed</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_remote_delivery</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_for_university_recruiting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 3994  \\\n",
       "Hiring Manager                                                Gregory Dupier (514538)   \n",
       "Management Level                                                    Senior Consultant   \n",
       "IMT                                                                       DIGITAL IMT   \n",
       "Job Requisition                                          R0080116 Data Analyst (Open)   \n",
       "Job Requisition Type                                                  Sold and Funded   \n",
       "Cluster                                                              Aberdeen Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                                        Data Analyst   \n",
       "Safi Recommendation                                                               NaN   \n",
       "Recruiting Start Date                                                      2020-03-04   \n",
       "Account Group                                                          FSO ACCT GROUP   \n",
       "Job Requisition ID                                                           R0080116   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization            Supervisory Organization (Gregory Dupier (5145...   \n",
       "Clearance Agency                                                                  DOD   \n",
       "Primary Location State/Province                                              Maryland   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                                 Neil Kramer (542022)   \n",
       "Primary Location                                USA, MD, Belcamp (4692 Millennium Dr)   \n",
       "Job Description                     Key Role:\\nApply expertise in quantitative ana...   \n",
       "Group                                                      STRATEGIC INNOVATION GROUP   \n",
       "Job Profile                                                          Data Analyst Mid   \n",
       "Job Family Group                                                           Technology   \n",
       "FSO                                                                 Digital Solutions   \n",
       "Job Family                                                           Data Engineering   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                       Data Analyst Mid   \n",
       "Job Posting                                                              Data Analyst   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             Secret   \n",
       "Primary Recruiter                                             Joseph Rossano (605895)   \n",
       "percent_fit                                                                         1   \n",
       "is_opportunity_application_emailed                                              False   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 4006  \\\n",
       "Hiring Manager                                                    Robin Rudy (509009)   \n",
       "Management Level                                                    Senior Consultant   \n",
       "IMT                                                                           JHT IMT   \n",
       "Job Requisition                                        R0080071 Data Scientist (Open)   \n",
       "Job Requisition Type                                                  Sold and Funded   \n",
       "Cluster                                                            Wash Metro Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                                      Data Scientist   \n",
       "Safi Recommendation                                                               NaN   \n",
       "Recruiting Start Date                                                      2020-03-04   \n",
       "Account Group                                                          JHT ACCT GROUP   \n",
       "Job Requisition ID                                                           R0080071   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization               Supervisory Organization (Robin Rudy (509009))   \n",
       "Clearance Agency                                                                Other   \n",
       "Primary Location State/Province                                              Virginia   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                               Emily Sylling (504033)   \n",
       "Primary Location                       USA, VA, McLean (8283 Greensboro Dr, Hamilton)   \n",
       "Job Description                     The Challenge:\\nAre you excited at the prospec...   \n",
       "Group                                                         CIVILIAN SERVICES GROUP   \n",
       "Job Profile                                                        Data Scientist Mid   \n",
       "Job Family Group                                                           Technology   \n",
       "FSO                                                                         Analytics   \n",
       "Job Family                                                             Data Scientist   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                     Data Scientist Mid   \n",
       "Job Posting                                                            Data Scientist   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                 Eligibility Determination Timeline   \n",
       "Primary Recruiter                                       Nicole Vertescher (900454)[C]   \n",
       "percent_fit                                                                         1   \n",
       "is_opportunity_application_emailed                                              False   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 4008  \n",
       "Hiring Manager                      Sivakumar Arunachalam | Siva Arunachalam (608203)  \n",
       "Management Level                                                    Senior Consultant  \n",
       "IMT                                                                           JCC IMT  \n",
       "Job Requisition                                   R0079006 Data Scientist, Mid (Open)  \n",
       "Job Requisition Type                                                  Sold and Funded  \n",
       "Cluster                                                            Wash Metro Cluster  \n",
       "Time Type                                                                   Full time  \n",
       "Job Posting Title                                                 Data Scientist, Mid  \n",
       "Safi Recommendation                                                               NaN  \n",
       "Recruiting Start Date                                                      2020-02-19  \n",
       "Account Group                                                          JCC ACCT GROUP  \n",
       "Job Requisition ID                                                           R0079006  \n",
       "Job Type                                                                      Regular  \n",
       "Supervisory Organization            Supervisory Organization (Sivakumar Arunachala...  \n",
       "Clearance Agency                                                                  DOD  \n",
       "Primary Location State/Province                                              Virginia  \n",
       "Furthest Stage                                                                 Review  \n",
       "Resource Manager                                               Emily Sylling (504033)  \n",
       "Primary Location                                  USA, VA, Herndon (575 Herndon Pkwy)  \n",
       "Job Description                     The Challenge:\\nAre you excited at the prospec...  \n",
       "Group                                                            GLOBAL DEFENSE GROUP  \n",
       "Job Profile                                                        Data Scientist Mid  \n",
       "Job Family Group                                                           Technology  \n",
       "FSO                                                                         Analytics  \n",
       "Job Family                                                             Data Scientist  \n",
       "Job Requisition Status                                                           Open  \n",
       "Business Title                                                     Data Scientist Mid  \n",
       "Job Posting                                                       Data Scientist, Mid  \n",
       "Primary Location Country                                     United States of America  \n",
       "Required Clearance                                                             Secret  \n",
       "Primary Recruiter                                                  Lori Nida (594683)  \n",
       "percent_fit                                                                         1  \n",
       "is_opportunity_application_emailed                                              False  \n",
       "is_remote_delivery                                                                NaN  \n",
       "is_for_university_recruiting                                                      NaN  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def f(x):\n",
    "    \n",
    "    return 'python' in str(x).lower()\n",
    "\n",
    "match_series = hunting_df['Job Requisition Type'].isin(['Sold and Funded', 'Sold & Unfunded']) & hunting_df['Job Description'].map(f)\n",
    "match_series = match_series & (hunting_df.percent_fit >= 0.95) & ~hunting_df['is_opportunity_application_emailed']\n",
    "match_series = match_series & ~(hunting_df.is_remote_delivery == False)\n",
    "match_series = match_series & ~hunting_df['Required Clearance'].isin(['TS/SCI', 'TS/SCI w/CIP'])\n",
    "print(hunting_df[match_series].shape)\n",
    "print(hunting_df[match_series].groupby('Required Clearance').count().T.max().sort_values(ascending=False))\n",
    "hunting_df[match_series].head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_emails(match_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually note the email has been sent\n",
    "req_id = 'R0080116'.strip()\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\basic_quals_df.pickle\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\bq_cv_vocab.pickle\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\bq_tt.pickle\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\basic_quals_clf.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Rebuild the datframe from the dictionary\n",
    "rows_list = [{'qualification_str': qualification_str, 'is_fit': is_fit} for qualification_str, is_fit in basic_quals_dict.items()]\n",
    "basic_quals_df = pd.DataFrame(rows_list)\n",
    "s.store_objects(basic_quals_df=basic_quals_df)\n",
    "\n",
    "# Re-transform the bag-of-words and tf-idf from the new manual scores\n",
    "sents_list = basic_quals_df.qualification_str.tolist()\n",
    "\n",
    "# Bag-of-words\n",
    "cv = CountVectorizer(lowercase=True, tokenizer=regex_tokenizer, token_pattern=r'\\b[1-9a-zA-Z][0-9a-zA-Z]*[#\\+]{0,2}', ngram_range=(1, 3))\n",
    "bow_matrix = cv.fit_transform(sents_list)\n",
    "s.store_objects(bq_cv_vocab=cv.vocabulary_)\n",
    "\n",
    "# Tf-idf, must get from BOW first\n",
    "tt = TfidfTransformer()\n",
    "tfidf_matrix = tt.fit_transform(bow_matrix)\n",
    "s.store_objects(bq_tt=tt)\n",
    "\n",
    "# Re-train the classifier\n",
    "X = tfidf_matrix.toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "fit_estimators_dict = s.load_object('fit_estimators_dict')\n",
    "#basic_quals_clf = RandomForestClassifier(n_estimators=997)\n",
    "#basic_quals_clf = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0, n_estimators=50, random_state=None)\n",
    "basic_quals_clf = fit_estimators_dict['LogisticRegression']\n",
    "basic_quals_clf.fit(X, y)\n",
    "s.store_objects(basic_quals_clf=basic_quals_clf)\n",
    "\n",
    "# Re-calibrate the inference engine\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "def predict_percent_fit(quals_list):\n",
    "    y_predict_proba = np.array([])\n",
    "    if len(quals_list):\n",
    "        X_test = bq_tt.transform(bq_cv.transform(quals_list)).toarray()\n",
    "        y_predict_proba = basic_quals_clf.predict_proba(X_test)\n",
    "    \n",
    "    return y_predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Look for a fit greater than 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4244/4244 = 100% completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loop through all the unset %fit values, set them if you can, break for help if you can't\n",
    "match_series = (hunting_df.percent_fit >= 0.0)\n",
    "for row_index, row_series in hunting_df[~match_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)\n",
    "    if job_fitness > 0.8:\n",
    "        if all(qual_str in basic_quals_dict for qual_str in quals_list):\n",
    "            hunting_df.loc[row_index, 'percent_fit'] = eval(' + '.join(map(qual_sum, quals_list))) / len(quals_list)\n",
    "            s.store_objects(hunting_df=hunting_df)\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        if len(quals_list):\n",
    "            hunting_df.loc[row_index, 'percent_fit'] = eval(' + '.join(map(qual_sum, quals_list))) / len(quals_list)\n",
    "            s.store_objects(hunting_df=hunting_df)\n",
    "print('{}/{} = {}% completed'.format(hunting_df[match_series].shape[0], hunting_df.shape[0],\n",
    "                                     int(100 * hunting_df[match_series].shape[0] / hunting_df.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge of CONUS military installations\n",
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\basic_quals_dict.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually label the unscored qual\n",
    "qualification_str = quals_list[3]\n",
    "print(qualification_str)\n",
    "basic_quals_dict[qualification_str] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Rescore the quals dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "# Get the training data and models\n",
    "X = tfidf_matrix.toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "estimators_list = [AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0, n_estimators=50, random_state=None),\n",
    "                   BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
    "                                     n_estimators=10, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None,\n",
    "                                        max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=100, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None, learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "                                              max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                              min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                                              n_iter_no_change=None, presort='deprecated', random_state=None, subsample=1.0, tol=0.0001,\n",
    "                                              validation_fraction=0.1, verbose=0, warm_start=False),\n",
    "                   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features='auto',\n",
    "                                          max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                          min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "                                          oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
    "                   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                                      multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                                      warm_start=False),\n",
    "                   SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3,\n",
    "                       gamma='scale', kernel='rbf', max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001, verbose=False)]\n",
    "\n",
    "# Fit the data and add the duration and fitted models to lists\n",
    "fit_estimators_list = []\n",
    "training_durations_list = []\n",
    "for clf in estimators_list:\n",
    "    start_time = time.time()\n",
    "    fit_estimators_list.append(clf.fit(X, y))\n",
    "    stop_time = time.time()\n",
    "    training_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(estimators_list=fit_estimators_list, training_durations_list=training_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimators_list = s.load_object('estimators_list')\n",
    "inference_durations_list = []\n",
    "for clf in estimators_list:\n",
    "    clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "    basic_quals_df[clf_name] = np.nan\n",
    "    start_time = time.time()\n",
    "    for row_index, row_series in basic_quals_df.iterrows():\n",
    "        qualification_str = row_series.qualification_str\n",
    "        X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "        y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "        basic_quals_df.loc[row_index, clf_name] = y_predict_proba\n",
    "    stop_time = time.time()\n",
    "    inference_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(basic_quals_df=basic_quals_df, inference_durations_list=inference_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "s = Storage()\n",
    "\n",
    "estimators_list = s.load_object('estimators_list')\n",
    "clf = StackingClassifier(estimators=[(str(type(e)).split('.')[-1].split(\"'\")[0], e) for e in estimators_list],\n",
    "                         final_estimator=None, cv=None, stack_method='auto', n_jobs=None, passthrough=False, verbose=0)\n",
    "clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "basic_quals_df = s.load_object('basic_quals_df')\n",
    "basic_quals_df[clf_name] = np.nan\n",
    "fit_estimators_list = estimators_list.copy()\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "X = bq_tt.transform(bq_cv.transform(basic_quals_df.qualification_str.tolist())).toarray()\n",
    "y = basic_quals_df.is_fit.to_numpy()\n",
    "start_time = time.time()\n",
    "fit_estimators_list.append(clf.fit(X, y))\n",
    "stop_time = time.time()\n",
    "training_durations_list = s.load_object('training_durations_list')\n",
    "training_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(fit_estimators_list=fit_estimators_list, training_durations_list=training_durations_list)\n",
    "\n",
    "# Re-score the quals dataframe\n",
    "inference_durations_list = s.load_object('inference_durations_list')\n",
    "start_time = time.time()\n",
    "for row_index, row_series in basic_quals_df.iterrows():\n",
    "    qualification_str = row_series.qualification_str\n",
    "    X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "    y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "    basic_quals_df.loc[row_index, clf_name] = y_predict_proba\n",
    "stop_time = time.time()\n",
    "inference_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(basic_quals_df=basic_quals_df, inference_durations_list=inference_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf = VotingClassifier(estimators=[(str(type(e)).split('.')[-1].split(\"'\")[0], e) for e in estimators_list],\n",
    "                       voting='soft', weights=None, n_jobs=None, flatten_transform=True)\n",
    "clf_name = str(type(clf)).split('.')[-1].split(\"'\")[0]\n",
    "basic_quals_df[clf_name] = np.nan\n",
    "fit_estimators_list = s.load_object('fit_estimators_list')\n",
    "start_time = time.time()\n",
    "fit_estimators_list.append(clf.fit(X, y))\n",
    "stop_time = time.time()\n",
    "training_durations_list = s.load_object('training_durations_list')\n",
    "training_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(fit_estimators_list=fit_estimators_list, training_durations_list=training_durations_list)\n",
    "\n",
    "# Re-score the quals dataframe\n",
    "bq_cv_vocab = s.load_object('bq_cv_vocab')\n",
    "bq_cv = CountVectorizer(vocabulary=bq_cv_vocab)\n",
    "bq_cv._validate_vocabulary()\n",
    "bq_tt = s.load_object('bq_tt')\n",
    "inference_durations_list = s.load_object('inference_durations_list')\n",
    "start_time = time.time()\n",
    "for row_index, row_series in basic_quals_df.iterrows():\n",
    "    qualification_str = row_series.qualification_str\n",
    "    X_test = bq_tt.transform(bq_cv.transform([qualification_str])).toarray()\n",
    "    y_predict_proba = clf.predict_proba(X_test)[0][1]\n",
    "    basic_quals_df.loc[row_index, clf_name] = y_predict_proba\n",
    "stop_time = time.time()\n",
    "inference_durations_list.append(stop_time - start_time)\n",
    "s.store_objects(basic_quals_df=basic_quals_df, inference_durations_list=inference_durations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(basic_quals_df.columns.tolist())\n",
    "basic_quals_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import inspect\n",
    "\n",
    "metrics_list = ['accuracy_score', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision_score',\n",
    "                'balanced_accuracy_score', 'cohen_kappa_score', 'completeness_score', 'explained_variance_score',\n",
    "                'f1_score', 'fowlkes_mallows_score', 'homogeneity_score', 'jaccard_score', 'mutual_info_score',\n",
    "                'normalized_mutual_info_score', 'precision_score', 'r2_score', 'recall_score', 'roc_auc_score', 'v_measure_score']\n",
    "description_dict = {name: fn.__doc__.strip().split('\\n')[0] for name, fn in inspect.getmembers(sys.modules[__name__],\n",
    "                                                                                               inspect.isfunction) if name in metrics_list}\n",
    "for name, cls in inspect.getmembers(sys.modules[__name__], inspect.isclass):\n",
    "    if name in entropy_df.index:\n",
    "        description_dict[name] = cls.__doc__.strip().split('\\n')[0]\n",
    "s.store_objects(metrics_list=metrics_list, description_dict=description_dict)\n",
    "exec('from sklearn.metrics import {}'.format(', '.join(metrics_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "fit_estimators_list = s.load_object('fit_estimators_list')\n",
    "clf_name_list = [str(type(clf)).split('.')[-1].split(\"'\")[0] for clf in fit_estimators_list]\n",
    "basic_quals_df = s.load_object('basic_quals_df')\n",
    "y_true = basic_quals_df.is_fit.tolist()\n",
    "fit_match_series = (basic_quals_df.is_fit == 1)\n",
    "yes_list = basic_quals_df[fit_match_series].is_fit.tolist()\n",
    "no_list = basic_quals_df[~fit_match_series].is_fit.tolist()\n",
    "columns_list = ['clf_name', 'training_duration', 'inference_duration', 'boundary_diff', 'clf_yes_entropy', 'relative_yes_entropy'] + metrics_list\n",
    "rows_list = []\n",
    "training_durations_list = s.load_object('training_durations_list')\n",
    "inference_durations_list = s.load_object('inference_durations_list')\n",
    "for column_name, training_duration, inference_duration in zip(clf_name_list, training_durations_list, inference_durations_list):\n",
    "    yes_series = basic_quals_df[fit_match_series][column_name]\n",
    "    upper_bound = yes_series.min()\n",
    "    no_series = basic_quals_df[~fit_match_series][column_name]\n",
    "    lower_bound = no_series.max()\n",
    "    y_pred = []\n",
    "    for p in basic_quals_df[column_name]:\n",
    "        if p > 0.5:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    row_dict = {}\n",
    "    row_dict['clf_name'] = column_name\n",
    "    row_dict['training_duration'] = training_duration\n",
    "    row_dict['inference_duration'] = inference_duration\n",
    "    row_dict['boundary_diff'] = upper_bound-lower_bound\n",
    "    row_dict['clf_yes_entropy'] = entropy(pk=yes_series.tolist())\n",
    "    row_dict['relative_yes_entropy'] = entropy(pk=yes_list, qk=yes_series.tolist())\n",
    "    for metric_str in metrics_list:\n",
    "        try:\n",
    "            row_dict[metric_str] = eval('{}(y_true, basic_quals_df[column_name].tolist())'.format(metric_str))\n",
    "        except Exception as e1:\n",
    "            try:\n",
    "                row_dict[metric_str] = eval('{}(y_true, y_pred)'.format(metric_str))\n",
    "            except Exception as e2:\n",
    "                row_dict[metric_str] = np.nan\n",
    "    rows_list.append(row_dict)\n",
    "entropy_df = pd.DataFrame(rows_list, columns=columns_list).dropna(axis='columns', how='all')\n",
    "entropy_df.set_index('clf_name', drop=True, inplace=True)\n",
    "s.store_objects(entropy_df=entropy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['training_duration', 'inference_duration', 'balanced_accuracy_score', 'r2_score']\n",
    "entropy_df[columns_list].sort_values('balanced_accuracy_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entropy_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit_estimators_list = s.load_object('fit_estimators_list')\n",
    "fit_estimators_dict = {str(type(clf)).split('.')[-1].split(\"'\")[0]: clf for clf in fit_estimators_list}\n",
    "s.store_objects(fit_estimators_dict=fit_estimators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "\n",
    "s = Storage()\n",
    "entropy_df = s.load_object('entropy_df')\n",
    "metrics_list = s.load_object('metrics_list')\n",
    "custom_metrics_list = ['boundary_diff', 'clf_yes_entropy', 'relative_yes_entropy']\n",
    "columns_list = metrics_list + custom_metrics_list\n",
    "columns_list = [cn for cn, s in sorted([(cn, entropy_df[cn].std()) for cn in columns_list], key=lambda x: x[1], reverse=True)][:3]\n",
    "for metric in columns_list:\n",
    "    print('{}: {}'.format(metric, description_dict[metric]))\n",
    "AxesSubplot_obj = entropy_df[columns_list].sort_values('r2_score', ascending=True).plot.line(rot=45, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "description_dict = s.load_object('description_dict')\n",
    "columns_list = ['training_duration', 'inference_duration', 'balanced_accuracy_score', 'r2_score']\n",
    "for metric in columns_list:\n",
    "    if metric in description_dict:\n",
    "        print('{}: {}'.format(metric, description_dict[metric]))\n",
    "entropy_df = s.load_object('entropy_df')\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_yscale('log')\n",
    "AxesSubplot_obj = entropy_df[columns_list].sort_values('training_duration', ascending=True).plot.line(rot=45, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_list = s.load_object('metrics_list')\n",
    "columns_list = [cn for cn in metrics_list if 'accur' in cn.lower()]\n",
    "for metric in columns_list:\n",
    "    if metric in description_dict:\n",
    "        print('{}: {}'.format(metric, description_dict[metric]))\n",
    "AxesSubplot_obj = entropy_df[columns_list].sort_values('accuracy_score', ascending=True).plot.line(rot=45, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entropy_df[custom_metrics_list].sort_values('boundary_diff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for metric in custom_metrics_list:\n",
    "    if metric in description_dict:\n",
    "        print('{}: {}'.format(metric, description_dict[metric]))\n",
    "AxesSubplot_obj = entropy_df[custom_metrics_list].sort_values('boundary_diff', ascending=True).plot.line(rot=45, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Add Next ORR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAH1002 - Open Requisitions Report (ORR) 2020-03-06 09_04 EST.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_name = 'BAH1002 - Open Requisitions Report (ORR) 2020-03-06 09_04 EST.csv'\n",
    "print(file_name)\n",
    "hunting_df = add_new_orr(file_name, hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4239</th>\n",
       "      <th>4240</th>\n",
       "      <th>4241</th>\n",
       "      <th>4242</th>\n",
       "      <th>4243</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hiring Manager</th>\n",
       "      <td>Douglas Persons | Doug Persons (543133)</td>\n",
       "      <td>Douglas Persons | Doug Persons (543133)</td>\n",
       "      <td>Michael Peters (608906)</td>\n",
       "      <td>John Harrison (576903)</td>\n",
       "      <td>Paul Burton (533981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Management Level</th>\n",
       "      <td>Associate</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Senior Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMT</th>\n",
       "      <td>SERVICES MI IMT</td>\n",
       "      <td>SERVICES MI IMT</td>\n",
       "      <td>PS TALENT ACQUISITION IMT</td>\n",
       "      <td>JCC IMT</td>\n",
       "      <td>NA DIGITAL SOLUTIONS IMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition</th>\n",
       "      <td>R0079159 UI/UX Engineer (Open)</td>\n",
       "      <td>R0079160 UI/UX Engineer, Senior (Open)</td>\n",
       "      <td>R0079724 UNSTOPPABLE - ERP Profile (Open)</td>\n",
       "      <td>R0080193 Wargaming Specialist (Open)</td>\n",
       "      <td>R0079769 Web Developer, Mid (Open)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Type</th>\n",
       "      <td>Sold &amp; Unfunded</td>\n",
       "      <td>Sold &amp; Unfunded</td>\n",
       "      <td>Capability Building</td>\n",
       "      <td>Sold and Funded</td>\n",
       "      <td>Sold and Funded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <td>Tampa Cluster</td>\n",
       "      <td>Wash Metro Cluster</td>\n",
       "      <td>Wash Metro Cluster</td>\n",
       "      <td>Colorado Springs Cluster</td>\n",
       "      <td>Wash Metro Cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time Type</th>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Full time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting Title</th>\n",
       "      <td>UI/UX Engineer</td>\n",
       "      <td>UI/UX Engineer, Senior</td>\n",
       "      <td>UNSTOPPABLE - ERP Profile</td>\n",
       "      <td>Wargaming Specialist</td>\n",
       "      <td>Web Developer, Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Safi Recommendation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recruiting Start Date</th>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>2020-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Group</th>\n",
       "      <td>DMI ACCT GROUP</td>\n",
       "      <td>DMI ACCT GROUP</td>\n",
       "      <td>PEOPLE SERVICES</td>\n",
       "      <td>JCC ACCT GROUP</td>\n",
       "      <td>NATL AGENCIES ACCT GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition ID</th>\n",
       "      <td>R0079159</td>\n",
       "      <td>R0079160</td>\n",
       "      <td>R0079724</td>\n",
       "      <td>R0080193</td>\n",
       "      <td>R0079769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Type</th>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supervisory Organization</th>\n",
       "      <td>Supervisory Organization (Douglas Persons | Do...</td>\n",
       "      <td>Supervisory Organization (Douglas Persons | Do...</td>\n",
       "      <td>Supervisory Organization (Michael Peters (6089...</td>\n",
       "      <td>Supervisory Organization (John Harrison (576903))</td>\n",
       "      <td>Supervisory Organization (Paul Burton (533981))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearance Agency</th>\n",
       "      <td>DOD SCI</td>\n",
       "      <td>DOD SCI</td>\n",
       "      <td>DOD</td>\n",
       "      <td>DOD SCI</td>\n",
       "      <td>UGC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location State/Province</th>\n",
       "      <td>Florida</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Furthest Stage</th>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "      <td>Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Manager</th>\n",
       "      <td>Kelly Robey (604183)</td>\n",
       "      <td>Emily Sylling (504033)</td>\n",
       "      <td>Jennifer Buchanan | Becky Buchanan (594279)</td>\n",
       "      <td>Susan Certo (838584)[C]</td>\n",
       "      <td>Emily Sylling (504033)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location</th>\n",
       "      <td>USA, FL, Tampa (4890 W Kennedy Blvd)</td>\n",
       "      <td>USA, DC, Washington (1 Columbus Cir)</td>\n",
       "      <td>USA, VA, McLean (8285 Greensboro Dr, Booz)</td>\n",
       "      <td>USA, NE, Offutt AFB (901 SAC Blvd)</td>\n",
       "      <td>USA, VA, McLean (8285 Greensboro Dr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Description</th>\n",
       "      <td>Key Role:\\nMake digital products more intuitiv...</td>\n",
       "      <td>Key Role:\\nMake digital products more intuitiv...</td>\n",
       "      <td>FAST FORWARD\\n\\nWe like to stay ahead of our t...</td>\n",
       "      <td>Key Role:\\nConsult on the design and execute s...</td>\n",
       "      <td>Key Role:\\nDesign and build Web sites or Web-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <td>NATIONAL SECURITY GROUP</td>\n",
       "      <td>NATIONAL SECURITY GROUP</td>\n",
       "      <td>CORPORATE CORE</td>\n",
       "      <td>GLOBAL DEFENSE GROUP</td>\n",
       "      <td>NATIONAL SECURITY GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Profile</th>\n",
       "      <td>UX Designer Sr</td>\n",
       "      <td>UX Designer Sr</td>\n",
       "      <td>Full Stack Developer Mid</td>\n",
       "      <td>Wargaming Analyst Mid</td>\n",
       "      <td>Visual Designer Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family Group</th>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Consulting &amp; Mission Operations</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSO</th>\n",
       "      <td>Digital Solutions</td>\n",
       "      <td>Digital Solutions</td>\n",
       "      <td>Digital Solutions</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Digital Solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family</th>\n",
       "      <td>Digital Experience</td>\n",
       "      <td>Digital Experience</td>\n",
       "      <td>Software Engineering</td>\n",
       "      <td>Wargaming Analyst</td>\n",
       "      <td>Digital Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Status</th>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Title</th>\n",
       "      <td>UX Designer Sr</td>\n",
       "      <td>UX Designer Sr</td>\n",
       "      <td>Full Stack Developer Mid</td>\n",
       "      <td>Wargaming Analyst Mid</td>\n",
       "      <td>Visual Designer Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting</th>\n",
       "      <td>UI/UX Engineer</td>\n",
       "      <td>UI/UX Engineer, Senior</td>\n",
       "      <td>UNSTOPPABLE - ERP Profile</td>\n",
       "      <td>Wargaming Specialist</td>\n",
       "      <td>Web Developer, Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location Country</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Required Clearance</th>\n",
       "      <td>TS/SCI</td>\n",
       "      <td>TS/SCI</td>\n",
       "      <td>Secret</td>\n",
       "      <td>TS/SCI</td>\n",
       "      <td>TS/SCI w/FSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Recruiter</th>\n",
       "      <td>Kelly Robey (604183)</td>\n",
       "      <td>Matthew Pruskowski (900508)[C]</td>\n",
       "      <td>Bobbi Oxendine (596463)</td>\n",
       "      <td>Susan Certo (838584)[C]</td>\n",
       "      <td>Matthew Pruskowski (900508)[C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_fit</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_opportunity_application_emailed</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_remote_delivery</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_for_university_recruiting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 4239  \\\n",
       "Hiring Manager                                Douglas Persons | Doug Persons (543133)   \n",
       "Management Level                                                            Associate   \n",
       "IMT                                                                   SERVICES MI IMT   \n",
       "Job Requisition                                        R0079159 UI/UX Engineer (Open)   \n",
       "Job Requisition Type                                                  Sold & Unfunded   \n",
       "Cluster                                                                 Tampa Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                                      UI/UX Engineer   \n",
       "Safi Recommendation                                                               NaN   \n",
       "Recruiting Start Date                                                      2020-02-20   \n",
       "Account Group                                                          DMI ACCT GROUP   \n",
       "Job Requisition ID                                                           R0079159   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization            Supervisory Organization (Douglas Persons | Do...   \n",
       "Clearance Agency                                                              DOD SCI   \n",
       "Primary Location State/Province                                               Florida   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                                 Kelly Robey (604183)   \n",
       "Primary Location                                 USA, FL, Tampa (4890 W Kennedy Blvd)   \n",
       "Job Description                     Key Role:\\nMake digital products more intuitiv...   \n",
       "Group                                                         NATIONAL SECURITY GROUP   \n",
       "Job Profile                                                            UX Designer Sr   \n",
       "Job Family Group                                                           Technology   \n",
       "FSO                                                                 Digital Solutions   \n",
       "Job Family                                                         Digital Experience   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                         UX Designer Sr   \n",
       "Job Posting                                                            UI/UX Engineer   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             TS/SCI   \n",
       "Primary Recruiter                                                Kelly Robey (604183)   \n",
       "percent_fit                                                                       NaN   \n",
       "is_opportunity_application_emailed                                              False   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 4240  \\\n",
       "Hiring Manager                                Douglas Persons | Doug Persons (543133)   \n",
       "Management Level                                                            Associate   \n",
       "IMT                                                                   SERVICES MI IMT   \n",
       "Job Requisition                                R0079160 UI/UX Engineer, Senior (Open)   \n",
       "Job Requisition Type                                                  Sold & Unfunded   \n",
       "Cluster                                                            Wash Metro Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                              UI/UX Engineer, Senior   \n",
       "Safi Recommendation                                                               NaN   \n",
       "Recruiting Start Date                                                      2020-02-20   \n",
       "Account Group                                                          DMI ACCT GROUP   \n",
       "Job Requisition ID                                                           R0079160   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization            Supervisory Organization (Douglas Persons | Do...   \n",
       "Clearance Agency                                                              DOD SCI   \n",
       "Primary Location State/Province                                  District of Columbia   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                               Emily Sylling (504033)   \n",
       "Primary Location                                 USA, DC, Washington (1 Columbus Cir)   \n",
       "Job Description                     Key Role:\\nMake digital products more intuitiv...   \n",
       "Group                                                         NATIONAL SECURITY GROUP   \n",
       "Job Profile                                                            UX Designer Sr   \n",
       "Job Family Group                                                           Technology   \n",
       "FSO                                                                 Digital Solutions   \n",
       "Job Family                                                         Digital Experience   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                         UX Designer Sr   \n",
       "Job Posting                                                    UI/UX Engineer, Senior   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             TS/SCI   \n",
       "Primary Recruiter                                      Matthew Pruskowski (900508)[C]   \n",
       "percent_fit                                                                       NaN   \n",
       "is_opportunity_application_emailed                                              False   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 4241  \\\n",
       "Hiring Manager                                                Michael Peters (608906)   \n",
       "Management Level                                                    Senior Consultant   \n",
       "IMT                                                         PS TALENT ACQUISITION IMT   \n",
       "Job Requisition                             R0079724 UNSTOPPABLE - ERP Profile (Open)   \n",
       "Job Requisition Type                                              Capability Building   \n",
       "Cluster                                                            Wash Metro Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                           UNSTOPPABLE - ERP Profile   \n",
       "Safi Recommendation                                                               NaN   \n",
       "Recruiting Start Date                                                      2020-02-27   \n",
       "Account Group                                                         PEOPLE SERVICES   \n",
       "Job Requisition ID                                                           R0079724   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization            Supervisory Organization (Michael Peters (6089...   \n",
       "Clearance Agency                                                                  DOD   \n",
       "Primary Location State/Province                                              Virginia   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                          Jennifer Buchanan | Becky Buchanan (594279)   \n",
       "Primary Location                           USA, VA, McLean (8285 Greensboro Dr, Booz)   \n",
       "Job Description                     FAST FORWARD\\n\\nWe like to stay ahead of our t...   \n",
       "Group                                                                  CORPORATE CORE   \n",
       "Job Profile                                                  Full Stack Developer Mid   \n",
       "Job Family Group                                                           Technology   \n",
       "FSO                                                                 Digital Solutions   \n",
       "Job Family                                                       Software Engineering   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                               Full Stack Developer Mid   \n",
       "Job Posting                                                 UNSTOPPABLE - ERP Profile   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             Secret   \n",
       "Primary Recruiter                                             Bobbi Oxendine (596463)   \n",
       "percent_fit                                                                       NaN   \n",
       "is_opportunity_application_emailed                                              False   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 4242  \\\n",
       "Hiring Manager                                                 John Harrison (576903)   \n",
       "Management Level                                                    Senior Consultant   \n",
       "IMT                                                                           JCC IMT   \n",
       "Job Requisition                                  R0080193 Wargaming Specialist (Open)   \n",
       "Job Requisition Type                                                  Sold and Funded   \n",
       "Cluster                                                      Colorado Springs Cluster   \n",
       "Time Type                                                                   Full time   \n",
       "Job Posting Title                                                Wargaming Specialist   \n",
       "Safi Recommendation                                                               NaN   \n",
       "Recruiting Start Date                                                      2020-03-04   \n",
       "Account Group                                                          JCC ACCT GROUP   \n",
       "Job Requisition ID                                                           R0080193   \n",
       "Job Type                                                                      Regular   \n",
       "Supervisory Organization            Supervisory Organization (John Harrison (576903))   \n",
       "Clearance Agency                                                              DOD SCI   \n",
       "Primary Location State/Province                                              Nebraska   \n",
       "Furthest Stage                                                                 Review   \n",
       "Resource Manager                                              Susan Certo (838584)[C]   \n",
       "Primary Location                                   USA, NE, Offutt AFB (901 SAC Blvd)   \n",
       "Job Description                     Key Role:\\nConsult on the design and execute s...   \n",
       "Group                                                            GLOBAL DEFENSE GROUP   \n",
       "Job Profile                                                     Wargaming Analyst Mid   \n",
       "Job Family Group                                      Consulting & Mission Operations   \n",
       "FSO                                                                        Consulting   \n",
       "Job Family                                                          Wargaming Analyst   \n",
       "Job Requisition Status                                                           Open   \n",
       "Business Title                                                  Wargaming Analyst Mid   \n",
       "Job Posting                                                      Wargaming Specialist   \n",
       "Primary Location Country                                     United States of America   \n",
       "Required Clearance                                                             TS/SCI   \n",
       "Primary Recruiter                                             Susan Certo (838584)[C]   \n",
       "percent_fit                                                                       NaN   \n",
       "is_opportunity_application_emailed                                              False   \n",
       "is_remote_delivery                                                                NaN   \n",
       "is_for_university_recruiting                                                      NaN   \n",
       "\n",
       "                                                                                 4243  \n",
       "Hiring Manager                                                   Paul Burton (533981)  \n",
       "Management Level                                                    Senior Consultant  \n",
       "IMT                                                          NA DIGITAL SOLUTIONS IMT  \n",
       "Job Requisition                                    R0079769 Web Developer, Mid (Open)  \n",
       "Job Requisition Type                                                  Sold and Funded  \n",
       "Cluster                                                            Wash Metro Cluster  \n",
       "Time Type                                                                   Full time  \n",
       "Job Posting Title                                                  Web Developer, Mid  \n",
       "Safi Recommendation                                                               NaN  \n",
       "Recruiting Start Date                                                      2020-02-27  \n",
       "Account Group                                                NATL AGENCIES ACCT GROUP  \n",
       "Job Requisition ID                                                           R0079769  \n",
       "Job Type                                                                      Regular  \n",
       "Supervisory Organization              Supervisory Organization (Paul Burton (533981))  \n",
       "Clearance Agency                                                                  UGC  \n",
       "Primary Location State/Province                                              Virginia  \n",
       "Furthest Stage                                                                 Review  \n",
       "Resource Manager                                               Emily Sylling (504033)  \n",
       "Primary Location                                 USA, VA, McLean (8285 Greensboro Dr)  \n",
       "Job Description                     Key Role:\\nDesign and build Web sites or Web-b...  \n",
       "Group                                                         NATIONAL SECURITY GROUP  \n",
       "Job Profile                                                       Visual Designer Mid  \n",
       "Job Family Group                                                           Technology  \n",
       "FSO                                                                 Digital Solutions  \n",
       "Job Family                                                         Digital Experience  \n",
       "Job Requisition Status                                                           Open  \n",
       "Business Title                                                    Visual Designer Mid  \n",
       "Job Posting                                                        Web Developer, Mid  \n",
       "Primary Location Country                                     United States of America  \n",
       "Required Clearance                                                       TS/SCI w/FSP  \n",
       "Primary Recruiter                                      Matthew Pruskowski (900508)[C]  \n",
       "percent_fit                                                                       NaN  \n",
       "is_opportunity_application_emailed                                              False  \n",
       "is_remote_delivery                                                                NaN  \n",
       "is_for_university_recruiting                                                      NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hunting_df.tail(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Flag setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set remote delivery for this list of jobs\n",
    "req_id_list = ['R0073564', 'R0073583', 'R0073584', 'R0073585', 'R0073586']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] == True\n",
    "hunting_df.loc[match_series, 'is_opportunity_application_emailed'] = True\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\Miscellaneous\\saves\\pickle\\hunting_df.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set remote delivery for this one job\n",
    "req_id = 'R007921'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] == False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set university recruiting for this job\n",
    "req_id = 'R0066388'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_for_university_recruiting'] = 1\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note you can't do this job from home\n",
    "req_id = 'R0064764'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "hunting_df.loc[match_series, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually note you can't do this job from home\n",
    "hunting_df.loc[83, 'is_remote_delivery'] = False\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.index == 2616)\n",
    "hunting_df.loc[match_series, 'is_for_university_recruiting'] = 1\n",
    "hunting_df.loc[match_series, 'percent_fit'] = 0.0\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id = 'R0063832'\n",
    "print_job_description(req_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    if re.search(r'\\bIAT\\b', str(x)):\n",
    "        results = True\n",
    "    else:\n",
    "        results = False\n",
    "    \n",
    "    return results\n",
    "\n",
    "match_series = basic_quals_df.qualification_str.map(f)\n",
    "for qual in basic_quals_df[match_series].qualification_str.tolist():\n",
    "    print('•\\t{} = {}'.format(qual, basic_quals_dict[qual]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basic_quals_dict['Ability to operate independently and manage staff'] = 0\n",
    "s.store_objects(basic_quals_dict=basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id = 'R0073507'\n",
    "match_series = (hunting_df['Job Requisition ID'] == req_id)\n",
    "print(hunting_df[match_series]['percent_fit'].tolist())\n",
    "for row_index, row_series in hunting_df[match_series].iterrows():\n",
    "    quals_list, job_fitness = print_fit_job(row_index, row_series, basic_quals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.loc[504, 'percent_fit'] = (1+1+1+1+0+1+1)/7\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "req_id_list = ['R0073564', 'R0073583', 'R0073584', 'R0073585', 'R0073586']\n",
    "match_series = hunting_df['Job Requisition ID'].isin(req_id_list)\n",
    "hunting_df[match_series].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.index == 437)\n",
    "print(hunting_df[match_series]['Job Description'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (hunting_df.percent_fit >= 0.0)\n",
    "print(hunting_df[~match_series].sample(1)['Job Description'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(['hunting_df.{}'.format(fn) for fn in dir(hunting_df) if 'dup' in fn.lower()])\n",
    "match_series = hunting_df.duplicated(subset='Job Requisition ID', keep=False)\n",
    "print(hunting_df[match_series].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['Hiring Manager', 'Management Level', 'IMT', 'Job Requisition', 'Job Requisition Type', 'Cluster', 'Time Type',\n",
    "                'Job Posting Title', 'Recruiting Start Date', 'Account Group', 'Job Requisition ID', 'Job Type',\n",
    "                'Supervisory Organization', 'Clearance Agency', 'Primary Location State/Province', 'Furthest Stage',\n",
    "                'Resource Manager', 'Primary Location', 'Job Description', 'Group', 'Job Profile', 'Job Family Group', 'FSO',\n",
    "                'Job Family', 'Job Requisition Status', 'Business Title', 'Job Posting', 'Primary Location Country',\n",
    "                'Required Clearance', 'Primary Recruiter']\n",
    "hunting_df = hunting_df.drop_duplicates(subset=columns_list, ignore_index=True)\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_list = hunting_df[match_series].index.tolist()\n",
    "first = idx_list[0]\n",
    "second = idx_list[1]\n",
    "columns_list = []\n",
    "for column_name in hunting_df.columns:\n",
    "    if hunting_df.loc[first, column_name] == hunting_df.loc[second, column_name]:\n",
    "        columns_list.append(column_name)\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = hunting_df.percent_fit.isnull()\n",
    "print(hunting_df[match_series].shape)\n",
    "req_id = hunting_df.loc[481, 'Job Requisition ID']\n",
    "print_job_description(req_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(['{}'.format(fn) for fn in hunting_df.columns if 'req' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_regex = re.compile(r'([^0-9A-Za-z\\+ \\/)(:,]+)-')\n",
    "for old_key in basic_quals_dict.keys():\n",
    "    match_obj = key_regex.search(old_key)\n",
    "    if match_obj:\n",
    "        print('\"{}\": {}'.format(match_obj.group(1), old_key))\n",
    "        #new_key = re.sub('^[?â-]+', '', old_key)\n",
    "        #print(new_key)\n",
    "        #basic_quals_dict[new_key] = basic_quals_dict.pop(old_key)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_regex = re.compile(r'\\s+$')\n",
    "old_key_list = basic_quals_dict.copy().keys()\n",
    "for old_key in old_key_list:\n",
    "    match_obj = key_regex.search(old_key)\n",
    "    if match_obj:\n",
    "        #print('\"{}\": {}'.format(match_obj.group(1), old_key))\n",
    "        new_key = re.sub(r'\\s+$', '', old_key)\n",
    "        #print(new_key)\n",
    "        basic_quals_dict[new_key] = basic_quals_dict.pop(old_key)\n",
    "        #print(old_key)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Manually score unscored jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df.loc[436, 'percent_fit'] = (0+1+1+1+1+1)/6\n",
    "s.store_objects(hunting_df=hunting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Study of the Safi recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "match_series = (hunting_df['Safi Recommendation'] == 1)\n",
    "[c[10:100].strip() for c in random.choices(population=hunting_df[match_series]['Job Description'].unique(), k=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(hunting_df=hunting_df)\n",
    "match_series = (hunting_df['Safi Recommendation'] == 1)\n",
    "hunting_df[match_series]['Primary Location State/Province'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Requisition'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Cluster'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Family'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Account Group'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Resource Manager'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Requisition Type'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df[match_series]['Job Posting'].unique()[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Hiring Manager'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['IMT'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Required Clearance'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Job Profile'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Management Level'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Clearance Agency'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Group'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Job Profile'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[cn for cn in columns_list if 'loca' in cn.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Primary Location'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "item_list = population=hunting_df[match_series]['Primary Recruiter'].unique().tolist()\n",
    "if len(item_list) > 10:\n",
    "    print(random.choices(item_list, k=10))\n",
    "else:\n",
    "    print(item_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Initial dataframe creation (don't run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_dir = r'D:\\Documents\\Administrivia\\Job Hunting'\n",
    "columns_list = []\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    #path = root.split(os.sep)\n",
    "    #print((len(path)-1) * '---', os.path.basename(root))\n",
    "    for file in files:\n",
    "        #print(len(path) * '---', file)\n",
    "        if file.endswith('.csv'):\n",
    "            print(file)\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, encoding='iso8859-1')\n",
    "                columns_list = list(set(columns_list) | set(df.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hunting_df = pd.DataFrame([], columns=columns_list)\n",
    "\n",
    "for root, dirs, files in os.walk(hunting_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_name = os.path.join(hunting_dir, file)\n",
    "            if os.path.isfile(file_name):\n",
    "                df = pd.read_csv(file_name, encoding='iso8859-1')\n",
    "                hunting_df = pd.concat([hunting_df, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "command_str = '{sys.executable} -m pip install pyOutlook'.format(sys=sys)\n",
    "print(command_str)\n",
    "!{command_str}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
