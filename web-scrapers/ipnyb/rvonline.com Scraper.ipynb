{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.rvonline.com/index.html\n"
     ]
    }
   ],
   "source": [
    "siteUrl = \"https://www.rvonline.com/index.html\"\n",
    "print(siteUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.poolmanager import PoolManager\n",
    "import ssl\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class MyAdapter(HTTPAdapter):\n",
    "    def init_poolmanager(self, connections, maxsize, block=False):\n",
    "        self.poolmanager = PoolManager(num_pools=connections,\n",
    "                                       maxsize=maxsize,\n",
    "                                       block=block,\n",
    "                                       ssl_version=ssl.PROTOCOL_TLSv1)\n",
    "\n",
    "s = requests.Session()\n",
    "s.mount('https://', MyAdapter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motorhomeLink = \"https://www.rvonline.com/motorhomes/mhprice.html\"\n",
    "fifthwheelLink = \"https://www.rvonline.com/motorhomes-5th-wheels.asp?Searchmethod=2&SortedBy=2\"\n",
    "trailerLink = \"https://www.rvonline.com/motorhomes-5th-wheels.asp?Searchmethod=3&SortedBy=2\"\n",
    "miscLink = \"https://www.rvonline.com/dinghy-tow-toads-trucks/dinghy-tow-vehicles-toad-trucks-haulers.html\"\n",
    "expensivemotorhomeLink = \"https://www.rvonline.com/motorhomes-5th-wheels.asp?Searchmethod=1&SortedBy=7\"\n",
    "mediummotorhomeLink = \"https://www.rvonline.com/motorhomes-5th-wheels.asp?Searchmethod=1&SortedBy=8\"\n",
    "cheapmotorhomelink = \"https://www.rvonline.com/motorhomes-5th-wheels.asp?Searchmethod=1&SortedBy=9\"\n",
    "siteLinks = {\n",
    "    'expensivemotorhomervonline': expensivemotorhomeLink,\n",
    "    'mediummotorhomervonline': mediummotorhomeLink,\n",
    "    'cheapmotorhomervonline': cheapmotorhomelink,\n",
    "    'fifthwheelrvonline': fifthwheelLink, \n",
    "    'trailerrvonline': trailerLink, \n",
    "    'miscrvonline': miscLink\n",
    "}\n",
    "sold_urls_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "phoneRe = re.compile(r\"Phone: *\\(?[0-9]{3}\\)?[-. ]?[0-9]{3}[-. ]?([0-9]{4}|[0-9]{3}(zero|one|two|three|four|five|six|seven|eight|nine))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 of 2 Motorhomes priced $99,999 thru $50,000\n",
      "Page 2 of 2 Motorhomes priced $99,999 thru $50,000\n",
      "Page 1 of 1 Travel Trailers / Park Models / Slide-Ins /Pop-Ups Sorted by Price\n",
      "Page 1 of 3 Motorhomes priced at or above $100,000\n",
      "Page 2 of 3 Motorhomes priced at or above $100,000\n",
      "Page 3 of 3 Motorhomes priced at or above $100,000\n",
      "Dinghy Tow Vehicles/Toads/Trucks/Haulers/Misc/ for sale\n",
      "Page 1 of 1 Motorhomes priced below $50,000\n",
      "Page 1 of 1 5th-Wheels for Sale Sorted by Price\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "\n",
    "for fileName, siteUrl in siteLinks.items():\n",
    "    #print(fileName)\n",
    "    seen_urls_array = []\n",
    "    \n",
    "    # Retrieve the page with tag results and set it up to be scraped\n",
    "    siteSoup = BeautifulSoup(s.get(siteUrl).text, 'lxml')\n",
    "    \n",
    "    # Get the max page link\n",
    "    max_page = 1\n",
    "    navLinks = siteSoup.select('center > a')\n",
    "    #print('\\n')\n",
    "    #print(navLinks)\n",
    "    #print('\\n')\n",
    "    for navLink in navLinks:\n",
    "        url = urllib.parse.urljoin(siteUrl, re.sub(' ', '%20', navLink['href']))\n",
    "        match = re.search(r\"&PAGE=(\\d+)\", url)\n",
    "        if match:\n",
    "            max_page = max(int(match.group(1)), max_page)\n",
    "    \n",
    "    for j in range(1, max_page+1):\n",
    "\n",
    "        # Retrieve the page with tag results and set it up to be scraped\n",
    "        rvListsUrl = \"&\".join([siteUrl, \"PAGE=\"+str(j)])\n",
    "        #print(rvListsUrl)\n",
    "        response = s.get(rvListsUrl)\n",
    "        match = re.search(r\"200\", str(response))\n",
    "        if not match:\n",
    "            response = s.get(siteUrl)\n",
    "\n",
    "        rvListsSoup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "        crumbTag = rvListsSoup.select('center > center')\n",
    "        #print('\\n')\n",
    "        #print(crumbTag)\n",
    "        #print('\\n')\n",
    "        if len(crumbTag) >= 3:\n",
    "            crumbArray = crumbTag[2].get_text().strip().split('\\xa0')\n",
    "            print(crumbArray[0], crumbArray[-1])\n",
    "        else:\n",
    "            print(rvListsSoup.title.text)\n",
    "        \n",
    "        # Get the links\n",
    "        pageLinks = rvListsSoup.find_all(\"a\")\n",
    "        #print(pageLinks)\n",
    "\n",
    "        for pageLink in pageLinks:\n",
    "            pageUrl = urllib.parse.urljoin(rvListsUrl, re.sub(' ', '%20', pageLink['href']))\n",
    "            #print(pageUrl)\n",
    "            match = re.search(r\"sold\\.gif\", str(pageLink.nextSibling))\n",
    "            if match:\n",
    "                firstMatch = True\n",
    "            else:\n",
    "                firstMatch = False\n",
    "            if pageLink.nextSibling is None:\n",
    "                secondMatch = False\n",
    "            else:\n",
    "                match = re.search(r\"sold\\.gif\", str(pageLink.nextSibling.nextSibling))\n",
    "                if match:\n",
    "                    secondMatch = True\n",
    "                else:\n",
    "                    secondMatch = False\n",
    "            if firstMatch or secondMatch:\n",
    "                if pageUrl not in sold_urls_array:\n",
    "                    sold_urls_array.append(pageUrl)\n",
    "            if pageUrl not in seen_urls_array and pageUrl not in sold_urls_array:\n",
    "                seen_urls_array.append(pageUrl)\n",
    "                    \n",
    "    for pageUrl in seen_urls_array:\n",
    "        if pageUrl not in sold_urls_array:\n",
    "            try:\n",
    "                response = s.get(pageUrl)\n",
    "                #print(response)\n",
    "                match = re.search(r\"200\", str(response))\n",
    "                if match:\n",
    "                    pageSoup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                    # Get model\n",
    "                    model = \"Unknown\"\n",
    "                    modelCss = \"h3 > b\"\n",
    "                    modelTag = pageSoup.select(modelCss)\n",
    "                    if not len(modelTag):\n",
    "                        modelCss = \"td > font > b\"\n",
    "                        modelTag = pageSoup.select(modelCss)\n",
    "                    if len(modelTag):\n",
    "                        match = re.search(r\"sold\\.gif\", str(modelTag[0]))\n",
    "                        if not match:\n",
    "                            model = modelTag[0].get_text().strip()\n",
    "\n",
    "                    # Get price\n",
    "                    price = \"Unknown\"\n",
    "                    priceCss = \"h4 > b\"\n",
    "                    priceString = \"\"\n",
    "                    priceTag = pageSoup.select(priceCss)\n",
    "                    if len(priceTag):\n",
    "                        priceString = priceTag[0].get_text().strip()\n",
    "                    else:\n",
    "                        priceCss = \"td > font > b\"\n",
    "                        priceTag = pageSoup.select(priceCss)\n",
    "                        if len(priceTag):\n",
    "                            priceString = priceTag[1].get_text().strip()\n",
    "                    if len(priceString):\n",
    "                        match = re.search(r\"\\$ *[0-9,]+\", str(priceString))\n",
    "                        if match:\n",
    "                            price = match.group()\n",
    "\n",
    "                    # Get phone\n",
    "                    phone = \"\"\n",
    "                    phoneTag = pageSoup.select(\"body\")\n",
    "                    phoneString = phoneTag[0].get_text().strip()\n",
    "                    match = phoneRe.search(phoneString)\n",
    "                    if match:\n",
    "                        phone = match.group(0)\n",
    "                    else:\n",
    "                        fontTag = pageSoup.select(\"font\")\n",
    "                        for font in fontTag:\n",
    "                            phoneString = font.get_text().strip()\n",
    "                            match = phoneRe.search(phoneString)\n",
    "                            if match:\n",
    "                                phone = match.group(0)\n",
    "                                break\n",
    "\n",
    "                    if len(phone):\n",
    "                        bigFile = open(fileName + '.txt', 'a', encoding='utf-8')\n",
    "                        bigFile.write(model + '\\t' + price + '\\t' + phone + '\\n')\n",
    "                        bigFile.close()\n",
    "                        #print('\\n' + pageUrl)\n",
    "                        #print(model)\n",
    "                        #print(price)\n",
    "                        #print(phone)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(pageUrl + \": \" + str(e))\n",
    "                #pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
