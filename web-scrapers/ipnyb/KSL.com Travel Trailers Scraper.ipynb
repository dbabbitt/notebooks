{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ksl.com/classifieds/search/?keyword=&category%5B%5D=Recreational+Vehicles&subCategory%5B%5D=Travel+Trailers%2C+5th+Wheel&priceFrom=10000&priceTo=100000000&sellerType%5B%5D=Private&city=&state=&zip=&miles=25&sort=0\n"
     ]
    }
   ],
   "source": [
    "siteUrl = \"http://www.ksl.com/classifieds/search/\"\n",
    "siteUrl = \"?\".join([siteUrl, \"keyword=\"])\n",
    "siteUrl = \"&\".join([siteUrl, \"category%5B%5D=Recreational+Vehicles\"])\n",
    "siteUrl = \"&\".join([siteUrl, \"subCategory%5B%5D=Travel+Trailers%2C+5th+Wheel\"])\n",
    "siteUrl = \"&\".join([siteUrl, \"priceFrom=10000\"])\n",
    "siteUrl = \"&\".join([siteUrl, \"priceTo=100000000\"])\n",
    "siteUrl = \"&\".join([siteUrl, \"sellerType%5B%5D=Private\"])\n",
    "siteUrl = \"&\".join([siteUrl, \"city=\"])\n",
    "siteUrl = \"&\".join([siteUrl, \"state=\"])\n",
    "siteUrl = \"&\".join([siteUrl, \"zip=\"])\n",
    "siteUrl = \"&\".join([siteUrl, \"miles=25\"])\n",
    "siteUrl = \"&\".join([siteUrl, \"sort=0\"])\n",
    "print(siteUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from base64 import b64encode\n",
    "\n",
    "proxy = {'host': '23.19.51.245', 'port': '40791', 'usr': '<<USERID>>', 'pwd': '<<PASSWORD>>'}\n",
    "# Retrieve the page with tag results and set it up to be scraped\n",
    "fp = webdriver.FirefoxProfile()\n",
    "fp.set_preference('network.proxy.type', 1)\n",
    "fp.set_preference('network.proxy.http', proxy['host'])\n",
    "fp.set_preference('network.proxy.http_port', int(proxy['port']))\n",
    "fp.set_preference('network.proxy.no_proxies_on', 'localhost, 127.0.0.1')\n",
    "fp.add_extension('closeproxy.xpi')\n",
    "credentials = '{usr}:{pwd}'.format(**proxy)\n",
    "credentials = b64encode(credentials.encode('ascii')).decode('utf-8')\n",
    "fp.set_preference('extensions.closeproxyauth.authtoken', credentials)\n",
    "\n",
    "#set some privacy settings\n",
    "fp.set_preference( \"places.history.enabled\", False )\n",
    "fp.set_preference( \"privacy.clearOnShutdown.offlineApps\", True )\n",
    "fp.set_preference( \"privacy.clearOnShutdown.passwords\", True )\n",
    "fp.set_preference( \"privacy.clearOnShutdown.siteSettings\", True )\n",
    "fp.set_preference( \"privacy.sanitize.sanitizeOnShutdown\", True )\n",
    "fp.set_preference( \"signon.rememberSignons\", False )\n",
    "fp.set_preference( \"network.cookie.lifetimePolicy\", 2 )\n",
    "fp.set_preference( \"network.dns.disablePrefetch\", True )\n",
    "fp.set_preference( \"network.http.sendRefererHeader\", 0 )\n",
    "\n",
    "#if you're really hardcore about your security\n",
    "#js can be used to reveal your true i.p.\n",
    "fp.set_preference( \"javascript.enabled\", False )\n",
    "\n",
    "#get a huge speed increase by not downloading images\n",
    "fp.set_preference( \"permissions.default.image\", 2 )\n",
    "\n",
    "ffDriver = webdriver.Firefox(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Error loading page, timed out (checkLoad)\n",
      "\n",
      "Message: Error loading page, timed out (checkLoad)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# set timeout information\n",
    "ffDriver.set_page_load_timeout(5)\n",
    "\n",
    "finished = 0\n",
    "while finished == 0:\n",
    "    try:\n",
    "        ffDriver.get(siteUrl)\n",
    "        finished = 1\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "def wait_for(condition_function):\n",
    "    start_time = time.time()\n",
    "    while time.time() < start_time + 6:\n",
    "        if condition_function():\n",
    "            return True\n",
    "        else:\n",
    "            time.sleep(0.1)\n",
    "    raise Exception(\n",
    "        'Timeout waiting for {}'.format(condition_function.__name__)\n",
    "    )\n",
    "\n",
    "class wait_for_page_load(object):\n",
    "\n",
    "    def __init__(self, browser):\n",
    "        self.ffDriver = ffDriver\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.old_page = self.ffDriver.find_element_by_tag_name('html')\n",
    "\n",
    "    def page_has_loaded(self):\n",
    "        new_page = self.ffDriver.find_element_by_tag_name('html')\n",
    "        time.sleep(0.1)\n",
    "        return new_page.id != self.old_page.id\n",
    "\n",
    "    def __exit__(self, *_):\n",
    "        wait_for(self.page_has_loaded)\n",
    "\n",
    "def get_page_urls(driver):\n",
    "    page_source = driver.page_source\n",
    "    current_url = driver.current_url\n",
    "    \n",
    "    # Retrieve the page with tag results and set it up to be scraped\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "    pageLinks = soup.select('h2 a.link')\n",
    "    for pageLink in pageLinks:\n",
    "        pageUrl = urllib.parse.urljoin(current_url, re.sub(' ', '%20', pageLink['href']))\n",
    "        if pageUrl not in seen_urls_array:\n",
    "            seen_urls_array.append(pageUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Next »\" link is missing: Message: Unable to locate element: html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import re\n",
    "\n",
    "seen_urls_array = []\n",
    "get_page_urls(ffDriver)\n",
    "while True:\n",
    "    try:\n",
    "        with wait_for_page_load(ffDriver):\n",
    "            ffDriver.find_element_by_link_text('Next »').click()\n",
    "        get_page_urls(ffDriver)\n",
    "    except NoSuchElementException as e:\n",
    "        print('The \"Next »\" link is missing: ' + str(e))\n",
    "        break  # cannot click the link anymore\n",
    "    except TimeoutException as e:\n",
    "        print('We timed out: ' + str(e))\n",
    "        break  # cannot click the link anymore\n",
    "    except Exception as e:\n",
    "        if re.search(r\"Timeout\", str(e)):\n",
    "            break # cannot click the link any more\n",
    "        else:\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ffDriver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ksl.com/classifieds/listing/42977318\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "import requests\n",
    "\n",
    "pageUrl = seen_urls_array[randint(0,len(seen_urls_array)-1)]\n",
    "print(pageUrl)\n",
    "\n",
    "page = requests.get(url=pageUrl)\n",
    "soup = BeautifulSoup(page.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cherokee\n",
      "$20,000.00\n",
      "(435) 830-7675\n"
     ]
    }
   ],
   "source": [
    "model = soup.select(\"div.listing-details.details-element > h2\")\n",
    "if(len(model)):\n",
    "    model = model[0].get_text().strip()\n",
    "else:\n",
    "    model = \"Unknown\"\n",
    "print(model)\n",
    "\n",
    "price = soup.select(\"div.listing-details.details-element > h3\")\n",
    "if(len(price)):\n",
    "    price = price[0].get_text().strip()\n",
    "else:\n",
    "    price = \"Unknown\"\n",
    "print(price)\n",
    "\n",
    "phone = soup.select('li.contact-homePhone > p > span')\n",
    "if(len(phone)>=2):\n",
    "    phone = phone[1].get_text().strip()\n",
    "else:\n",
    "    phone = \"\"\n",
    "print(phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 records written\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "n = 0\n",
    "for pageUrl in seen_urls_array:\n",
    "    #print(pageUrl)\n",
    "    page = requests.get(url=pageUrl)\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "    model = soup.select(\"div.listing-details.details-element > h2\")\n",
    "    if(len(model)):\n",
    "        model = model[0].get_text().strip()\n",
    "    else:\n",
    "        model = \"Unknown\"\n",
    "    price = soup.select(\"div.listing-details.details-element > h3\")\n",
    "    if(len(price)):\n",
    "        price = price[0].get_text().strip()\n",
    "    else:\n",
    "        price = \"Unknown\"\n",
    "    phone = soup.select('li.contact-homePhone > p > span')\n",
    "    if(len(phone)>=2):\n",
    "        phone = phone[1].get_text().strip()\n",
    "    else:\n",
    "        phone = \"\"\n",
    "    if len(phone):\n",
    "        bigFile = open('kslTrailers.txt', 'a', encoding='utf-8')\n",
    "        byteString = model + '\\t' + price + '\\t' + phone + '\\n'\n",
    "        try:\n",
    "            bigFile.write(byteString)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            print(model + '\\t' + price + '\\t' + phone + '\\n')\n",
    "        n = n + 1\n",
    "        bigFile.close()\n",
    "print(str(n) + \" records written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
