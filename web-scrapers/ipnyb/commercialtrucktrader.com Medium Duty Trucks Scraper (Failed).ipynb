{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import urllib.parse\n",
    "\n",
    "from selenium import webdriver\n",
    "import selenium.webdriver.support.ui as ui\n",
    "from base64 import b64encode\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.commercialtrucktrader.com/Medium-Duty-Trucks-For-Sale/search-results?type=medium\n"
     ]
    }
   ],
   "source": [
    "siteUrl = \"http://www.commercialtrucktrader.com/Medium-Duty-Trucks-For-Sale/search-results\"\n",
    "siteUrl = \"?\".join([siteUrl, \"type=medium\"])\n",
    "print(siteUrl)\n",
    "max_page = 0\n",
    "seen_urls_array = []\n",
    "proxy = {'host': '23.19.51.245', 'port': '40791', 'usr': '<<USERID>>', 'pwd': '<<PASSWORD>>'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081\n"
     ]
    }
   ],
   "source": [
    "#<a href=\"/Medium-Duty-Trucks-For-Sale/search-results?type=medium&amp;page=1081\" class=\"listings-pag-default\">1081</a>\n",
    "\n",
    "# Retrieve the page with tag results and set it up to be scraped\n",
    "sitePage = requests.get(url=siteUrl)\n",
    "sitePageSoup = BeautifulSoup(sitePage.content, 'lxml')\n",
    "\n",
    "css = 'div.listings-pag-bottom > div > a.listings-pag-default'\n",
    "pageLinks = sitePageSoup.select(css)\n",
    "if len(pageLinks):\n",
    "    max_page = int(pageLinks[-1][\"href\"].split('=')[2])\n",
    "print(max_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve the page with tag results and set it up to be scraped\n",
    "fp = webdriver.FirefoxProfile()\n",
    "fp.set_preference('network.proxy.type', 1)\n",
    "fp.set_preference('network.proxy.http', proxy['host'])\n",
    "fp.set_preference('network.proxy.http_port', int(proxy['port']))\n",
    "fp.set_preference('network.proxy.no_proxies_on', 'localhost, 127.0.0.1')\n",
    "fp.add_extension('closeproxy.xpi')\n",
    "credentials = '{usr}:{pwd}'.format(**proxy)\n",
    "credentials = b64encode(credentials.encode('ascii')).decode('utf-8')\n",
    "fp.set_preference('extensions.closeproxyauth.authtoken', credentials)\n",
    "\n",
    "#set some privacy settings\n",
    "fp.set_preference( \"places.history.enabled\", False )\n",
    "fp.set_preference( \"privacy.clearOnShutdown.offlineApps\", True )\n",
    "fp.set_preference( \"privacy.clearOnShutdown.passwords\", True )\n",
    "fp.set_preference( \"privacy.clearOnShutdown.siteSettings\", True )\n",
    "fp.set_preference( \"privacy.sanitize.sanitizeOnShutdown\", True )\n",
    "fp.set_preference( \"signon.rememberSignons\", False )\n",
    "fp.set_preference( \"network.cookie.lifetimePolicy\", 2 )\n",
    "fp.set_preference( \"network.dns.disablePrefetch\", True )\n",
    "fp.set_preference( \"network.http.sendRefererHeader\", 0 )\n",
    "\n",
    "#if you're really hardcore about your security\n",
    "#js can be used to reveal your true i.p.\n",
    "fp.set_preference( \"javascript.enabled\", False )\n",
    "\n",
    "#get a huge speed increase by not downloading images\n",
    "fp.set_preference( \"permissions.default.image\", 2 )\n",
    "\n",
    "driver = webdriver.Firefox(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Error loading page, timed out (checkLoad)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set timeout information\n",
    "driver.set_page_load_timeout(5)\n",
    "\n",
    "finished = 0\n",
    "while finished == 0:\n",
    "    try:\n",
    "        driver.get(siteUrl)\n",
    "        finished = 1\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n",
      "Message: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wait = WebDriverWait(driver, 10)\n",
    "pattern = re.compile('\\d+')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        element = wait.until(EC.element_to_be_clickable((By.LINK_TEXT, 'Next')))\n",
    "        this_title = driver.find_element_by_tag_name('title').text\n",
    "        match = pattern.search(this_title)\n",
    "        page_number = int(match.group())\n",
    "        #print(page_number)\n",
    "\n",
    "        # Retrieve the page with tag results and set it up to be scraped\n",
    "        tagPageSoup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "        pageLinks = tagPageSoup.select('div.listing-header > a > h2')\n",
    "        for pageLink in pageLinks:\n",
    "            pageUrl = urllib.parse.urljoin(siteUrl, re.sub(' ', '%20', pageLink.parent['href']))\n",
    "            #print(pageUrl)\n",
    "            if pageUrl not in seen_urls_array:\n",
    "                seen_urls_array.append(pageUrl)\n",
    "        \n",
    "        element.click()\n",
    "    except TimeoutException:\n",
    "        break  # cannot click the button anymore\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "    # TODO: wait for the results of the click action\n",
    "    try:\n",
    "        WebDriverWait(driver, 3).until(\n",
    "            EC.title_contains('Medium Duty Trucks For Sale - Page ' + str(page_number+1))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(seen_urls_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigFile = open('commercialtrucktraderMediumDutyTrucks.txt', 'a')\n",
    "for pageUrl in seen_urls_array:\n",
    "    page = requests.get(url=pageUrl)\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "    dealerLink = soup.select(\"body > div.details-container > div.details > div.details-default > div.details-right > strong\")\n",
    "    dealerName = dealerLink[0].get_text().strip()\n",
    "\n",
    "    if dealerName == \"Private Seller\":\n",
    "        model = soup.select(\"div.details > h1\")\n",
    "        if(len(model)):\n",
    "            model = model[0].get_text().strip()\n",
    "        else:\n",
    "            model = \"Unknown\"\n",
    "        price = soup.select(\"div.details-right > h2.lfloat\")\n",
    "        if(len(price)):\n",
    "            price = price[0].get_text().strip()\n",
    "        else:\n",
    "            price = \"Unknown\"\n",
    "        phone = soup.select('span.flipphone.bold.font1-1')\n",
    "        if(len(phone)>=2):\n",
    "            phone = phone[1].get_text().strip()\n",
    "        else:\n",
    "            phone = \"\"\n",
    "        if len(phone):\n",
    "            bigFile.write(model + '\\t' + price + '\\t' + phone + '\\n')\n",
    "bigFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
