{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import urllib.parse\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.commercialtrucktrader.com/Medium-Duty-Trucks-For-Sale/search-results?type=medium\n"
     ]
    }
   ],
   "source": [
    "siteUrl = \"http://www.commercialtrucktrader.com/Medium-Duty-Trucks-For-Sale/search-results\"\n",
    "siteUrl = \"?\".join([siteUrl, \"type=medium\"])\n",
    "print(siteUrl)\n",
    "max_page = 0\n",
    "seen_urls_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072\n"
     ]
    }
   ],
   "source": [
    "#<a href=\"/Heavy-Duty-Trucks-For-Sale/search-results?type=heavy&amp;page=1799\" class=\"listings-pag-default\">1799</a>\n",
    "\n",
    "# Retrieve the page with tag results and set it up to be scraped\n",
    "sitePage = requests.get(url=siteUrl)\n",
    "sitePageSoup = BeautifulSoup(sitePage.content, 'lxml')\n",
    "\n",
    "css = 'div.listings-pag-bottom > div > a.listings-pag-default'\n",
    "pageLinks = sitePageSoup.select(css)\n",
    "if len(pageLinks):\n",
    "    max_page = int(pageLinks[-1][\"href\"].split('=')[2])\n",
    "print(max_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26794\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, max_page+1):\n",
    "    tagUrl = \"&\".join([siteUrl, \"page=\"+str(i)])\n",
    "    page = requests.get(url=tagUrl)\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "    # Get the title of the page to prove we are progressing\n",
    "    titleTag = soup.select(\"head > title\")\n",
    "    titleString = titleTag[0].get_text().strip()\n",
    "    #print(titleString)\n",
    "\n",
    "    # Get the links to the individual pages\n",
    "    pageLinks = soup.select('div.listing-header > a > h2')\n",
    "    for pageLink in pageLinks:\n",
    "        pageUrl = urllib.parse.urljoin(siteUrl, re.sub(' ', '%20', pageLink.parent['href']))\n",
    "        #print(pageUrl)\n",
    "        if pageUrl not in seen_urls_array:\n",
    "            seen_urls_array.append(pageUrl)\n",
    "    \n",
    "    # Destroy the tree when you're done working with it\n",
    "    soup.decompose()\n",
    "\n",
    "# Show the number of individual page links you have\n",
    "print(len(seen_urls_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('commercialtrucktraderMediumDutyTrucks.pickle', 'wb') as handle:\n",
    "    pickle.dump(seen_urls_array, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('commercialtrucktraderMediumDutyTrucks.pickle', 'rb') as handle:\n",
    "    seen_urls_array = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceeded 30 redirects.\n"
     ]
    }
   ],
   "source": [
    "for pageUrl in seen_urls_array:\n",
    "    try:\n",
    "        page = requests.get(url=pageUrl)\n",
    "        soup = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "        dealCss = \"body > div.details-container > div.details > div.details-default > div.details-right > strong\"\n",
    "        dealerLink = soup.select(dealCss)\n",
    "        if len(dealerLink):\n",
    "            dealerName = dealerLink[0].get_text().strip()\n",
    "\n",
    "            if dealerName == \"Private Seller\":\n",
    "                model = soup.select(\"div.details > h1\")\n",
    "                if(len(model)):\n",
    "                    model = model[0].get_text().strip()\n",
    "                else:\n",
    "                    model = \"Unknown\"\n",
    "                price = soup.select(\"div.details-right > h2.lfloat\")\n",
    "                if(len(price)):\n",
    "                    price = price[0].get_text().strip()\n",
    "                else:\n",
    "                    price = \"Unknown\"\n",
    "                phone = soup.select(\"span.flipphone.bold.font1-1\")\n",
    "                if len(phone):\n",
    "                    phone = phone[0].get_text().strip()[::-1]\n",
    "                else:\n",
    "                    phone = \"\"\n",
    "                if len(phone):\n",
    "                    bigFile = open('commercialtrucktraderMediumDutyTrucks.txt', 'a')\n",
    "                    bigFile.write(model + '\\t' + price + '\\t' + phone + '\\n')\n",
    "                    bigFile.close()\n",
    "    \n",
    "        # Destroy the tree when you're done working with it\n",
    "        soup.decompose()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
