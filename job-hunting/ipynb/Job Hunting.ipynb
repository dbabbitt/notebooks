{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ../data: File exists\n",
      "mkdir: ../data/csv: File exists\n",
      "mkdir: ../saves: File exists\n",
      "mkdir: ../saves/pickle: File exists\n",
      "mkdir: ../saves/csv: File exists\n"
     ]
    }
   ],
   "source": [
    "# %load ../../load_magic/storage.py\n",
    "\n",
    "!mkdir ../data\n",
    "!mkdir ../data/csv\n",
    "!mkdir ../saves\n",
    "!mkdir ../saves/pickle\n",
    "!mkdir ../saves/csv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Handy list of the different types of encodings\n",
    "encoding = ['latin1', 'iso8859-1', 'utf-8'][1]\n",
    "\n",
    "# Change this to your data and saves folders\n",
    "data_folder = r'../data/'\n",
    "saves_folder = r'../saves/'\n",
    "\n",
    "def load_csv(csv_name=None):\n",
    "    csv_folder = data_folder + 'csv/'\n",
    "    if csv_name is None:\n",
    "        \n",
    "        # Get the newest csv\n",
    "        csv_path = max([os.path.join(csv_folder, f) for f in os.listdir(csv_folder)],\n",
    "                       key=os.path.getmtime)\n",
    "        \n",
    "    else:\n",
    "        csv_path = csv_folder + csv_name + '.csv'\n",
    "    csv_df = pd.read_csv(csv_path, encoding=encoding)\n",
    "    \n",
    "    return(csv_df)\n",
    "\n",
    "def load_object(obj_name):\n",
    "    pickle_path = saves_folder + 'pickle/' + obj_name + '.pickle'\n",
    "    try:\n",
    "        object = pd.read_pickle(pickle_path)\n",
    "    except:\n",
    "        with open(pickle_path, 'rb') as handle:\n",
    "            object = pickle.load(handle)\n",
    "    \n",
    "    return(object)\n",
    "\n",
    "def save_dataframes(include_index=False, **kwargs):\n",
    "    csv_folder = saves_folder + 'csv/'\n",
    "    for frame_name in kwargs:\n",
    "        if isinstance(kwargs[frame_name], pd.DataFrame):\n",
    "            csv_path = csv_folder + frame_name + '.csv'\n",
    "            kwargs[frame_name].to_csv(csv_path, sep=',', encoding=encoding,\n",
    "                                      index=include_index)\n",
    "\n",
    "# Classes, functions, and methods cannot be pickled\n",
    "def store_objects(**kwargs):\n",
    "    for obj_name in kwargs:\n",
    "        if hasattr(kwargs[obj_name], '__call__'):\n",
    "            raise RuntimeError('Functions cannot be pickled.')\n",
    "        obj_path = saves_folder + 'pickle/' + str(obj_name)\n",
    "        pickle_path = obj_path + '.pickle'\n",
    "        if isinstance(kwargs[obj_name], pd.DataFrame):\n",
    "            kwargs[obj_name].to_pickle(pickle_path)\n",
    "        else:\n",
    "            with open(pickle_path, 'wb') as handle:\n",
    "                pickle.dump(kwargs[obj_name], handle, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Requisition', 'Management Level', 'Required Clearance',\n",
       "       'Clearance Agency', 'Job Requisition Type', 'Group', 'Account Group',\n",
       "       'IMT', 'Cluster', 'FSO', 'Resource Manager', 'Primary Recruiter',\n",
       "       'Hiring Manager', 'Primary Location', 'Primary Location State/Province',\n",
       "       'Primary Location Country', 'Job Description', 'Job Family'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1421</th>\n",
       "      <th>330</th>\n",
       "      <th>1746</th>\n",
       "      <th>887</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Job Requisition</th>\n",
       "      <td>R0015012 Software Engineer , Mid (Open)</td>\n",
       "      <td>R0018687 RES Engineer (Open)</td>\n",
       "      <td>R0011659 Disaster Recovery Engineer, Senior (O...</td>\n",
       "      <td>R0017175 SharePoint Designer (Open)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Management Level</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Senior Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Required Clearance</th>\n",
       "      <td>Secret</td>\n",
       "      <td>Eligibility Determination Timeline</td>\n",
       "      <td>TS/SCI</td>\n",
       "      <td>TS/SCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearance Agency</th>\n",
       "      <td>DOD</td>\n",
       "      <td>DHS</td>\n",
       "      <td>DOD</td>\n",
       "      <td>DOD SCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Requisition Type</th>\n",
       "      <td>Sold &amp; Unfunded</td>\n",
       "      <td>Contingent</td>\n",
       "      <td>Contingent</td>\n",
       "      <td>Sold and Funded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <td>DEFENSE &amp; INTELLIGENCE GROUP</td>\n",
       "      <td>STRATEGIC INNOVATION GROUP</td>\n",
       "      <td>DEFENSE &amp; INTELLIGENCE GROUP</td>\n",
       "      <td>DEFENSE &amp; INTELLIGENCE GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Group</th>\n",
       "      <td>AIR FORCE ACCT GROUP</td>\n",
       "      <td>CYBER ISO/FSO ACCT GROUP</td>\n",
       "      <td>JCC ACCT GROUP</td>\n",
       "      <td>DMI ACCT GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMT</th>\n",
       "      <td>AF A&amp;L IMT</td>\n",
       "      <td>CYBER FSO IMT</td>\n",
       "      <td>JCC IMT</td>\n",
       "      <td>MIA IMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <td>Dayton Cluster</td>\n",
       "      <td>Wash Metro Cluster</td>\n",
       "      <td>Tampa Cluster</td>\n",
       "      <td>Natl Business Park Cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSO</th>\n",
       "      <td>Digital Solutions</td>\n",
       "      <td>Cyber</td>\n",
       "      <td>Digital Solutions</td>\n",
       "      <td>Digital Solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Manager</th>\n",
       "      <td>Kiran Syed | Kiran Zafar (530950)</td>\n",
       "      <td>Monae Nickerson (576625)</td>\n",
       "      <td>Elizabeth Overstreet (538581)</td>\n",
       "      <td>Celeste Thai (547794)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Recruiter</th>\n",
       "      <td>Jessica McCann (838463)[C]</td>\n",
       "      <td>Alexandra Clemmons | Sasha Clemmons (576686)</td>\n",
       "      <td>Jason Cook (595388)</td>\n",
       "      <td>Melanie Myers-Echague (558104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hiring Manager</th>\n",
       "      <td>Robert Goble (571380)</td>\n",
       "      <td>Erica Banks (514131)</td>\n",
       "      <td>Christopher Meyer | Chris Meyer (526902)</td>\n",
       "      <td>Jerrod Bryson (554744)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location</th>\n",
       "      <td>USA, OH, Dayton (4180 Watson Way)</td>\n",
       "      <td>USA, VA, McLean (8283 Greensboro Dr, Hamilton)</td>\n",
       "      <td>USA, FL, Tampa (S Boundary Blvd)</td>\n",
       "      <td>USA, MD, Fort Meade (9800 Savage Rd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location State/Province</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location Country</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Description</th>\n",
       "      <td>Key Role:\\rApply technical knowledge of softwa...</td>\n",
       "      <td>Key Role:\\rWork with a highly skilled team foc...</td>\n",
       "      <td>Key Role:\\rManage the overall strategy for dis...</td>\n",
       "      <td>Key Role:\\rMaintain responsibility for the des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Cyber Security Operations Engineer</td>\n",
       "      <td>SD Data Architect</td>\n",
       "      <td>Digital Creative Communications Consultant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              1421  \\\n",
       "Job Requisition                            R0015012 Software Engineer , Mid (Open)   \n",
       "Management Level                                                 Senior Consultant   \n",
       "Required Clearance                                                          Secret   \n",
       "Clearance Agency                                                               DOD   \n",
       "Job Requisition Type                                               Sold & Unfunded   \n",
       "Group                                                 DEFENSE & INTELLIGENCE GROUP   \n",
       "Account Group                                                 AIR FORCE ACCT GROUP   \n",
       "IMT                                                                     AF A&L IMT   \n",
       "Cluster                                                             Dayton Cluster   \n",
       "FSO                                                              Digital Solutions   \n",
       "Resource Manager                                 Kiran Syed | Kiran Zafar (530950)   \n",
       "Primary Recruiter                                       Jessica McCann (838463)[C]   \n",
       "Hiring Manager                                               Robert Goble (571380)   \n",
       "Primary Location                                 USA, OH, Dayton (4180 Watson Way)   \n",
       "Primary Location State/Province                                               Ohio   \n",
       "Primary Location Country                                  United States of America   \n",
       "Job Description                  Key Role:\\rApply technical knowledge of softwa...   \n",
       "Job Family                                                       Software Engineer   \n",
       "\n",
       "                                                                              330   \\\n",
       "Job Requisition                                       R0018687 RES Engineer (Open)   \n",
       "Management Level                                                         Associate   \n",
       "Required Clearance                              Eligibility Determination Timeline   \n",
       "Clearance Agency                                                               DHS   \n",
       "Job Requisition Type                                                    Contingent   \n",
       "Group                                                   STRATEGIC INNOVATION GROUP   \n",
       "Account Group                                             CYBER ISO/FSO ACCT GROUP   \n",
       "IMT                                                                  CYBER FSO IMT   \n",
       "Cluster                                                         Wash Metro Cluster   \n",
       "FSO                                                                          Cyber   \n",
       "Resource Manager                                          Monae Nickerson (576625)   \n",
       "Primary Recruiter                     Alexandra Clemmons | Sasha Clemmons (576686)   \n",
       "Hiring Manager                                                Erica Banks (514131)   \n",
       "Primary Location                    USA, VA, McLean (8283 Greensboro Dr, Hamilton)   \n",
       "Primary Location State/Province                                           Virginia   \n",
       "Primary Location Country                                  United States of America   \n",
       "Job Description                  Key Role:\\rWork with a highly skilled team foc...   \n",
       "Job Family                                      Cyber Security Operations Engineer   \n",
       "\n",
       "                                                                              1746  \\\n",
       "Job Requisition                  R0011659 Disaster Recovery Engineer, Senior (O...   \n",
       "Management Level                                                         Associate   \n",
       "Required Clearance                                                          TS/SCI   \n",
       "Clearance Agency                                                               DOD   \n",
       "Job Requisition Type                                                    Contingent   \n",
       "Group                                                 DEFENSE & INTELLIGENCE GROUP   \n",
       "Account Group                                                       JCC ACCT GROUP   \n",
       "IMT                                                                        JCC IMT   \n",
       "Cluster                                                              Tampa Cluster   \n",
       "FSO                                                              Digital Solutions   \n",
       "Resource Manager                                     Elizabeth Overstreet (538581)   \n",
       "Primary Recruiter                                              Jason Cook (595388)   \n",
       "Hiring Manager                            Christopher Meyer | Chris Meyer (526902)   \n",
       "Primary Location                                  USA, FL, Tampa (S Boundary Blvd)   \n",
       "Primary Location State/Province                                            Florida   \n",
       "Primary Location Country                                  United States of America   \n",
       "Job Description                  Key Role:\\rManage the overall strategy for dis...   \n",
       "Job Family                                                       SD Data Architect   \n",
       "\n",
       "                                                                              887   \n",
       "Job Requisition                                R0017175 SharePoint Designer (Open)  \n",
       "Management Level                                                 Senior Consultant  \n",
       "Required Clearance                                                          TS/SCI  \n",
       "Clearance Agency                                                           DOD SCI  \n",
       "Job Requisition Type                                               Sold and Funded  \n",
       "Group                                                 DEFENSE & INTELLIGENCE GROUP  \n",
       "Account Group                                                       DMI ACCT GROUP  \n",
       "IMT                                                                        MIA IMT  \n",
       "Cluster                                                 Natl Business Park Cluster  \n",
       "FSO                                                              Digital Solutions  \n",
       "Resource Manager                                             Celeste Thai (547794)  \n",
       "Primary Recruiter                                   Melanie Myers-Echague (558104)  \n",
       "Hiring Manager                                              Jerrod Bryson (554744)  \n",
       "Primary Location                              USA, MD, Fort Meade (9800 Savage Rd)  \n",
       "Primary Location State/Province                                           Maryland  \n",
       "Primary Location Country                                  United States of America  \n",
       "Job Description                  Key Role:\\rMaintain responsibility for the des...  \n",
       "Job Family                              Digital Creative Communications Consultant  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "jobs_df = load_csv()\n",
    "jobs_df.columns\n",
    "jobs_df.sample(4).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the Job Requisition field into its ID\n",
    "def f(x):\n",
    "    state = str(x)\n",
    "    comma_list = state.split(',')\n",
    "    if len(comma_list) > 1:\n",
    "        state = comma_list[1]\n",
    "        state = state.strip()\n",
    "    elif '8283 Greensboro Drive' in state:\n",
    "        state = 'DC'\n",
    "    else:\n",
    "        state = pd.NaN\n",
    "    \n",
    "    return state\n",
    "\n",
    "jobs_df['Job Requisition ID'] = jobs_df['Job Requisition'].map(lambda x: str(x).split(' ')[0])\n",
    "jobs_df['Job Posting'] = jobs_df['Job Requisition'].map(lambda x: ' '.join(str(x).split(' ')[1:]))\n",
    "#jobs_df['Primary Location State/Province'] = jobs_df['Location'].map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Science Intelligence Tradecraft Analyst (Open)', 'Data Scientist (Open)', 'Data Scientist, Junior (Open)', 'Data Scientist, Mid (Open)', 'Data Scientist/Intelligence Analyst (Open)', 'Deep Learning/Computer Vision Data Scientist (Open)', 'Graph Analytics Research Data Scientist (Open)', 'Intelligence Data Scientist (Open)', 'Machine Intelligence Data Scientist, Mid (Open)', 'Machine Learning/Data Scientist (Open)', 'Research Data Scientist (Open)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the Data Science job titles\n",
    "full_list = sorted(jobs_df['Job Posting'].unique().tolist())\n",
    "job_title_list = []\n",
    "for job_title in full_list:\n",
    "    if ('Senior' not in job_title) and ('.NET' not in job_title) and ('Chief' not in job_title) and ('Lead' not in job_title):\n",
    "        if ('Data' in job_title) and ('Scien' in job_title):\n",
    "            job_title_list.append(job_title)\n",
    "        elif ('Machine' in job_title) and ('Learning' in job_title):\n",
    "            job_title_list.append(job_title)\n",
    "print(job_title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TS/SCI',\n",
       " 'Secret',\n",
       " 'Eligibility Determination Timeline',\n",
       " 'Top Secret',\n",
       " 'None',\n",
       " 'Confidential',\n",
       " 'TS/SCI w/FSP',\n",
       " 'TS/SCI w/CIP']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the security clearances\n",
    "match_series = (jobs_df['Job Posting'].isin(job_title_list))\n",
    "good_jobs_df = jobs_df[match_series].copy()\n",
    "good_jobs_df['Required Clearance'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Missouri',\n",
       " 'Massachusetts',\n",
       " 'Virginia',\n",
       " 'Alabama',\n",
       " 'Texas',\n",
       " 'Maryland',\n",
       " 'Florida',\n",
       " 'New York',\n",
       " 'Baden-Wurttemberg',\n",
       " 'California',\n",
       " 'Nebraska']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get rid of the full scope poly jobs\n",
    "match_series = (good_jobs_df['Required Clearance'] == 'TS/SCI w/FSP')\n",
    "good_jobs_df = good_jobs_df[~match_series]\n",
    "good_jobs_df['Primary Location State/Province'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the jobs in states that we care about\n",
    "location_list = ['District of Columbia', 'Maryland', 'Massachusetts', 'New York', 'Virginia', 'Colorado', 'Arizona']\n",
    "#location_list = ['DC', 'MD', 'MA', 'VA']\n",
    "match_series = (good_jobs_df['Primary Location State/Province'].isin(location_list))\n",
    "column_list = ['Job Requisition ID', 'Job Posting', 'Management Level', 'Required Clearance', 'Clearance Agency',\n",
    "               'Job Requisition Type', 'Group', 'Account Group', 'IMT', 'Cluster', 'FSO', 'Resource Manager',\n",
    "               'Primary Recruiter', 'Hiring Manager', 'Primary Location', 'Primary Location State/Province',\n",
    "               'Job Description', 'Job Family']\n",
    "good_jobs_df = good_jobs_df[match_series][column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the jobs you haven't already applied for\n",
    "already_applied_for_list = load_object('already_applied_for_list')\n",
    "match_series = (good_jobs_df['Job Requisition ID'].isin(already_applied_for_list))\n",
    "good_jobs_df = good_jobs_df[~match_series]\n",
    "save_dataframes(good_jobs_df=good_jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Additional Qualification:',\n",
       " 'Additional Qualifications:',\n",
       " 'Basic Qualification:',\n",
       " 'Basic Qualifications:',\n",
       " 'Clearance:',\n",
       " 'Experience with at least one of the following:',\n",
       " 'Key Role:',\n",
       " 'Preferred Qualifications:'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the job description subheadings\n",
    "import re\n",
    "\n",
    "heading_regex = re.compile(r'([A-Z][A-za-z ]+:)')\n",
    "description_list = sorted(good_jobs_df['Job Description'].unique().tolist())\n",
    "set(heading_regex.findall(' '.join(description_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile all the subheading regexes\n",
    "paragraph_regex = re.compile(r'\\r *\\r')\n",
    "key_role_regex = re.compile(r'^(Key Role|The Challenge): *\\r')\n",
    "basic_qualifications_regex = re.compile(r'^(Basic Qualifications?|You Have): *\\r')\n",
    "additional_qualifications_regex = re.compile(r'^(Additional Qualifications?|Nice If You Have):? *\\r')\n",
    "clearance_regex = re.compile(r'^(Clearance): *\\r')\n",
    "preferred_qualifications_regex = re.compile(r'^(Preferred Qualifications): *\\r')\n",
    "relocation_regex = re.compile(r'^(Relocation): *\\r')\n",
    "perks_regex = re.compile(r'^(The Perks): *\\r')\n",
    "space_regex = re.compile(r' +')\n",
    "r_regex = re.compile(r'\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cleaning routines\n",
    "def clean(paragraph, regex):\n",
    "    paragraph = regex.sub('', paragraph)\n",
    "    paragraph = space_regex.sub(' ', paragraph)\n",
    "    paragraph = r_regex.sub('\\n', paragraph)\n",
    "    paragraph = paragraph.strip()\n",
    "    \n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create subheading features from the job description\n",
    "def f(row):\n",
    "    description_list = paragraph_regex.split(row['Job Description'])\n",
    "    last_attribute = 'No Idea'\n",
    "    for paragraph in description_list:\n",
    "        if key_role_regex.match(paragraph) is not None:\n",
    "            last_attribute = 'Key Role'\n",
    "            row[last_attribute] = clean(paragraph, key_role_regex)\n",
    "        elif basic_qualifications_regex.match(paragraph) is not None:\n",
    "            last_attribute = 'Basic Qualifications'\n",
    "            row[last_attribute] = clean(paragraph, basic_qualifications_regex)\n",
    "        elif additional_qualifications_regex.match(paragraph) is not None:\n",
    "            last_attribute = 'Additional Qualifications'\n",
    "            row[last_attribute] = clean(paragraph, additional_qualifications_regex)\n",
    "        elif clearance_regex.match(paragraph) is not None:\n",
    "            last_attribute = 'Clearance'\n",
    "            row[last_attribute] = clean(paragraph, clearance_regex)\n",
    "        elif preferred_qualifications_regex.match(paragraph) is not None:\n",
    "            last_attribute = 'Preferred Qualifications'\n",
    "            row[last_attribute] = clean(paragraph, preferred_qualifications_regex)\n",
    "        elif relocation_regex.match(paragraph) is not None:\n",
    "            last_attribute = 'Relocation'\n",
    "            row[last_attribute] = clean(paragraph, relocation_regex)\n",
    "        elif perks_regex.match(paragraph) is not None:\n",
    "            last_attribute = 'Perks'\n",
    "            row[last_attribute] = clean(paragraph, perks_regex)\n",
    "        else:\n",
    "            row[last_attribute] = row[last_attribute] + '\\n\\n' + paragraph\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the requiremnents list from the basic qualifications\n",
    "dash_regex = re.compile(r'[\\n_]â€‹?-')\n",
    "good_jobs_df = good_jobs_df.apply(f, axis=1)\n",
    "bq_series = good_jobs_df['Basic Qualifications'].map(lambda x: dash_regex.split('\\n' + str(x))[1:])\n",
    "max_reqs = bq_series.map(lambda x: len(x)).max()\n",
    "req_list = []\n",
    "for bq_list in bq_series.tolist():\n",
    "    for requirement in bq_list:\n",
    "        requirement = requirement.strip()\n",
    "        if requirement not in req_list:\n",
    "            req_list.append(requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the basic qualifications dataframe\n",
    "column_list = ['requisition_number'] + ['qualification_'+str(x).zfill(2) for x in range(1, max_reqs+1)]\n",
    "rows_list = []\n",
    "\n",
    "def f(row):\n",
    "    row_dict = {}\n",
    "    row_dict['requisition_number'] = row['Job Requisition ID']\n",
    "    quals_list = [x.strip() for x in dash_regex.split('\\n' + str(row['Basic Qualifications']))[1:]]\n",
    "    for x, qual in enumerate(quals_list):\n",
    "        row_dict['qualification_'+str(x).zfill(2)] = qual\n",
    "    rows_list.append(row_dict)\n",
    "    \n",
    "_ = good_jobs_df.apply(f, axis=1)\n",
    "basic_qualifications_df = pd.DataFrame(rows_list, columns=column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the qual ratings widget dataset\n",
    "column_list = ['req_number', 'qual_description']\n",
    "rows_list = []\n",
    "\n",
    "def f(row):\n",
    "    for qual in dash_regex.split('\\n' + str(row['Basic Qualifications']))[1:]:\n",
    "        row_dict = {}\n",
    "        row_dict['req_number'] = row['Job Requisition ID']\n",
    "        row_dict['qual_description'] = qual.strip()\n",
    "        rows_list.append(row_dict)\n",
    "    \n",
    "_ = good_jobs_df.apply(f, axis=1)\n",
    "bqs_df = pd.DataFrame(rows_list, columns=column_list)\n",
    "bqs_df['qual_rating'] = -1\n",
    "qual_description_dict = load_object('qual_description_dict')\n",
    "\n",
    "def f(row):\n",
    "    if row['qual_description'] in qual_description_dict.keys():\n",
    "        row['qual_rating'] = qual_description_dict[row['qual_description']]\n",
    "    \n",
    "    return row\n",
    "\n",
    "bqs_df = bqs_df.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the qual rating business logic for the interactive widget app\n",
    "def get_req(**kwargs):\n",
    "    if kwargs['rating_buttons'] is not None:\n",
    "        qual_rating = rating_options.index(kwargs['rating_buttons'])\n",
    "        index = int(kwargs['index'])\n",
    "        qual_description = kwargs['rating_text']\n",
    "        match_series = (bqs_df['qual_description'] == qual_description)\n",
    "        bqs_df.loc[match_series, 'qual_rating'] = qual_rating\n",
    "        qual_description_dict[qual_description] = qual_rating\n",
    "        store_objects(qual_description_dict=qual_description_dict)\n",
    "        \n",
    "        match_series = (bqs_df['qual_rating'] == -1)\n",
    "        display(bqs_df[match_series].shape)\n",
    "        df = bqs_df[match_series]\n",
    "        if df.shape[0] > 0:\n",
    "            row_series = df.sample(1)\n",
    "            req_number = row_series['req_number'].squeeze()\n",
    "            qual_description = row_series['qual_description'].squeeze()\n",
    "            hidden_label.value = str(row_series.index.max())\n",
    "            rating_text.value = qual_description\n",
    "            rating_text.description = req_number+':'\n",
    "            rating_buttons.value = None\n",
    "        else:\n",
    "            hidden_label.value = str(-1)\n",
    "            rating_text.value = 'Finished'\n",
    "            rating_text.description = 'XXXXXXXXX:'\n",
    "            rating_buttons.value = None\n",
    "    display(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prep the widget app for first use\n",
    "match_series = (bqs_df['qual_rating'] == -1)\n",
    "df = bqs_df[match_series]\n",
    "if df.shape[0] > 0:\n",
    "    row_series = df.sample(1)\n",
    "    req_number = row_series['req_number'].squeeze()\n",
    "    qual_description = row_series['qual_description'].squeeze()\n",
    "    row_index = row_series.index.max()\n",
    "else:\n",
    "    req_number = 'XXXXXXXXX'\n",
    "    qual_description = 'Finished'\n",
    "    row_index = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prep the widgets themselves for first use\n",
    "import ipywidgets\n",
    "from ipywidgets import HTML, RadioButtons, Label, Layout, interactive\n",
    "from IPython.display import display\n",
    "\n",
    "kwargs = {}\n",
    "kwargs['index'] = Label(value=str(row_index), layout=Layout(visibility='hidden'))\n",
    "kwargs['rating_text'] = HTML(\n",
    "    value=qual_description,\n",
    "    description=req_number+':'\n",
    "    )\n",
    "rating_options = ['Not at all', 'Very little', 'Neither', 'Very much', 'Completely']\n",
    "kwargs['rating_buttons'] = RadioButtons(\n",
    "    options=rating_options,\n",
    "    description='Applicability:',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltips=rating_options,\n",
    "    value=None\n",
    "    )\n",
    "ip = interactive(get_req, {'manual': True}, **kwargs)\n",
    "for i, widget in enumerate(ip.children):\n",
    "    if type(widget) == ipywidgets.widgets.widget_selection.RadioButtons:\n",
    "        rating_buttons = ip.children[i]\n",
    "    elif type(widget) == ipywidgets.widgets.widget_string.HTML:\n",
    "        rating_text = ip.children[i]\n",
    "    elif type(widget) == ipywidgets.widgets.widget_string.Label:\n",
    "        hidden_label = ip.children[i]\n",
    "    elif type(widget) == ipywidgets.widgets.widget_button.Button:\n",
    "        submit_button = ip.children[i]\n",
    "        submit_button.description = 'Submit'\n",
    "    elif type(widget) == ipywidgets.widgets.widget_output.Output:\n",
    "        out = ip.children[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352f5c849c3941b1a4d7a3cbdd1e45d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value='Finished', description='XXXXXXXXX:'), HBox(children=(RadioButtons(description='Applicability:', options=('Not at all', 'Very little', 'Neither', 'Very much', 'Completely'), value=None), Button(description='Submit', style=ButtonStyle()))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Display the app\n",
    "from ipywidgets import VBox, HBox\n",
    "\n",
    "display(VBox([rating_text, HBox([rating_buttons, submit_button]), out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Job Requisition ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Key Role</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Basic Qualifications</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Additional Qualifications</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Required Clearance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary Location State/Province</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Family</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Job Requisition ID, Job Posting, Key Role, Basic Qualifications, Additional Qualifications, Clearance, Required Clearance, Primary Location, Primary Location State/Province, Job Family]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Display jobs you are qualified for\n",
    "bqs_group = bqs_df.groupby('req_number')\n",
    "bqs_group_means_df = bqs_group.mean()\n",
    "match_series = (bqs_group_means_df['qual_rating'] >= 3.75)\n",
    "req_number_list = bqs_group_means_df[match_series].sort_values('qual_rating', ascending=False).index.tolist()\n",
    "match_series = good_jobs_df['Job Requisition ID'].isin(req_number_list)\n",
    "\n",
    "\n",
    "# Get rid of useless columns\n",
    "column_list = ['Job Requisition ID', 'Job Posting', 'Key Role', 'Basic Qualifications', 'Additional Qualifications',\n",
    "               'Clearance', 'Required Clearance', 'Primary Location', 'Primary Location State/Province', 'Job Family']\n",
    "best_jobs_df = good_jobs_df[match_series][column_list].T.dropna()\n",
    "save_dataframes(include_index=True, best_jobs_df=best_jobs_df)\n",
    "best_jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['R0004444', 'R0013123', 'R0006735', 'R0017065', 'R0017064', 'R0011910', 'R0018879']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "\n",
    "# Add req numbers (after the process) to your already-applied list\n",
    "already_applied_for_list = list(set(['R0004444', 'R0013123', 'R0011910', 'R0006735', 'R0018879', 'R0017065', 'R0017064', 'R0004444']) | set(already_applied_for_list))\n",
    "store_objects(already_applied_for_list=already_applied_for_list)\n",
    "already_applied_for_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Admin Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_jobs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_list = ['Job Requisition ID', 'Job Posting', 'Key Role', 'Basic Qualifications', 'Additional Qualifications',\n",
    "               'Clearance', 'Required Clearance', 'Primary Location State/Province', 'Job Family']\n",
    "#good_jobs_df = load_csv('good_jobs_df')\n",
    "good_jobs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (good_jobs_df['Job Requisition ID'] == 'R0012921')\n",
    "good_jobs_df[match_series].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_series = (bqs_df['req_number'] == 'R0012921')\n",
    "bqs_df[match_series]['qual_description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_list = ['req_number', 'qual_description']\n",
    "rows_list = []\n",
    "\n",
    "def f(row):\n",
    "    for qual in dash_regex.split('\\n' + str(row['Additional Qualifications']))[1:]:\n",
    "        row_dict = {}\n",
    "        row_dict['req_number'] = row['Job Requisition ID']\n",
    "        row_dict['qual_description'] = qual.strip()\n",
    "        rows_list.append(row_dict)\n",
    "    \n",
    "_ = good_jobs_df.apply(f, axis=1)\n",
    "aqs_df = pd.DataFrame(rows_list, columns=column_list)\n",
    "match_series = (aqs_df['req_number'] == 'R0012921')\n",
    "aqs_df[match_series]['qual_description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#best_jobs_df = load_csv('best_jobs_df')\n",
    "best_req_list = best_jobs_df.columns.tolist()[1:]\n",
    "match_series = (jobs_df['Job Requisition ID'].isin(best_req_list))\n",
    "column_list = ['Job Requisition ID', 'Job Posting', 'Resource Manager', 'Primary Recruiter', 'Hiring Manager', \n",
    "               'Primary Location State/Province']\n",
    "lack_of_work_df = jobs_df[match_series][column_list].sort_values('Resource Manager')\n",
    "save_dataframes(lack_of_work_df=lack_of_work_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lack_of_work_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
