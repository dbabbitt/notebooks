{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Attack Type using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The goal of this analysis is to explore some machine learning tools on a single practical task: analyzing five collections of 500,000 conflict-related events on nine different attack types. In this notebook we will:\n",
    "\n",
    "* load the spreadsheet contents and the categories\n",
    "\n",
    "* extract feature vectors suitable for machine learning\n",
    "\n",
    "* train a few models to perform categorization\n",
    "\n",
    "* use a grid search strategy to find a good configuration of both the feature extraction components and the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load the spreadsheet contents and the categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One of the datasets, GTDB, contains numerous Attack Type columns that can serve as a way of labeling each record. Here I convert the spreadsheet into its own DataFrame in order to visualize a few of its many columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eventid', 'iyear', 'imonth', 'iday', 'approxdate', 'extended',\n",
       "       'resolution', 'country', 'country_txt', 'region',\n",
       "       ...\n",
       "       'addnotes', 'scite1', 'scite2', 'scite3', 'dbsource', 'INT_LOG',\n",
       "       'INT_IDEO', 'INT_MISC', 'INT_ANY', 'related'],\n",
       "      dtype='object', length=137)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "gtdb_path = \"../data/csv/GTDB\"\n",
    "csv_path =  gtdb_path + '.csv'\n",
    "encoding = ['latin1', 'iso8859-1', 'utf-8'][1]\n",
    "gtdb_df = pd.read_csv(csv_path, encoding=encoding, low_memory=False)\n",
    "gtdb_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The columns that might give away the category (the dependent variables) all have the word \"attack\" in them, so I separate them out here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attacktype1',\n",
       " 'attacktype1_txt',\n",
       " 'attacktype2',\n",
       " 'attacktype2_txt',\n",
       " 'attacktype3',\n",
       " 'attacktype3_txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "attack_regex = re.compile(r\"attack\")\n",
    "attack_column_list = [column for column in gtdb_df.columns for m in [attack_regex.search(column)] if m]\n",
    "attack_column_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It looks like the attacktype1_txt column is the one we need to index on. Here is all the different values contained in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Assassination', 'Hostage Taking (Kidnapping)', 'Bombing/Explosion',\n",
       "       'Facility/Infrastructure Attack', 'Armed Assault', 'Hijacking',\n",
       "       'Unknown', 'Unarmed Assault', 'Hostage Taking (Barricade Incident)'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gtdb_df['attacktype1_txt'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "We need to decide what order to place them in for indexing. So, our categories are summarized in their own spreadsheet. Here I convert it to a DataFrame for easy visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack Type Id</th>\n",
       "      <th>Attack Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Assassination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Armed Assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bombing/Explosion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hijacking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hostage Taking (Barricade Incident)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Hostage Taking (Kidnapping)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Facility/Infrastructure Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Unarmed Assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attack Type Id                          Attack Type\n",
       "0               1                        Assassination\n",
       "1               2                        Armed Assault\n",
       "2               3                    Bombing/Explosion\n",
       "3               4                            Hijacking\n",
       "4               5  Hostage Taking (Barricade Incident)\n",
       "5               6          Hostage Taking (Kidnapping)\n",
       "6               7       Facility/Infrastructure Attack\n",
       "7               8                      Unarmed Assault\n",
       "8               9                              Unknown"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "attack_types_path = \"../data/csv/AttackTypes\"\n",
    "csv_path =  attack_types_path + '.csv'\n",
    "attack_types_df = pd.read_csv(csv_path, encoding=encoding, low_memory=False)\n",
    "attack_types_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The problem is all the rest of the datasets don't have anything like an _Attack Type_ column. Here I convert each spreadsheet into its own DataFrame and display the columns in each to show the difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'relid', 'year', 'active_year', 'type_of_violence',\n",
       "       'conflict_dset_id', 'conflict_new_id', 'conflict_name', 'dyad_dset_id',\n",
       "       'dyad_new_id', 'dyad_name', 'side_a_dset_id', 'side_a_new_id', 'side_a',\n",
       "       'side_b_dset_id', 'side_b_new_id', 'side_b', 'number_of_sources',\n",
       "       'source_article', 'source_office', 'source_date', 'source_headline',\n",
       "       'source_original', 'where_prec', 'where_coordinates',\n",
       "       'where_description', 'adm_1', 'adm_2', 'latitude', 'longitude',\n",
       "       'geom_wkt', 'priogrid_gid', 'country', 'region', 'event_clarity',\n",
       "       'date_prec', 'date_start', 'date_end', 'deaths_a', 'deaths_b',\n",
       "       'deaths_civilians', 'deaths_unknown', 'best_est', 'high_est', 'low_est',\n",
       "       'isocc', 'gwno', 'gwab'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ucdp_path = \"../data/csv/UCDP\"\n",
    "csv_path =  ucdp_path + '.csv'\n",
    "ucdp_df = pd.read_csv(csv_path, encoding=encoding, low_memory=False)\n",
    "ucdp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eventid', 'id', 'ccode', 'countryname', 'startdate', 'enddate',\n",
       "       'duration', 'stday', 'stmo', 'styr', 'eday', 'emo', 'eyr', 'etype',\n",
       "       'escalation', 'actor1', 'actor2', 'actor3', 'target1', 'target2',\n",
       "       'cgovtarget', 'rgovtarget', 'npart', 'ndeath', 'repress', 'elocal',\n",
       "       'ilocal', 'sublocal', 'locnum', 'gislocnum', 'issue1', 'issue2',\n",
       "       'issue3', 'issuenote', 'nsource', 'notes', 'coder', 'acd_questionable',\n",
       "       'latitude', 'longitude', 'geo_comments', 'location_precision'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scad_path = \"../data/csv/SCAD\"\n",
    "csv_path =  scad_path + '.csv'\n",
    "scad_df = pd.read_csv(csv_path, encoding=encoding, low_memory=False)\n",
    "scad_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['startdate', 'city', 'country', 'perpetrator', 'weapon', 'injuries',\n",
       "       'fatalities', 'description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rand_path = \"../data/csv/RAND\"\n",
    "csv_path =  rand_path + '.csv'\n",
    "rand_df = pd.read_csv(csv_path, encoding=encoding, low_memory=False)\n",
    "rand_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GWNO', 'EVENT_ID_CNTY', 'EVENT_ID_NO_CNTY', 'EVENT_DATE', 'YEAR',\n",
       "       'TIME_PRECISION', 'EVENT_TYPE', 'ACTOR1', 'ALLY_ACTOR_1', 'INTER1',\n",
       "       'ACTOR1_ID', 'ACTOR2', 'ALLY_ACTOR_2', 'INTER2', 'ACTOR2_ID',\n",
       "       'INTERACTION', 'ACTOR_DYAD_ID', 'COUNTRY', 'ADMIN1', 'ADMIN2', 'ADMIN3',\n",
       "       'LOCATION', 'LATITUDE', 'LONGITUDE', 'GEO_PRECISION', 'SOURCE', 'NOTES',\n",
       "       'FATALITIES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "acled_path = \"../data/csv/ACLED\"\n",
    "csv_path =  acled_path + '.csv'\n",
    "acled_df = pd.read_csv(csv_path, encoding=encoding, low_memory=False)\n",
    "acled_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Get the training data into a bunch suitable for extracting feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors. But most of the columns in the datasets contain numbers that can't easily be used for categorization. Our solution was to concatonate all the textual descriptions into one sentence for each row, then extract feature vectors from that sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def concat_independendent_variables(df):\n",
    "    X = pd.Series([])\n",
    "    for row_index, row_series in df.iterrows():\n",
    "        row_concat = row_series.astype('str').str.cat(sep=' ').strip()\n",
    "        row_concat = sq_regex.sub(r'', row_concat)\n",
    "        row_concat = nonalpha_regex.sub(r' ', row_concat)\n",
    "        X = X.append(pd.Series([row_concat]), ignore_index=True)\n",
    "    \n",
    "    return X\n",
    "\n",
    "nonalpha_regex = re.compile(r\"[^a-zA-Z]+\")\n",
    "sq_regex = re.compile(r\"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here we are only ingesting the rows that have been previously labeled to create the training set. The analyst has manually labeled of few of each spreadsheet for greater accuracy. This takes a long time, so we report to ourselves how long (in seconds) it took the last time we ran it, to estimate how long the coffee break should last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413.7951662540436 Mon Jul  3 13:36:02 2017\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "X = pd.Series([])\n",
    "y = pd.Series([])\n",
    "for csv_file in ['acled', 'rand', 'scad', 'ucdp', 'GTDB']:\n",
    "    if csv_file == \"GTDB\":\n",
    "        gtdb_path = \"../data/csv/GTDB\"\n",
    "        csv_path =  gtdb_path + '.csv'\n",
    "    else:\n",
    "        relabeled_path = \"../data/csv/mike_\"\n",
    "        csv_path =  relabeled_path + csv_file + '.csv'\n",
    "    df = pd.read_csv(csv_path, encoding=encoding, low_memory=False)\n",
    "    df.fillna(value=\"\", inplace=True)\n",
    "    if csv_file == \"GTDB\":\n",
    "        important_columns = [column for column in df.columns if (column not in attack_column_list)]\n",
    "    else:\n",
    "        important_columns = df.columns.tolist()[:-1]\n",
    "    X = X.append(concat_independendent_variables(df[important_columns]), ignore_index=True)\n",
    "    if csv_file == \"GTDB\":\n",
    "        y = y.append(df['attacktype1'].map(lambda x: int(x)-1), ignore_index=True)\n",
    "    else:\n",
    "        y = y.append(df[df.columns.tolist()[-1]].map(lambda x: attack_types_df['Attack Type'].tolist().index(x)), \n",
    "                     ignore_index=True)\n",
    "t1 = time.time()\n",
    "print(t1-t0, time.ctime(t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Here we break up the X and y into a training and testing sets for ease of use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "class Bunch(dict):\n",
    "    \"\"\"Container object for datasets: dictionary-like object that\n",
    "       exposes its keys as attributes.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        dict.__init__(self, kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=0)\n",
    "csv_path = \"../data/csv/\"\n",
    "csv_files = [join(csv_path, f) for f in listdir(csv_path) if isfile(join(csv_path, f))]\n",
    "gtdb_train = Bunch(filenames=np.asarray(csv_files),\n",
    "                   target_names=attack_types_df['Attack Type'].tolist(),\n",
    "                   DESCR=None,\n",
    "                   target=np.asarray(y_train.tolist()),\n",
    "                   data=X_train.tolist(),\n",
    "                   description=\"The GTDB dataset concatoned into one column (minus the target columns)\")\n",
    "gtdb_test = Bunch(filenames=np.asarray(csv_files),\n",
    "                   target_names=attack_types_df['Attack Type'].tolist(),\n",
    "                   DESCR=None,\n",
    "                   target=np.asarray(y_test.tolist()),\n",
    "                   data=X_test.tolist(),\n",
    "                   description=\"The GTDB dataset concatoned into one column (minus the target columns)\")\n",
    "gtdb_all = Bunch(filenames=np.asarray(csv_files),\n",
    "                   target_names=attack_types_df['Attack Type'].tolist(),\n",
    "                   DESCR=None,\n",
    "                   target=np.asarray(y.tolist()),\n",
    "                   data=X.tolist(),\n",
    "                   description=\"The GTDB dataset concatoned into one column (minus the target columns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So, the training data looks like a bunch of words all strung together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Peru South America Ayacucho Ayacucho district Police Police Building headquarters station school Police post Peru Shining Path SL Unknown Attacked Unknown PGIS ',\n",
       " ' Afghanistan South Asia Herat Shaydai Assailants opened fire on Afghan National Army ANA soldiers in Shaydai area Herat province Afghanistan Two soldiers were killed in the attack The Taliban claimed responsibility for the incident Insurgency Guerilla Action Military Military Personnel soldiers troops officers forces Afghan National Army ANA Officers Afghanistan Taliban Posted to website blog etc Firearms Unknown Gun Type Unknown Gunmen Kills Afghan Soldiers in Herat Tolo News July Afghanistan Afghan army officers martyred in gunmen attack in Herat Khaama Press July Mine blast kills Afghan two soldiers Afghan Islamic Press July START Primary Collection ',\n",
       " ' Philippines Southeast Asia Metropolitian Manila Manila Business Hotel Resort Manila Garden Hotel Philippines Unknown Incendiary Incendiary defused PGIS ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gtdb_train.data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Each row of which is labeled with an attack type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown\n",
      "Armed Assault\n",
      "Facility/Infrastructure Attack\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in gtdb_train.target[:3]:\n",
    "    print(gtdb_train.target_names[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Extract feature vectors suitable for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now have our data in a form where we can extract feature vectors suitable for machine learning. The most intuitive way to do so is the **bags of words** representation:\n",
    "\n",
    "1. assign a fixed integer id to each word occurring in any row of the training set (for instance by building a dictionary from words to integer indices).\n",
    "\n",
    "2. for each row #`i`, count the number of occurrences of each word `w` and store it in `X[i, j]` as the value of feature `#j` where `j` is the index of word w in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.046195268630981 Mon Jul  3 14:41:27 2017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(105501, 97921)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "t0 = time.time()\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(gtdb_train.data)\n",
    "t1 = time.time()\n",
    "print(t1-t0, time.ctime(t1))\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So now we have a dictionary of feature indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7241"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count_vect.vocabulary_.get(u'ayacucho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Occurrence count is a good start but there is an issue: rows with more words in them will have higher average count values than shorter rows, even though they might talk about the same topics.\n",
    "\n",
    "To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a row by the total number of words in the row: these new features are called `tf` for Term Frequencies.\n",
    "\n",
    "Another refinement on top of `tf` is to downscale weights for words that occur in many rows in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus.\n",
    "\n",
    "This downscaling is called `tf–idf` for “Term Frequency times Inverse Document Frequency”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105501, 97921)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Train a few models to perform categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we have our features, we can train a classifier to try to predict the category of a post. Let’s start with a **naïve Bayes** classifier, which provides a nice baseline for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' India South Asia Jharkhand Siladon Assailants set construction equipment on fire in Siladon area Jharkhand state India There were no reported casualties however construction equipment was damaged in the attack No group claimed responsibility for the incident however sources attributed the attack to the Peoples Liberation Front of India Business Construction Unknown Construction Equipment India Peoples Liberation Front of India The specific motive is unknown however sources posited that the attack was part of a bandh by the Peoples Liberation Front of India in demonstration against the death of two civilians Incendiary Arson Fire Minor likely million Three construction machines and a vehicle were damaged in this attack LWE outfit torch four vehicles in Jharkhands Khunti Hindustan Times September PLFI militants torch five machines and a car ahead of bandh in Jharkhand ZeeNews com September START Primary Collection ' => Bombing/Explosion\n",
      "' Sri Lanka South Asia Eastern Sardhapura Insurgency Guerilla Action Military Military Unit Patrol Convoy Military Unit Sri Lanka Liberation Tigers of Tamil Eelam LTTE Firearms Automatic Weapon Automatic firearm PGIS ' => Armed Assault\n",
      "' Russia Eastern Europe Dagestan Buynaksk Four gunmen opened fire on a police checkpoint in Buynaksk town Dagestan republic Russia All four assailants were killed by retaliatory fire No group claimed responsibility for the incident Police Police Checkpoint Russian Police Checkpoint Russia Unknown Firearms Unknown Gun Type gunmen killed in insurgency hit southern Russia United News of Bangladesh Limited October START Primary Collection ' => Armed Assault\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, gtdb_train.target)\n",
    "\n",
    "docs_new = gtdb_test.data[:3]\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, gtdb_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to make the vectorizer => transformer => classifier easier to work with, we will use the Pipeline class that behaves like a compound classifier, and evaluate the predictive accuracy of the naïve Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66205449926872451"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "text_clf = text_clf.fit(gtdb_train.data, gtdb_train.target)\n",
    "predicted = text_clf.predict(gtdb_test.data)\n",
    "np.mean(predicted == gtdb_test.target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I.e., we achieved 66.2% accuracy. Let’s see if we can do better with a linear **support vector machine** (SVM), which is widely regarded as one of the best text classification algorithms (although it’s also a bit slower than naïve Bayes). We can change the learner by just plugging a different classifier object into our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.02935862541199 Mon Jul  3 15:25:36 2017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85836348241089988"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "t0 = time.time()\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', SGDClassifier(loss='modified_huber', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)),\n",
    "])\n",
    "text_clf = text_clf.fit(gtdb_train.data, gtdb_train.target)\n",
    "predicted = text_clf.predict(gtdb_test.data)\n",
    "t1 = time.time()\n",
    "print(t1-t0, time.ctime(t1))\n",
    "np.mean(predicted == gtdb_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "An accuracy of 85.8% is a much better choice. Here is a more detailed performance analysis of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                      Assassination       0.74      0.48      0.58      5798\n",
      "                      Armed Assault       0.76      0.89      0.82     12345\n",
      "                  Bombing/Explosion       0.94      0.99      0.96     25217\n",
      "                          Hijacking       0.96      0.14      0.24       187\n",
      "Hostage Taking (Barricade Incident)       0.50      0.01      0.01       273\n",
      "        Hostage Taking (Kidnapping)       0.87      0.74      0.80      3035\n",
      "     Facility/Infrastructure Attack       0.82      0.80      0.81      2905\n",
      "                    Unarmed Assault       0.82      0.32      0.47       370\n",
      "                            Unknown       0.70      0.63      0.66      1834\n",
      "\n",
      "                        avg / total       0.85      0.86      0.85     51964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(gtdb_test.target, predicted, target_names=gtdb_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notice that the categories of _Hijacking_ and _Hostage Taking (Barricade Incident)_ have very low **support**. This means that there is not much for the model to train on. They also have low **recall**, meaning that they didn't include many rows that were actually labeled with the category as being in the category. And it looks like only half the rows the model predicted to be _Hostage Taking (Barricade Incident)_ were actually that - hence the low **precision**.\n",
    "\n",
    "We can see this replicated in the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2788,  1781,   932,     0,     0,    57,    38,     1,   201],\n",
       "       [  544, 11025,   368,     0,     2,    74,   310,     5,    17],\n",
       "       [   18,    97, 24952,     0,     0,     5,    53,     3,    89],\n",
       "       [    5,    55,    38,    26,     0,    40,    10,     0,    13],\n",
       "       [   21,   105,    56,     0,     2,    47,    14,     0,    28],\n",
       "       [  213,   457,    45,     1,     0,  2231,    30,     1,    57],\n",
       "       [   15,   405,    81,     0,     0,    17,  2311,    13,    63],\n",
       "       [   42,    82,    57,     0,     0,    31,    23,   120,    15],\n",
       "       [   99,   451,    50,     0,     0,    60,    22,     3,  1149]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics.confusion_matrix(gtdb_test.target, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the diagonal running from the top left to the bottom right, we can see that the _Hostage Taking (Barricade Incident)_ category was only predicted correctly twice, while the _Hijacking_ category was only predicted correctly 26 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### Use a grid search strategy to find a good configuration of both the feature extraction components and the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Instead of tweaking the parameters of the various components of the chain, it is possible to run an exhaustive search of the best parameters on a grid of possible values. We try out all classifiers on either words or bigrams or trigrams, with or without idf, with a penalty parameter of either 0.01 or 0.001 or 0.0001, and a log or modified huber loss function for the linear SVM. As you can see, the best score from this search is 75.3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955.3238289356232 Mon Jul  3 16:25:54 2017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7536404915378021"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3, 1e-4),\n",
    "              'clf__loss': ('log', 'modified_huber'),\n",
    "}\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(penalty='l2', n_iter=5, random_state=42)),\n",
    "])\n",
    "gs_all_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_all_clf = gs_all_clf.fit(gtdb_all.data, gtdb_all.target)\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1-t0, time.ctime(t1))\n",
    "\n",
    "# 0.7536404915378021\n",
    "gs_all_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The comparitive accuracy is 89.7% - much better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8498926162719727 Mon Jul  3 17:34:29 2017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89656300515741671"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "predicted = gs_all_clf.predict(gtdb_test.data)\n",
    "t1 = time.time()\n",
    "print(t1-t0, time.ctime(t1))\n",
    "np.mean(predicted == gtdb_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Add a \"predicted\" column to all the datasets and save them as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1283.0713064670563 Mon Jul  3 17:56:17 2017\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for df in [acled_df, rand_df, scad_df, ucdp_df, gtdb_df]:\n",
    "    data = concat_independendent_variables(df).tolist()\n",
    "    df['predicted_id'] = gs_all_clf.predict(data)\n",
    "    df['predicted_type'] = df['predicted_id'].map(lambda x: gtdb_all.target_names[x])\n",
    "    df['probabilities'] = pd.Series(list(gs_all_clf.predict_proba(data)))\n",
    "    df['probability'] = df.apply(lambda row: \"{0:.1f}%\".format(row['probabilities'][row['predicted_id']]*100), axis=1)\n",
    "    df.drop(['predicted_id','probabilities'], axis=1, inplace=True)\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1-t0, time.ctime(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "csv_folder = \"../data/csv/\"\n",
    "gtdb_df.to_csv(csv_folder+\"gtdb_df.csv\", sep=',', encoding=encoding, index=False)\n",
    "acled_df.to_csv(csv_folder+\"acled_df.csv\", sep=',', encoding=encoding, index=False)\n",
    "rand_df.to_csv(csv_folder+\"rand_df.csv\", sep=',', encoding=encoding, index=False)\n",
    "scad_df.to_csv(csv_folder+\"scad_df.csv\", sep=',', encoding=encoding, index=False)\n",
    "ucdp_df.to_csv(csv_folder+\"ucdp_df.csv\", sep=',', encoding=encoding, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
