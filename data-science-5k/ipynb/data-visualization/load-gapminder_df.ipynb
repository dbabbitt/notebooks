{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Handy list of the different types of encodings\n",
    "encoding = ['latin1', 'iso8859-1', 'utf-8'][1]\n",
    "\n",
    "# Change this to your data and saves folders\n",
    "data_folder = r'../../data/'\n",
    "saves_folder = r'../../saves/'\n",
    "\n",
    "def load_object(obj_name, download_url=None):\n",
    "    pickle_path = saves_folder + 'pickle/' + obj_name + '.pickle'\n",
    "    if not os.path.isfile(pickle_path):\n",
    "        csv_path = saves_folder + 'csv/' + obj_name + '.csv'\n",
    "        if not os.path.isfile(csv_path):\n",
    "            object = pd.read_csv(download_url, low_memory=False,\n",
    "                                 encoding=encoding)\n",
    "        else:\n",
    "            object = pd.read_csv(csv_path, low_memory=False,\n",
    "                                 encoding=encoding)\n",
    "        try:\n",
    "            if isinstance(object, pd.DataFrame):\n",
    "                object.to_pickle(pickle_path)\n",
    "            else:\n",
    "                with open(pickle_path, 'wb') as handle:\n",
    "                    pickle.dump(object, handle, pickle.HIGHEST_PROTOCOL)\n",
    "        except:\n",
    "            with open(pickle_path, 'wb') as handle:\n",
    "                pickle.dump(object, handle, pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        try:\n",
    "            object = pd.read_pickle(pickle_path)\n",
    "        except:\n",
    "            with open(pickle_path, 'rb') as handle:\n",
    "                object = pickle.load(handle)\n",
    "    \n",
    "    return(object)\n",
    "\n",
    "# Classes, functions, and methods cannot be pickled\n",
    "def store_objects(**kwargs):\n",
    "    for obj_name in kwargs:\n",
    "        if hasattr(kwargs[obj_name], '__call__'):\n",
    "            raise RuntimeError('Functions cannot be pickled.')\n",
    "        obj_path = saves_folder + 'pickle/' + str(obj_name)\n",
    "        pickle_path = obj_path + '.pickle'\n",
    "        if isinstance(kwargs[obj_name], pd.DataFrame):\n",
    "            kwargs[obj_name].to_pickle(pickle_path)\n",
    "        else:\n",
    "            with open(pickle_path, 'wb') as handle:\n",
    "                pickle.dump(kwargs[obj_name], handle, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "download_url = 'https://raw.githubusercontent.com/jdantonio/ratistics/master/examples/gapminder.csv'\n",
    "gapminder_df = load_object('gapminder_df', download_url=download_url)\n",
    "gapminder_df.columns = ['country_name', 'income_per_person',\n",
    "                        'alcohol_consumption', 'armed_forces_rate',\n",
    "                        'breast_cancer_per_100th', 'co2_emissions',\n",
    "                        'female_employment_rate', 'hiv_rate',\n",
    "                        'internet_use_rate', 'life_expectancy',\n",
    "                        'oil_per_person', 'polity_score',\n",
    "                        'residential_electricity_per_person',\n",
    "                        'suicide_per_100th', 'employment_rate',\n",
    "                        'urban_rate']\n",
    "number_column_list = list(set(gapminder_df.columns) - set(['country_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_path = saves_folder + 'pickle/formal_name_dict.pickle'\n",
    "if not os.path.isfile(obj_path):\n",
    "    formal_name_dict = {}\n",
    "    formal_name_dict['alcohol_consumption'] = '2008 alcohol consumption per adult (age 15+) in litres'\n",
    "    formal_name_dict['armed_forces_rate'] = 'Armed forces personnel as a % of total labor force'\n",
    "    formal_name_dict['breast_cancer_per_100th'] = '2002 breast cancer new cases per hundred thousand females'\n",
    "    formal_name_dict['co2_emissions'] = '2006 cumulative CO2 emission in metric tons'\n",
    "    formal_name_dict['employment_rate'] = '2007 total employees age 15+ as a % of population'\n",
    "    formal_name_dict['female_employment_rate'] = '2007 female employees age 15+ as a % of population'\n",
    "    formal_name_dict['hiv_rate'] = '2009 estimated HIV Prevalence % for Ages 15-49'\n",
    "    formal_name_dict['income_per_person'] = '2010 Gross Domestic Product per capita in constant 2000 USD'\n",
    "    formal_name_dict['internet_use_rate'] = '2010 Internet users per 100 people'\n",
    "    formal_name_dict['life_expectancy'] = '2011 life expectancy at birth in years'\n",
    "    formal_name_dict['oil_per_person'] = '2010 oil Consumption per capita in tonnes per year and person'\n",
    "    formal_name_dict['polity_score'] = '2009 Democracy score as measured by Polity'\n",
    "    formal_name_dict['residential_electricity_per_person'] = '2008 residential electricity consumption per person in kWh'\n",
    "    formal_name_dict['suicide_per_100th'] = '2005 Suicide age adjusted per hundred thousand'\n",
    "    formal_name_dict['urban_rate'] = '2008 urban population as a % of total'\n",
    "    store_objects(formal_name_dict=formal_name_dict)\n",
    "else:\n",
    "    formal_name_dict = load_object('formal_name_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_path = saves_folder + 'pickle/informal_name_dict.pickle'\n",
    "if not os.path.isfile(obj_path):\n",
    "    informal_name_dict = {}\n",
    "    informal_name_dict['alcohol_consumption'] = 'alcohol consumption'\n",
    "    informal_name_dict['armed_forces_rate'] = 'armed forces rate'\n",
    "    informal_name_dict['breast_cancer_per_100th'] = 'breast cancer'\n",
    "    informal_name_dict['co2_emissions'] = 'CO2 emissions'\n",
    "    informal_name_dict['employment_rate'] = 'employment rate'\n",
    "    informal_name_dict['female_employment_rate'] = 'female employment rate'\n",
    "    informal_name_dict['hiv_rate'] = 'HIV rate'\n",
    "    informal_name_dict['income_per_person'] = 'income per person'\n",
    "    informal_name_dict['internet_use_rate'] = 'internet use rate'\n",
    "    informal_name_dict['life_expectancy'] = 'life expectancy'\n",
    "    informal_name_dict['oil_per_person'] = 'oil per person'\n",
    "    informal_name_dict['polity_score'] = 'polity score'\n",
    "    informal_name_dict['residential_electricity_per_person'] = 'residential electricity'\n",
    "    informal_name_dict['suicide_per_100th'] = 'suicide rate'\n",
    "    informal_name_dict['urban_rate'] = 'urban rate'\n",
    "    store_objects(informal_name_dict=informal_name_dict)\n",
    "else:\n",
    "    informal_name_dict = load_object('informal_name_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_binned_categories(df, number_of_categories, column_name, prefix):\n",
    "    \n",
    "    # Get the percentiles\n",
    "    out_categorical, percentiles_list = pd.cut([0, 1], number_of_categories, retbins=True)\n",
    "    describe_series = df[column_name].describe(percentiles=percentiles_list[1:-1]).copy()\n",
    "\n",
    "    # Get the bin list and group names\n",
    "    bad_list = ['count', 'mean', 'std']\n",
    "    if (number_of_categories % 2) == 1:\n",
    "        bad_list += ['50%']\n",
    "    \n",
    "    # array of indexes, e.g. ['min', '50%', 'max']\n",
    "    index_list = [x for x in describe_series.index.tolist() if x not in bad_list]\n",
    "    bin_list = describe_series.loc[index_list].tolist()\n",
    "    if len(set(bin_list)) == len(bin_list):\n",
    "        \n",
    "        # Create the extra column\n",
    "        df[prefix+'_categories'] = pd.cut(x=df[column_name],\n",
    "                                          bins=bin_list).map(lambda x: (x.left + x.right)/2.)\n",
    "    else:\n",
    "\n",
    "        # array of quantiles, e.g. [0, .25, .5, .75, 1.]\n",
    "        quantiles_list = []\n",
    "        for index in index_list:\n",
    "            if index == 'min':\n",
    "                quantiles_list.append(0)\n",
    "            elif index == 'max':\n",
    "                quantiles_list.append(1.)\n",
    "            else:\n",
    "                quantiles_list.append(float(index.split('%')[0])/100.)\n",
    "        \n",
    "        # Create the extra column\n",
    "        df[prefix+'_categories'] = pd.qcut(x=df[column_name], q=quantiles_list,\n",
    "                                           duplicates='drop').map(lambda x: (x.left + x.right)/2.)\n",
    "\n",
    "    # Fix the bottom row\n",
    "    null_series = df[prefix+'_categories'].isnull()\n",
    "    df.loc[null_series, prefix+'_categories'] = df[~null_series][prefix+'_categories'].min()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import squareform, pdist, euclidean\n",
    "import numpy as np\n",
    "\n",
    "# From https://stackoverflow.com/questions/2827393/angles-between-two-n-dimensional-vectors-in-python\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "def round_down(num, divisor):\n",
    "    \n",
    "    return num - (num%divisor)\n",
    "\n",
    "def round_up(num, divisor):\n",
    "    \n",
    "    return num - (num%divisor) + divisor\n",
    "\n",
    "def get_min_max(df, column_name, circle_min=5, circle_max=500):\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(circle_min, circle_max))\n",
    "    min_max = min_max_scaler.fit_transform(df[column_name].values.reshape(-1, 1))\n",
    "    \n",
    "    return min_max\n",
    "\n",
    "def conjunctify_list(noun_list):\n",
    "    \n",
    "    return ', and '.join([', '.join(noun_list[:-1])] + [noun_list[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
