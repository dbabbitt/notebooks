{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Peer-graded Assignment: Test a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"rc-AssignmentInstructions\"><div class=\"introduction\"><div class=\"rc-CML styled\"><div><p> This week's assignment is to test a logistic regression model. </p><p><strong>Data preparation for this assignment:</strong></p><p>1) If your response variable is categorical with more than two categories, you will need to collapse it down to two categories, or subset your data to select observations from 2 categories.</p><p>2) If your response variable is quantitative, you will need to bin it into two categories.</p><p><strong>The assignment:</strong></p><p>Write a blog entry that summarize in a few sentences 1) what you found, making sure you discuss the results for the associations between <strong>all</strong> of your explanatory variables and your response variable. Make sure to include statistical results (odds ratios, p-values, and 95% confidence intervals for the odds ratios) in your summary. 2) Report whether or not your results supported your hypothesis for the association between your primary explanatory variable and your response variable. 3) Discuss whether or not there was evidence of confounding for the association between your primary explanatory and the response variable (Hint: adding additional explanatory variables to your model one at a time will make it easier to identify which of the variables are confounding variables).  </p><p>\n",
    "\n",
    "<strong>What to Submit: Write a blog entry and submit the URL for your blog. Your blog entry should include 1) the summary of your results that addresses parts 1-3 of the assignment, 2) the output from your logistic regression model.</strong></p><p>  Example of how to write logistic regression results:</p><p>After adjusting for potential confounding factors (list them), the odds of having nicotine dependence were more than two times higher for participants with major depression than for participants without major depression (OR=2.36, 95% CI = 1.44-3.81, p=.0001). Age was also significantly associated with nicotine dependence, such that older older participants were significantly less likely to have nicotine dependence (OR= 0.81, 95% CI=0.40-0.93, p=.041).  </p></div></div></div><div class=\"rc-AssignmentInstructionSection\"><div class=\"title-container bgcolor-primary-light\"><span class=\"body-2-text\">Review criteria</span></div><div class=\"instructions-content-container\" id=\"instructions-container-1529142337748\"><div class=\"rc-CML styled\"><div><p> Your assessment will be based on the evidence you provide that you have completed all of the steps. When relevant, gradients in the scoring will be available to reward clarity (for example, you will get one point for submitting an inaccurate or incomplete description of your results, but two points if the description is accurate and complete). In all cases, consider that the peer assessing your work is likely not an expert in the field you are analyzing. You will be assessed equally on all parts of the assignment, and whether you post your program and output.  </p></div></div></div></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install inflect --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import inflect\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_FOLDER: ../data/\n",
      "SAVES_FOLDER: ../saves/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../saves/pickle/gapminder_df.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Documents\\Repositories\\notebooks\\data-science-5k\\ipynb\\data-visualization\\load-gapminder_df.ipynb\u001b[0m in \u001b[0;36mload_object\u001b[1;34m(obj_name, download_url)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[1;34m(self, path, compression, protocol)\u001b[0m\n\u001b[0;32m   2592\u001b[0m         return to_pickle(self, path, compression=compression,\n\u001b[1;32m-> 2593\u001b[1;33m                          protocol=protocol)\n\u001b[0m\u001b[0;32m   2594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[1;34m(obj, path, compression, protocol)\u001b[0m\n\u001b[0;32m     72\u001b[0m                         \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                         is_text=False)\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../saves/pickle/gapminder_df.pickle'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Documents\\Repositories\\notebooks\\data-science-5k\\ipynb\\data-visualization\\load-gapminder_df.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdownload_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://raw.githubusercontent.com/jdantonio/ratistics/master/examples/gapminder.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgapminder_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gapminder_df'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m original_columns = ['country_name', 'income_per_person', 'alcohol_consumption',\n\u001b[0;32m      5\u001b[0m                     \u001b[1;34m'armed_forces_rate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'breast_cancer_per_100th'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'co2_emissions'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\Repositories\\notebooks\\data-science-5k\\ipynb\\data-visualization\\load-gapminder_df.ipynb\u001b[0m in \u001b[0;36mload_object\u001b[1;34m(obj_name, download_url)\u001b[0m\n\u001b[0;32m     28\u001b[0m                     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../saves/pickle/gapminder_df.pickle'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_CSV_FOLDER\t DATA_FOLDER\t ENCODING_TYPE\t SAVES_CSV_FOLDER\t SAVES_FOLDER\t SAVES_PICKLE_FOLDER\t attempt_to_pickle\t csv\t data_folder\t \n",
      "download_url\t encoding\t inflect\t load_csv\t load_dataframes\t load_object\t math\t np\t os\t \n",
      "pd\t pickle\t save_dataframes\t saves_folder\t sm\t smf\t sns\t store_objects\t sys\t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%run ../../../load_magic/storage.py\n",
    "%run ../data-visualization/load-gapminder_df.ipynb\n",
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-55179e1e7a07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mformal_name_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'formal_name_dict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mformal_name_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b71521824973>\u001b[0m in \u001b[0;36mload_object\u001b[1;34m(obj_name, download_url)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             object = pd.read_csv(download_url, low_memory=False,\n\u001b[1;32m---> 19\u001b[1;33m                                  encoding=encoding)\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             object = pd.read_csv(csv_path, low_memory=False,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[1;32m--> 413\u001b[1;33m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[0;32m    414\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compression'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Invalid file path or buffer object type: {_type}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "\n",
    "formal_name_dict = load_object('formal_name_dict')\n",
    "formal_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-99f653b096e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minformal_name_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'informal_name_dict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0minformal_name_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b71521824973>\u001b[0m in \u001b[0;36mload_object\u001b[1;34m(obj_name, download_url)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             object = pd.read_csv(download_url, low_memory=False,\n\u001b[1;32m---> 19\u001b[1;33m                                  encoding=encoding)\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             object = pd.read_csv(csv_path, low_memory=False,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[1;32m--> 413\u001b[1;33m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[0;32m    414\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compression'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Invalid file path or buffer object type: {_type}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "\n",
    "informal_name_dict = load_object('informal_name_dict')\n",
    "informal_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_name: ufunc 'subtract' did not contain a loop with signature matching types dtype('<U11') dtype('<U11') dtype('<U11')\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1674: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1724: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.331220\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.277487\n",
      "         Iterations 23\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.447065\n",
      "         Iterations 7\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.283118\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.391555\n",
      "         Iterations 8\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.012979\n",
      "         Iterations: 35\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.312532\n",
      "         Iterations: 35\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.372858\n",
      "         Iterations 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gapminder_df = load_object('gapminder_df')\n",
    "gapminder_df.dropna(subset=None, inplace=True)\n",
    "for column_name in gapminder_df.columns:\n",
    "    try:\n",
    "        gapminder_df = create_binned_categories(df=gapminder_df, number_of_categories=2,\n",
    "                                                column_name=column_name, prefix=column_name)\n",
    "    except Exception as e:\n",
    "        print('{}: {}'.format(column_name, e))\n",
    "category_column_list = [column_name for column_name in gapminder_df.columns if column_name.endswith('_categories')]\n",
    "for column_name in category_column_list:\n",
    "    low_high_list = sorted(gapminder_df[column_name].unique().tolist())\n",
    "    if len(low_high_list) == 2:\n",
    "        binary_column_name = '_'.join(column_name.split('_')[:-1] + ['binary'])\n",
    "        gapminder_df[binary_column_name] = gapminder_df[column_name].map(lambda x: low_high_list.index(x)).cat.codes\n",
    "binary_column_list = [column_name for column_name in gapminder_df.columns if column_name.endswith('_binary')]\n",
    "\n",
    "inflect_engine = inflect.engine()\n",
    "\n",
    "# Find some formulas that don't blow up\n",
    "patsy_formula_list = []\n",
    "for dependent_variable in binary_column_list:\n",
    "    independent_variables_list = [col_name for col_name in binary_column_list if col_name != dependent_variable]\n",
    "    patsy_formula = dependent_variable + ' ~ ' + ' + '.join(independent_variables_list)\n",
    "    \n",
    "    # Logistic regression\n",
    "    try:\n",
    "        binary_brw = smf.logit(formula=patsy_formula, data=gapminder_df).fit()\n",
    "        patsy_formula_list.append(patsy_formula)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.331220\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.447065\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.569956\n",
      "         Iterations 6\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.283118\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.391555\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539204\n",
      "         Iterations 6\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.012979\n",
      "         Iterations: 35\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.312532\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.618813\n",
      "         Iterations 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1092: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bse_ = np.sqrt(np.diag(self.cov_params()))\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "C:\\Users\\dev\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.372858\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.519606\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find some formulas with at least one significant explanatory variable\n",
    "significant_patsy_formula_list = []\n",
    "for patsy_formula in patsy_formula_list:\n",
    "    binary_brw = smf.logit(formula=patsy_formula, data=gapminder_df).fit()\n",
    "    pvalues_series = binary_brw.pvalues\n",
    "    mask_series = (pvalues_series <= 0.05) & (pvalues_series.index != 'Intercept')\n",
    "    significant_column_list = pvalues_series[mask_series].index.tolist()\n",
    "    if len(significant_column_list) > 0:\n",
    "        response_variable_name = patsy_formula.split('~')[0].strip()\n",
    "        significant_patsy_formula = response_variable_name + ' ~ ' + ' + '.join(significant_column_list)\n",
    "        try:\n",
    "            binary_brw = smf.logit(formula=significant_patsy_formula, data=gapminder_df).fit()\n",
    "            significant_patsy_formula_list.append(significant_patsy_formula)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.569956\n",
      "         Iterations 6\n",
      "\n",
      "\n",
      "For the forty-seven nations in the study, I examine the association between the oil per person and the CO2 emissions. However in this case both the response variable and the explanatory variables are quantitative, so I categorized them all as binary variables. For the reponse variable, the 0-valued countries average about 2,256,422,666.66 (2006 cumulative CO2 emission in metric tons) and the countries for which there is an outcome that has occurred average about 169,253,731,166.50 (2006 cumulative CO2 emission in metric tons). For the explanatory variable, the 0-valued countries average about 0.45 (2010 oil Consumption per capita in tonnes per year and person) and the 1-valued countries average about 1.94 (2010 oil Consumption per capita in tonnes per year and person).\n",
      "\n",
      "After adjusting for potential confounding factors (armed forces rate, residential electricity, and employment rate), the odds of having a high CO2 emissions were more than thirty-two times higher for nations with a high oil per person than for nations with a low oil per person (OR=32.35, 95% CI=2.06-507.06, p=0.0133). Armed forces rate was also significantly associated with CO2 emissions, such that higher nations were significantly less likely to have a high CO2 emissions (OR=0.15, 95% CI=0.03-0.81, p=0.0270). Residential electricity was also significantly associated with CO2 emissions, such that higher nations were significantly less likely to have a high CO2 emissions (OR=0.04, 95% CI=0.00-0.65, p=0.0229). Employment rate was also significantly associated with CO2 emissions, such that higher nations were significantly less likely to have a high CO2 emissions (OR=0.17, 95% CI=0.03-0.91, p=0.0391).\n",
      "\n",
      "                            Logit Regression Results                            \n",
      "================================================================================\n",
      "Dep. Variable:     co2_emissions_binary   No. Observations:                   47\n",
      "Model:                            Logit   Df Residuals:                       42\n",
      "Method:                             MLE   Df Model:                            4\n",
      "Date:                  Sat, 16 Jun 2018   Pseudo R-squ.:                  0.1775\n",
      "Time:                          17:54:43   Log-Likelihood:                -26.788\n",
      "converged:                         True   LL-Null:                       -32.567\n",
      "                                          LLR p-value:                   0.02095\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         1.5488      0.863      1.795      0.073      -0.142       3.240\n",
      "armed_forces_rate_binary         -1.8991      0.859     -2.211      0.027      -3.583      -0.216\n",
      "oil_per_person_binary             3.4766      1.404      2.476      0.013       0.725       6.229\n",
      "electricity_per_person_binary    -3.1257      1.374     -2.275      0.023      -5.819      -0.432\n",
      "employ_rate_binary               -1.7964      0.871     -2.063      0.039      -3.503      -0.090\n",
      "=================================================================================================\n",
      "                               Lower CI    Upper CI  Odds Ratios\n",
      "Intercept                      0.867374   25.531193     4.705857\n",
      "armed_forces_rate_binary       0.027806    0.806038     0.149708\n",
      "oil_per_person_binary          2.063919  507.063065    32.350223\n",
      "electricity_per_person_binary  0.002970    0.649023     0.043907\n",
      "employ_rate_binary             0.030111    0.913905     0.165888\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539204\n",
      "         Iterations 6\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.618813\n",
      "         Iterations 5\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.519606\n",
      "         Iterations 6\n",
      "\n",
      "\n",
      "For the forty-seven nations in the study, I examine the association between the life expectancy and the urban rate. However in this case both the response variable and the explanatory variables are quantitative, so I categorized them all as binary variables. For the reponse variable, the 0-valued countries average about 48.75 (2008 urban population as a % of total) and the countries for which there is an outcome that has occurred average about 81.18 (2008 urban population as a % of total). For the explanatory variable, the 0-valued countries average about 64.88 (2011 life expectancy at birth in years) and the 1-valued countries average about 80.17 (2011 life expectancy at birth in years).\n",
      "\n",
      "After adjusting for potential confounding factors (employment rate), the odds of having a high urban rate were more than seven times higher for nations with a high life expectancy than for nations with a low life expectancy (OR=7.33, 95% CI=1.69-31.80, p=0.0078). Employment rate was also significantly associated with urban rate, such that higher nations were significantly more likely to have a high urban rate (OR=7.33, 95% CI=1.69-31.80, p=0.0078).\n",
      "\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      urban_rate_binary   No. Observations:                   47\n",
      "Model:                          Logit   Df Residuals:                       44\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 16 Jun 2018   Pseudo R-squ.:                  0.2501\n",
      "Time:                        17:54:43   Log-Likelihood:                -24.421\n",
      "converged:                       True   LL-Null:                       -32.567\n",
      "                                        LLR p-value:                 0.0002900\n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "Intercept                 -2.0067      0.703     -2.853      0.004      -3.385      -0.628\n",
      "life_expectancy_binary     1.9919      0.749      2.660      0.008       0.524       3.460\n",
      "employ_rate_binary         1.9919      0.749      2.660      0.008       0.524       3.460\n",
      "==========================================================================================\n",
      "                        Lower CI   Upper CI  Odds Ratios\n",
      "Intercept               0.033870   0.533593     0.134436\n",
      "life_expectancy_binary  1.689223  31.803513     7.329613\n",
      "employ_rate_binary      1.689223  31.803513     7.329613\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for patsy_formula in significant_patsy_formula_list:\n",
    "    binary_brw = smf.logit(formula=patsy_formula, data=gapminder_df).fit()\n",
    "    print()\n",
    "    #print(patsy_formula)\n",
    "    #print(binary_brw.summary())\n",
    "\n",
    "    # Odd ratios with 95% confidence intervals\n",
    "    params_series = binary_brw.params\n",
    "    conf_int_df = binary_brw.conf_int()\n",
    "    conf_int_df['OR'] = params_series\n",
    "    conf_int_df.columns = ['Lower CI', 'Upper CI', 'Odds Ratios']\n",
    "    conf_int_df = np.exp(conf_int_df)\n",
    "\n",
    "    # Get column with highest odds\n",
    "    mask_series = (conf_int_df.index != 'Intercept')\n",
    "    max_odds_ratio = conf_int_df[mask_series]['Odds Ratios'].max()\n",
    "    mask_series = (conf_int_df['Odds Ratios'] == max_odds_ratio)\n",
    "    max_odds_column = conf_int_df[mask_series].index.tolist()[0]\n",
    "    \n",
    "    # Get other explanation params\n",
    "    mask_series = (conf_int_df.index == max_odds_column)\n",
    "    lower_ci = conf_int_df[mask_series]['Lower CI'].squeeze()\n",
    "    upper_ci = conf_int_df[mask_series]['Upper CI'].squeeze()\n",
    "    \n",
    "    # Get p-value of highest odds column\n",
    "    pvalues_series = binary_brw.pvalues\n",
    "    mask_series = (pvalues_series.index == max_odds_column)\n",
    "    p_value = pvalues_series[mask_series].squeeze()\n",
    "    \n",
    "    if (max_odds_ratio >= 2.0) and (p_value <= 0.05):\n",
    "        \n",
    "        # Get list of other significant columns\n",
    "        other_significants_match_series = (pvalues_series.index != 'Intercept') & (pvalues_series.index != max_odds_column)\n",
    "        other_significants_list = pvalues_series[other_significants_match_series].index.tolist()\n",
    "        \n",
    "        # Get informal name of response variable\n",
    "        response_variable_name = patsy_formula.split('~')[0].strip()\n",
    "        response_variable_prefix = '_'.join(response_variable_name.split('_')[:-1])\n",
    "        informal_response_name = informal_name_dict[response_variable_prefix]\n",
    "        \n",
    "        # Get informal name of explanatory variable\n",
    "        explanatory_variable_prefix = '_'.join(max_odds_column.split('_')[:-1])\n",
    "        informal_odds_name = informal_name_dict[explanatory_variable_prefix]\n",
    "        \n",
    "        # Describe the thesis\n",
    "        explanation_str = ('For the ' + inflect_engine.number_to_words(gapminder_df.shape[0]) + ' nations in the study, ' +\n",
    "                           'I examine the association between the ' + informal_odds_name +\n",
    "                           ' and the ' + informal_response_name +\n",
    "                           '. However in this case both the response variable and the explanatory variables are ' +\n",
    "                           'quantitative, so I categorized them all as binary variables. ')\n",
    "        \n",
    "        # Describe the response variable\n",
    "        category_column_name = response_variable_prefix + '_categories'\n",
    "        low_high_list = sorted(gapminder_df[category_column_name].unique().tolist())\n",
    "        explanation_str += ('For the reponse variable, the 0-valued countries average about ' +\n",
    "                            '{:,.2f} ('.format(low_high_list[0]) + \n",
    "                            formal_name_dict[response_variable_prefix] +\n",
    "                            ') and the countries for which there is an outcome that has occurred ' +\n",
    "                            'average about {:,.2f} ('.format(low_high_list[1]) + formal_name_dict[response_variable_prefix] +\n",
    "                            '). ')\n",
    "        \n",
    "        # Describe the explanatory variable\n",
    "        category_column_name = explanatory_variable_prefix + '_categories'\n",
    "        low_high_list = sorted(gapminder_df[category_column_name].unique().tolist())\n",
    "        explanation_str += ('For the explanatory variable, the 0-valued countries average about ' +\n",
    "                            '{:,.2f} ('.format(low_high_list[0]) + \n",
    "                            formal_name_dict[explanatory_variable_prefix] +\n",
    "                            ') and the 1-valued countries average about {:,.2f} ('.format(low_high_list[1]) +\n",
    "                            formal_name_dict[explanatory_variable_prefix] + ').')\n",
    "        \n",
    "        if len(other_significants_list) > 0:\n",
    "            other_significants_list = [informal_name_dict['_'.join(c.split('_')[:-1])] for c in other_significants_list]\n",
    "            explanation_str += ('\\n\\nAfter adjusting for potential confounding factors (' +\n",
    "                               conjunctify_list(other_significants_list) +\n",
    "                               '), t')\n",
    "        else:\n",
    "            explanation_str += ('\\n\\nT')\n",
    "        explanation_str += ('he odds of having a high ' + informal_response_name +\n",
    "                            ' were more than ' + inflect_engine.number_to_words(math.floor(max_odds_ratio)) +\n",
    "                            ' times higher for nations with a high ' + informal_odds_name +\n",
    "                            ' than for nations with a low ' + informal_odds_name +\n",
    "                            ' (OR={:.2f}, 95% CI={:.2f}-{:.2f}, p={:.4f})'.format(max_odds_ratio, lower_ci,\n",
    "                                                                                  upper_ci, p_value) +\n",
    "                            '.')\n",
    "        confounded_variables_list = []\n",
    "        for significant_column, significant_pvalue in pvalues_series[other_significants_match_series].iteritems():\n",
    "            informal_significant_name = informal_name_dict['_'.join(significant_column.split('_')[:-1])]\n",
    "            odds_match_series = (conf_int_df.index == significant_column)\n",
    "            odds_ratio = conf_int_df[odds_match_series]['Odds Ratios'].max()\n",
    "            if odds_ratio < 1.0:\n",
    "                less_more_str = 'less'\n",
    "            elif odds_ratio > 1.0:\n",
    "                less_more_str = 'more'\n",
    "            else:\n",
    "                less_more_str = 'equally'\n",
    "            lower_ci = conf_int_df[odds_match_series]['Lower CI'].max()\n",
    "            upper_ci = conf_int_df[odds_match_series]['Upper CI'].max()\n",
    "            if significant_pvalue <= 0.05:\n",
    "                explanation_str += (' ' + informal_significant_name[0].upper() + informal_significant_name[1:] +\n",
    "                                    ' was also significantly associated with ' + informal_response_name +\n",
    "                                    ', such that higher nations were significantly ' + less_more_str +\n",
    "                                    ' likely to have a high ' + informal_response_name +\n",
    "                                    ' (OR={:.2f}, 95% CI={:.2f}-{:.2f}, p={:.4f})'.format(odds_ratio, lower_ci,\n",
    "                                                                                          upper_ci,\n",
    "                                                                                          significant_pvalue) +\n",
    "                                    '.')\n",
    "            else:\n",
    "                confounded_variables_list.append(significant_column)\n",
    "                confounded_formula = patsy_formula.split('~')[0].strip() + ' ~ ' + confounded_variable\n",
    "                confounded_brw = smf.logit(formula=confounded_formula, data=gapminder_df).fit()\n",
    "                confounded_pvalues_series = confounded_brw.pvalues\n",
    "                confounded_match_series = (confounded_pvalues_series <= 0.05) & (confounded_pvalues_series.index != 'Intercept')\n",
    "                significant_confounded_list = confounded_pvalues_series[confounded_match_series].index.tolist()\n",
    "                if len(significant_confounded_list) > 0:\n",
    "                    explanation_str += (' ' + informal_significant_name[0].upper() + informal_significant_name[1:] +\n",
    "                                        ' was also insignificantly associated with ' + informal_response_name +\n",
    "                                        ', such that higher nations were insignificantly ' + less_more_str +\n",
    "                                        ' likely to have a high ' + informal_response_name +\n",
    "                                        ' (OR={:.2f}, 95% CI={:.2f}-{:.2f}, p={:.4f})'.format(odds_ratio, lower_ci,\n",
    "                                                                                              upper_ci,\n",
    "                                                                                              significant_pvalue) +\n",
    "                                        '. (There is evidence that this variable was confounded by the addition of ' +\n",
    "                                        'other variables as it is significant in isolation.)')\n",
    "        print()\n",
    "        print(explanation_str)\n",
    "        #print(patsy_formula)\n",
    "        print()\n",
    "        print(binary_brw.summary())\n",
    "        print(conf_int_df)\n",
    "        print()\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
