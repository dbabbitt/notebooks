{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats as sps\n",
    "from IPython.display import clear_output\n",
    "%run ../../load_magic/storage.py\n",
    "s = Storage()\n",
    "states_stats_df = s.load_object('states_stats_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_posteriors(sr, sigma=0.15):\n",
    "\n",
    "    # (1) Calculate Lambda\n",
    "    lam = sr[:-1].values * np.exp(GAMMA * (r_t_range[:, None] - 1))\n",
    "\n",
    "    \n",
    "    # (2) Calculate each day's likelihood\n",
    "    likelihoods = pd.DataFrame(\n",
    "        data = sps.poisson.pmf(sr[1:].values, lam),\n",
    "        index = r_t_range,\n",
    "        columns = sr.index[1:])\n",
    "    \n",
    "    # (3) Create the Gaussian Matrix\n",
    "    process_matrix = sps.norm(loc=r_t_range,\n",
    "                              scale=sigma\n",
    "                             ).pdf(r_t_range[:, None]) \n",
    "\n",
    "    # (3a) Normalize all rows to sum to 1\n",
    "    process_matrix /= process_matrix.sum(axis=0)\n",
    "    \n",
    "    # (4) Calculate the initial prior\n",
    "    prior0 = sps.gamma(a=4).pdf(r_t_range)\n",
    "    prior0 /= prior0.sum()\n",
    "\n",
    "    # Create a DataFrame that will hold our posteriors for each day\n",
    "    # Insert our prior as the first posterior.\n",
    "    posteriors_df = pd.DataFrame(\n",
    "        index=r_t_range,\n",
    "        columns=sr.index,\n",
    "        data={sr.index[0]: prior0}\n",
    "    )\n",
    "    \n",
    "    # We said we'd keep track of the sum of the log of the probability\n",
    "    # of the data for maximum likelihood calculation.\n",
    "    log_likelihood = 0.0\n",
    "\n",
    "    # (5) Iteratively apply Bayes' rule\n",
    "    for previous_day, current_day in zip(sr.index[:-1], sr.index[1:]):\n",
    "\n",
    "        #(5a) Calculate the new prior\n",
    "        current_prior = process_matrix @ posteriors_df[previous_day]\n",
    "        \n",
    "        #(5b) Calculate the numerator of Bayes' Rule: P(k|R_t)P(R_t)\n",
    "        numerator = likelihoods[current_day] * current_prior\n",
    "        \n",
    "        #(5c) Calcluate the denominator of Bayes' Rule P(k)\n",
    "        denominator = np.sum(numerator)\n",
    "        \n",
    "        # Execute full Bayes' Rule\n",
    "        posteriors_df[current_day] = numerator/denominator\n",
    "        \n",
    "        # Add to the running sum of log likelihoods\n",
    "        log_likelihood += np.log(denominator)\n",
    "    \n",
    "    return posteriors_df, log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_cases(cases, cutoff=25):\n",
    "    new_cases = cases.diff()\n",
    "\n",
    "    smoothed = new_cases.rolling(7,\n",
    "        win_type='gaussian',\n",
    "        min_periods=1,\n",
    "        center=True).mean(std=2).round()\n",
    "    \n",
    "    idx_start = np.searchsorted(smoothed, cutoff)\n",
    "    \n",
    "    smoothed = smoothed.iloc[idx_start:]\n",
    "    original = new_cases.loc[smoothed.index]\n",
    "    \n",
    "    return original, smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def highest_density_interval(pmf, p=.9):\n",
    "    \n",
    "    # If we pass a DataFrame, just call this recursively on the columns\n",
    "    if(isinstance(pmf, pd.DataFrame)):\n",
    "        \n",
    "        return pd.DataFrame([highest_density_interval(pmf[col], p=p) for col in pmf],\n",
    "                            index=pmf.columns)\n",
    "    \n",
    "    cumsum = np.cumsum(pmf.values)\n",
    "    \n",
    "    # N x N matrix of total probability mass for each low, high\n",
    "    total_p = cumsum - cumsum[:, None]\n",
    "    \n",
    "    # Return all indices with total_p > p\n",
    "    lows, highs = (total_p > p).nonzero()\n",
    "    if (lows.size == 0) or (highs.size == 0):\n",
    "    \n",
    "        return pd.Series([np.nan, np.nan], index=[f'Low_{p*100:.0f}', f'High_{p*100:.0f}'], dtype='float64')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Find the smallest range (highest density)\n",
    "        best = (highs - lows).argmin()\n",
    "\n",
    "        low = pmf.index[lows[best]]\n",
    "        high = pmf.index[highs[best]]\n",
    "\n",
    "        return pd.Series([low, high],\n",
    "                         index=[f'Low_{p*100:.0f}',\n",
    "                                f'High_{p*100:.0f}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Final Results\n",
    "\n",
    "Given that we've selected the optimal $\\sigma$, let's grab the precalculated posterior corresponding to that value of $\\sigma$ for each state. Let's also calculate the 90% and 50% highest density intervals (this takes a little while) and also the most likely value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We create an array for every possible value of Rt\n",
    "R_T_MAX = 12\n",
    "r_t_range = np.linspace(0, R_T_MAX, R_T_MAX*100+1)\n",
    "\n",
    "# Gamma is 1/serial interval\n",
    "# https://wwwnc.cdc.gov/eid/article/26/7/20-0282_article\n",
    "# https://www.nejm.org/doi/full/10.1056/NEJMoa2001316\n",
    "GAMMA = 1/7\n",
    "\n",
    "FILTERED_REGION_CODES = ['AS', 'GU', 'PR', 'VI', 'MP']\n",
    "url = 'https://covidtracking.com/api/v1/states/daily.csv'\n",
    "states = pd.read_csv(url,\n",
    "                     usecols=['date', 'state', 'positive'],\n",
    "                     parse_dates=['date'],\n",
    "                     index_col=['state', 'date'],\n",
    "                     squeeze=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sigmas = np.linspace(1/20, 1, 20)\n",
    "targets = ~states.index.get_level_values('state').isin(FILTERED_REGION_CODES)\n",
    "states_to_process = states.loc[targets]\n",
    "results = {}\n",
    "n_min = 25\n",
    "for state_name, cases in states_to_process.groupby(level='state'):\n",
    "    print(state_name)\n",
    "    n = 7\n",
    "    new, smoothed = prepare_cases(cases, cutoff=n)\n",
    "    while len(smoothed) == 0:\n",
    "        n -= 1\n",
    "        new, smoothed = prepare_cases(cases, cutoff=n)\n",
    "    result_dict = {}\n",
    "    n_min = min(n_min, n)\n",
    "    \n",
    "    # Holds all posteriors with every given value of sigma\n",
    "    result_dict['posteriors'] = []\n",
    "    \n",
    "    # Holds the log likelihood across all k for each value of sigma\n",
    "    result_dict['log_likelihoods'] = []\n",
    "    \n",
    "    for sigma in sigmas:\n",
    "        posteriors, log_likelihood = get_posteriors(smoothed, sigma=sigma)\n",
    "        result_dict['posteriors'].append(posteriors)\n",
    "        result_dict['log_likelihoods'].append(log_likelihood)\n",
    "    \n",
    "    # Store all results keyed off of state name\n",
    "    results[state_name] = result_dict\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'{n_min} Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Each index of this array holds the total of the log likelihoods for\n",
    "# the corresponding index of the sigmas array.\n",
    "total_log_likelihoods = np.zeros_like(sigmas)\n",
    "\n",
    "# Loop through each state's results and add the log likelihoods to the running total.\n",
    "for state_name, result_series in results.items():\n",
    "    total_log_likelihoods += result_series['log_likelihoods']\n",
    "\n",
    "# Select the index with the largest log likelihood total\n",
    "max_likelihood_index = total_log_likelihoods.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_results = None\n",
    "\n",
    "for state_name, result in results.items():\n",
    "    print(state_name)\n",
    "    posteriors = result['posteriors'][max_likelihood_index]\n",
    "    hdis_90 = highest_density_interval(posteriors, p=.9)\n",
    "    hdis_50 = highest_density_interval(posteriors, p=.5)\n",
    "    most_likely = posteriors.idxmax().rename('ML')\n",
    "    result_df = pd.concat([most_likely, hdis_90, hdis_50], axis=1)\n",
    "    mask_series = result_df.Low_90.isnull() | result_df.High_90.isnull()\n",
    "    result_df = result_df[~mask_series]\n",
    "    if final_results is None:\n",
    "        final_results = result_df\n",
    "    else:\n",
    "        final_results = pd.concat([final_results, result_df])\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HERD_IMMUNITY_THRESHOLD = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = states.to_frame()\n",
    "df.columns = ['cumulative_cases']\n",
    "df['new_cases'] = df.cumulative_cases.diff()\n",
    "final_results['DuFI'] = np.nan\n",
    "for index_tuple, row_series in final_results.iterrows():\n",
    "    state_name = index_tuple[0]\n",
    "    state_mask_series = (df.index.get_level_values('state') == state_name)\n",
    "    time_stamp = index_tuple[1]\n",
    "    date_mask_series = (df.index.get_level_values('date') == time_stamp)\n",
    "    mask_series = state_mask_series & date_mask_series\n",
    "    if df[mask_series].shape[0] > 0:\n",
    "        case_rate = int(df[mask_series].new_cases.squeeze())\n",
    "        if case_rate > 0:\n",
    "            date_mask_series = (df.index.get_level_values('date') <= time_stamp)\n",
    "            mask_series = state_mask_series & date_mask_series\n",
    "            infected_population = int(df[mask_series].cumulative_cases[-1])\n",
    "            if state_name == 'DC':\n",
    "                population = 601_723\n",
    "            else:\n",
    "                mask_series = (states_stats_df.State_Abbreviation == state_name)\n",
    "                population = states_stats_df[mask_series].Census_Population_2010.squeeze()\n",
    "            days_until_full_infection = int((HERD_IMMUNITY_THRESHOLD*population - infected_population)/case_rate)\n",
    "            final_results.loc[index_tuple, 'DuFI'] = days_until_full_infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\dev\\Documents\\repositories\\notebooks\\covid19\\saves\\pickle\\final_results.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.store_objects(final_results=final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ML</th>\n",
       "      <th>Low_90</th>\n",
       "      <th>High_90</th>\n",
       "      <th>Low_50</th>\n",
       "      <th>High_50</th>\n",
       "      <th>DuFI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AK</th>\n",
       "      <th>2020-05-19</th>\n",
       "      <td>1.07</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-20</th>\n",
       "      <td>1.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.31</td>\n",
       "      <td>212935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-21</th>\n",
       "      <td>1.07</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-22</th>\n",
       "      <td>1.06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.28</td>\n",
       "      <td>319401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-23</th>\n",
       "      <td>1.06</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.29</td>\n",
       "      <td>159699.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ML  Low_90  High_90  Low_50  High_50      DuFI\n",
       "state date                                                        \n",
       "AK    2020-05-19  1.07    0.35     1.73    0.73     1.30       NaN\n",
       "      2020-05-20  1.07    0.33     1.72    0.74     1.31  212935.0\n",
       "      2020-05-21  1.07    0.34     1.73    0.77     1.34       NaN\n",
       "      2020-05-22  1.06    0.32     1.72    0.70     1.28  319401.0\n",
       "      2020-05-23  1.06    0.33     1.73    0.71     1.29  159699.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "state_mask_series = (final_results.index.get_level_values('state') == final_results.groupby('state').DuFI.min().idxmax())\n",
    "final_results[state_mask_series].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ML</th>\n",
       "      <th>Low_90</th>\n",
       "      <th>High_90</th>\n",
       "      <th>Low_50</th>\n",
       "      <th>High_50</th>\n",
       "      <th>DuFI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">TX</th>\n",
       "      <th>2020-05-19</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.95</td>\n",
       "      <td>18524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-20</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.85</td>\n",
       "      <td>16002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-21</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.80</td>\n",
       "      <td>23892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-22</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.70</td>\n",
       "      <td>19117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-23</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ML  Low_90  High_90  Low_50  High_50     DuFI\n",
       "state date                                                       \n",
       "TX    2020-05-19  0.90    0.72     1.04    0.82     0.95  18524.0\n",
       "      2020-05-20  0.80    0.62     0.94    0.72     0.85  16002.0\n",
       "      2020-05-21  0.77    0.59     0.91    0.66     0.80  23892.0\n",
       "      2020-05-22  0.66    0.48     0.81    0.56     0.70  19117.0\n",
       "      2020-05-23  0.51    0.32     0.66    0.42     0.56      NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "state_mask_series = (final_results.index.get_level_values('state') == final_results.groupby('state').DuFI.max().idxmax())\n",
    "final_results[state_mask_series].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cumulative_cases</th>\n",
       "      <th>percent_population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">TX</th>\n",
       "      <th>2020-05-19</th>\n",
       "      <td>49912.0</td>\n",
       "      <td>0.198492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-20</th>\n",
       "      <td>51323.0</td>\n",
       "      <td>0.204104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-21</th>\n",
       "      <td>52268.0</td>\n",
       "      <td>0.207862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-22</th>\n",
       "      <td>53449.0</td>\n",
       "      <td>0.212558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-23</th>\n",
       "      <td>53449.0</td>\n",
       "      <td>0.212558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cumulative_cases  percent_population\n",
       "state date                                            \n",
       "TX    2020-05-19           49912.0            0.198492\n",
       "      2020-05-20           51323.0            0.204104\n",
       "      2020-05-21           52268.0            0.207862\n",
       "      2020-05-22           53449.0            0.212558\n",
       "      2020-05-23           53449.0            0.212558"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "state_name = final_results.groupby('state').DuFI.max().idxmax()\n",
    "mask_series = (states_stats_df.State_Abbreviation == state_name)\n",
    "population = states_stats_df[mask_series].Census_Population_2010.squeeze()\n",
    "state_mask_series = (states.index.get_level_values('state') == state_name)\n",
    "df = states[state_mask_series].to_frame()\n",
    "df.columns = ['cumulative_cases']\n",
    "df['percent_population'] = df.cumulative_cases.map(lambda x: 100*x/population)\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
