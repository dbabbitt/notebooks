{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Final Results\n",
    "\n",
    "Given that we've selected the optimal $\\sigma$, let's grab the precalculated posterior corresponding to that value of $\\sigma$ for each state. Let's also calculate the 90% and 50% highest density intervals (this takes a little while) and also the most likely value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_posteriors(sr, sigma=0.15):\n",
    "\n",
    "    # (1) Calculate Lambda\n",
    "    lam = sr[:-1].values * np.exp(GAMMA * (r_t_range[:, None] - 1))\n",
    "\n",
    "    \n",
    "    # (2) Calculate each day's likelihood\n",
    "    likelihoods = pd.DataFrame(\n",
    "        data = sps.poisson.pmf(sr[1:].values, lam),\n",
    "        index = r_t_range,\n",
    "        columns = sr.index[1:])\n",
    "    \n",
    "    # (3) Create the Gaussian Matrix\n",
    "    process_matrix = sps.norm(loc=r_t_range,\n",
    "                              scale=sigma\n",
    "                             ).pdf(r_t_range[:, None]) \n",
    "\n",
    "    # (3a) Normalize all rows to sum to 1\n",
    "    process_matrix /= process_matrix.sum(axis=0)\n",
    "    \n",
    "    # (4) Calculate the initial prior\n",
    "    prior0 = sps.gamma(a=4).pdf(r_t_range)\n",
    "    prior0 /= prior0.sum()\n",
    "\n",
    "    # Create a DataFrame that will hold our posteriors for each day\n",
    "    # Insert our prior as the first posterior.\n",
    "    posteriors_df = pd.DataFrame(\n",
    "        index=r_t_range,\n",
    "        columns=sr.index,\n",
    "        data={sr.index[0]: prior0}\n",
    "    )\n",
    "    \n",
    "    # We said we'd keep track of the sum of the log of the probability\n",
    "    # of the data for maximum likelihood calculation.\n",
    "    log_likelihood = 0.0\n",
    "\n",
    "    # (5) Iteratively apply Bayes' rule\n",
    "    for previous_day, current_day in zip(sr.index[:-1], sr.index[1:]):\n",
    "\n",
    "        #(5a) Calculate the new prior\n",
    "        current_prior = process_matrix @ posteriors_df[previous_day]\n",
    "        \n",
    "        #(5b) Calculate the numerator of Bayes' Rule: P(k|R_t)P(R_t)\n",
    "        numerator = likelihoods[current_day] * current_prior\n",
    "        \n",
    "        #(5c) Calcluate the denominator of Bayes' Rule P(k)\n",
    "        denominator = np.sum(numerator)\n",
    "        \n",
    "        # Execute full Bayes' Rule\n",
    "        posteriors_df[current_day] = numerator/denominator\n",
    "        \n",
    "        # Add to the running sum of log likelihoods\n",
    "        log_likelihood += np.log(denominator)\n",
    "    \n",
    "    return posteriors_df, log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_cases(cases, cutoff=25):\n",
    "    new_cases = cases.diff()\n",
    "\n",
    "    smoothed = new_cases.rolling(7,\n",
    "        win_type='gaussian',\n",
    "        min_periods=1,\n",
    "        center=True).mean(std=2).round()\n",
    "    \n",
    "    idx_start = np.searchsorted(smoothed, cutoff)\n",
    "    \n",
    "    smoothed = smoothed.iloc[idx_start:]\n",
    "    original = new_cases.loc[smoothed.index]\n",
    "    \n",
    "    return original, smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# We create an array for every possible value of Rt\n",
    "R_T_MAX = 12\n",
    "r_t_range = np.linspace(0, R_T_MAX, R_T_MAX*100+1)\n",
    "\n",
    "# Gamma is 1/serial interval\n",
    "# https://wwwnc.cdc.gov/eid/article/26/7/20-0282_article\n",
    "# https://www.nejm.org/doi/full/10.1056/NEJMoa2001316\n",
    "GAMMA = 1/7\n",
    "\n",
    "FILTERED_REGION_CODES = ['AS', 'GU', 'PR', 'VI', 'MP']\n",
    "url = 'https://covidtracking.com/api/v1/states/daily.csv'\n",
    "states = pd.read_csv(url,\n",
    "                     usecols=['date', 'state', 'positive'],\n",
    "                     parse_dates=['date'],\n",
    "                     index_col=['state', 'date'],\n",
    "                     squeeze=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import stats as sps\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sigmas = np.linspace(1/20, 1, 20)\n",
    "targets = ~states.index.get_level_values('state').isin(FILTERED_REGION_CODES)\n",
    "states_to_process = states.loc[targets]\n",
    "results = {}\n",
    "for state_name, cases in states_to_process.groupby(level='state'):\n",
    "    print(state_name)\n",
    "    new, smoothed = prepare_cases(cases, cutoff=25)\n",
    "    if len(smoothed) == 0:\n",
    "        new, smoothed = prepare_cases(cases, cutoff=10)\n",
    "    result_dict = {}\n",
    "    \n",
    "    # Holds all posteriors with every given value of sigma\n",
    "    result_dict['posteriors'] = []\n",
    "    \n",
    "    # Holds the log likelihood across all k for each value of sigma\n",
    "    result_dict['log_likelihoods'] = []\n",
    "    \n",
    "    for sigma in sigmas:\n",
    "        posteriors, log_likelihood = get_posteriors(smoothed, sigma=sigma)\n",
    "        result_dict['posteriors'].append(posteriors)\n",
    "        result_dict['log_likelihoods'].append(log_likelihood)\n",
    "    \n",
    "    # Store all results keyed off of state name\n",
    "    results[state_name] = result_dict\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Each index of this array holds the total of the log likelihoods for\n",
    "# the corresponding index of the sigmas array.\n",
    "total_log_likelihoods = np.zeros_like(sigmas)\n",
    "\n",
    "# Loop through each state's results and add the log likelihoods to the running total.\n",
    "for state_name, result_series in results.items():\n",
    "    total_log_likelihoods += result_series['log_likelihoods']\n",
    "\n",
    "# Select the index with the largest log likelihood total\n",
    "max_likelihood_index = total_log_likelihoods.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def highest_density_interval(pmf, p=.9):\n",
    "    \n",
    "    # If we pass a DataFrame, just call this recursively on the columns\n",
    "    if(isinstance(pmf, pd.DataFrame)):\n",
    "        \n",
    "        return pd.DataFrame([highest_density_interval(pmf[col], p=p) for col in pmf],\n",
    "                            index=pmf.columns)\n",
    "    \n",
    "    cumsum = np.cumsum(pmf.values)\n",
    "    \n",
    "    # N x N matrix of total probability mass for each low, high\n",
    "    total_p = cumsum - cumsum[:, None]\n",
    "    \n",
    "    # Return all indices with total_p > p\n",
    "    lows, highs = (total_p > p).nonzero()\n",
    "    if (lows.size == 0) or (highs.size == 0):\n",
    "    \n",
    "        return pd.Series([np.nan, np.nan], index=[f'Low_{p*100:.0f}', f'High_{p*100:.0f}'], dtype='float64')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Find the smallest range (highest density)\n",
    "        best = (highs - lows).argmin()\n",
    "\n",
    "        low = pmf.index[lows[best]]\n",
    "        high = pmf.index[highs[best]]\n",
    "\n",
    "        return pd.Series([low, high],\n",
    "                         index=[f'Low_{p*100:.0f}',\n",
    "                                f'High_{p*100:.0f}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_results = None\n",
    "\n",
    "for state_name, result in results.items():\n",
    "    print(state_name)\n",
    "    posteriors = result['posteriors'][max_likelihood_index]\n",
    "    hdis_90 = highest_density_interval(posteriors, p=.9)\n",
    "    hdis_50 = highest_density_interval(posteriors, p=.5)\n",
    "    most_likely = posteriors.idxmax().rename('ML')\n",
    "    result_df = pd.concat([most_likely, hdis_90, hdis_50], axis=1)\n",
    "    mask_series = result_df.Low_90.isnull() | result_df.High_90.isnull()\n",
    "    result_df = result_df[~mask_series]\n",
    "    if final_results is None:\n",
    "        final_results = result_df\n",
    "    else:\n",
    "        final_results = pd.concat([final_results, result_df])\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "s = Storage()\n",
    "states_stats_df = s.load_object('states_stats_df')\n",
    "HERD_IMMUNITY_THRESHOLD = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_results['DuFI'] = np.nan\n",
    "for index_tuple, row_series in final_results.iterrows():\n",
    "    state_name = index_tuple[0]\n",
    "    state_mask_series = (states.index.get_level_values('state') == state_name)\n",
    "    date_mask_series = (states.index.get_level_values('date') == index_tuple[1])\n",
    "    mask_series = state_mask_series & date_mask_series\n",
    "    if states[mask_series].shape[0] > 0:\n",
    "        case_rate = int(states[mask_series].squeeze())\n",
    "        date_mask_series = (states.index.get_level_values('date') <= index_tuple[1])\n",
    "        mask_series = state_mask_series & date_mask_series\n",
    "        total_cases = int(states[mask_series].cumsum()[-1])\n",
    "        if state_name == 'DC':\n",
    "            population = 601_723\n",
    "        else:\n",
    "            mask_series = (states_stats_df.State_Abbreviation == state_name)\n",
    "            population = states_stats_df[mask_series].Census_Population_2010.squeeze()\n",
    "        days_until_full_infection = int((population-total_cases)/case_rate * HERD_IMMUNITY_THRESHOLD)\n",
    "        final_results.loc[index_tuple, 'DuFI'] = days_until_full_infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to D:\\Documents\\Repositories\\notebooks\\covid19\\saves\\pickle\\final_results.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.store_objects(final_results=final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ML</th>\n",
       "      <th>Low_90</th>\n",
       "      <th>High_90</th>\n",
       "      <th>Low_50</th>\n",
       "      <th>High_50</th>\n",
       "      <th>DuFI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AK</th>\n",
       "      <th>2020-03-25</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>6.84</td>\n",
       "      <td>1.86</td>\n",
       "      <td>4.27</td>\n",
       "      <td>10143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>2.72</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.77</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.46</td>\n",
       "      <td>7220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-27</th>\n",
       "      <td>2.39</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.95</td>\n",
       "      <td>6173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-28</th>\n",
       "      <td>2.09</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.57</td>\n",
       "      <td>5010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-29</th>\n",
       "      <td>1.90</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3.14</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.39</td>\n",
       "      <td>4174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">WY</th>\n",
       "      <th>2020-05-06</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.85</td>\n",
       "      <td>547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-07</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.83</td>\n",
       "      <td>523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-08</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-09</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.99</td>\n",
       "      <td>511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-10</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.04</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ML  Low_90  High_90  Low_50  High_50     DuFI\n",
       "state date                                                       \n",
       "AK    2020-03-25  3.00    0.86     6.84    1.86     4.27  10143.0\n",
       "      2020-03-26  2.72    0.99     4.77    1.87     3.46   7220.0\n",
       "      2020-03-27  2.39    0.90     3.98    1.66     2.95   6173.0\n",
       "      2020-03-28  2.09    0.75     3.46    1.44     2.57   5010.0\n",
       "      2020-03-29  1.90    0.62     3.14    1.35     2.39   4174.0\n",
       "...                ...     ...      ...     ...      ...      ...\n",
       "WY    2020-05-06  0.51    0.00     1.47    0.19     0.85    547.0\n",
       "      2020-05-07  0.53    0.00     1.52    0.14     0.83    523.0\n",
       "      2020-05-08  0.61    0.00     1.60    0.21     0.94    519.0\n",
       "      2020-05-09  0.63    0.00     1.63    0.25     0.99    511.0\n",
       "      2020-05-10  0.65    0.00     1.65    0.29     1.04    497.0\n",
       "\n",
       "[2572 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
