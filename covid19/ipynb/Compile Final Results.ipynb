{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats as sps\n",
    "from IPython.display import clear_output\n",
    "%run ../../load_magic/storage.py\n",
    "s = Storage()\n",
    "states_stats_df = s.load_object('states_stats_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_posteriors(sr, sigma=0.15):\n",
    "\n",
    "    # (1) Calculate Lambda\n",
    "    lam = sr[:-1].values * np.exp(GAMMA * (r_t_range[:, None] - 1))\n",
    "\n",
    "    \n",
    "    # (2) Calculate each day's likelihood\n",
    "    likelihoods = pd.DataFrame(\n",
    "        data = sps.poisson.pmf(sr[1:].values, lam),\n",
    "        index = r_t_range,\n",
    "        columns = sr.index[1:])\n",
    "    \n",
    "    # (3) Create the Gaussian Matrix\n",
    "    process_matrix = sps.norm(loc=r_t_range,\n",
    "                              scale=sigma\n",
    "                             ).pdf(r_t_range[:, None]) \n",
    "\n",
    "    # (3a) Normalize all rows to sum to 1\n",
    "    process_matrix /= process_matrix.sum(axis=0)\n",
    "    \n",
    "    # (4) Calculate the initial prior\n",
    "    prior0 = sps.gamma(a=4).pdf(r_t_range)\n",
    "    prior0 /= prior0.sum()\n",
    "\n",
    "    # Create a DataFrame that will hold our posteriors for each day\n",
    "    # Insert our prior as the first posterior.\n",
    "    posteriors_df = pd.DataFrame(\n",
    "        index=r_t_range,\n",
    "        columns=sr.index,\n",
    "        data={sr.index[0]: prior0}\n",
    "    )\n",
    "    \n",
    "    # We said we'd keep track of the sum of the log of the probability\n",
    "    # of the data for maximum likelihood calculation.\n",
    "    log_likelihood = 0.0\n",
    "\n",
    "    # (5) Iteratively apply Bayes' rule\n",
    "    for previous_day, current_day in zip(sr.index[:-1], sr.index[1:]):\n",
    "\n",
    "        #(5a) Calculate the new prior\n",
    "        current_prior = process_matrix @ posteriors_df[previous_day]\n",
    "        \n",
    "        #(5b) Calculate the numerator of Bayes' Rule: P(k|R_t)P(R_t)\n",
    "        numerator = likelihoods[current_day] * current_prior\n",
    "        \n",
    "        #(5c) Calcluate the denominator of Bayes' Rule P(k)\n",
    "        denominator = np.sum(numerator)\n",
    "        \n",
    "        # Execute full Bayes' Rule\n",
    "        posteriors_df[current_day] = numerator/denominator\n",
    "        \n",
    "        # Add to the running sum of log likelihoods\n",
    "        log_likelihood += np.log(denominator)\n",
    "    \n",
    "    return posteriors_df, log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_cases(cases, cutoff=25):\n",
    "    new_cases = cases.diff()\n",
    "\n",
    "    smoothed = new_cases.rolling(7,\n",
    "        win_type='gaussian',\n",
    "        min_periods=1,\n",
    "        center=True).mean(std=2).round()\n",
    "    \n",
    "    idx_start = np.searchsorted(smoothed, cutoff)\n",
    "    \n",
    "    smoothed = smoothed.iloc[idx_start:]\n",
    "    original = new_cases.loc[smoothed.index]\n",
    "    \n",
    "    return original, smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def highest_density_interval(pmf, p=.9):\n",
    "    \n",
    "    # If we pass a DataFrame, just call this recursively on the columns\n",
    "    if(isinstance(pmf, pd.DataFrame)):\n",
    "        \n",
    "        return pd.DataFrame([highest_density_interval(pmf[col], p=p) for col in pmf],\n",
    "                            index=pmf.columns)\n",
    "    \n",
    "    cumsum = np.cumsum(pmf.values)\n",
    "    \n",
    "    # N x N matrix of total probability mass for each low, high\n",
    "    total_p = cumsum - cumsum[:, None]\n",
    "    \n",
    "    # Return all indices with total_p > p\n",
    "    lows, highs = (total_p > p).nonzero()\n",
    "    if (lows.size == 0) or (highs.size == 0):\n",
    "    \n",
    "        return pd.Series([np.nan, np.nan], index=[f'Low_{p*100:.0f}', f'High_{p*100:.0f}'], dtype='float64')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Find the smallest range (highest density)\n",
    "        best = (highs - lows).argmin()\n",
    "\n",
    "        low = pmf.index[lows[best]]\n",
    "        high = pmf.index[highs[best]]\n",
    "\n",
    "        return pd.Series([low, high],\n",
    "                         index=[f'Low_{p*100:.0f}',\n",
    "                                f'High_{p*100:.0f}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Final Results\n",
    "\n",
    "Given that we've selected the optimal $\\sigma$, let's grab the precalculated posterior corresponding to that value of $\\sigma$ for each state. Let's also calculate the 90% and 50% highest density intervals (this takes a little while) and also the most likely value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We create an array for every possible value of Rt\n",
    "R_T_MAX = 12\n",
    "r_t_range = np.linspace(0, R_T_MAX, R_T_MAX*100+1)\n",
    "\n",
    "# Gamma is 1/serial interval\n",
    "# https://wwwnc.cdc.gov/eid/article/26/7/20-0282_article\n",
    "# https://www.nejm.org/doi/full/10.1056/NEJMoa2001316\n",
    "GAMMA = 1/7\n",
    "\n",
    "FILTERED_REGION_CODES = ['AS', 'GU', 'PR', 'VI', 'MP']\n",
    "url = 'https://covidtracking.com/api/v1/states/daily.csv'\n",
    "states = pd.read_csv(url,\n",
    "                     usecols=['date', 'state', 'positive'],\n",
    "                     parse_dates=['date'],\n",
    "                     index_col=['state', 'date'],\n",
    "                     squeeze=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sigmas = np.linspace(1/20, 1, 20)\n",
    "targets = ~states.index.get_level_values('state').isin(FILTERED_REGION_CODES)\n",
    "states_to_process = states.loc[targets]\n",
    "results = {}\n",
    "n_min = 25\n",
    "for state_name, cases in states_to_process.groupby(level='state'):\n",
    "    print(state_name)\n",
    "    n = 7\n",
    "    new, smoothed = prepare_cases(cases, cutoff=n)\n",
    "    while len(smoothed) == 0:\n",
    "        n -= 1\n",
    "        new, smoothed = prepare_cases(cases, cutoff=n)\n",
    "    result_dict = {}\n",
    "    n_min = min(n_min, n)\n",
    "    \n",
    "    # Holds all posteriors with every given value of sigma\n",
    "    result_dict['posteriors'] = []\n",
    "    \n",
    "    # Holds the log likelihood across all k for each value of sigma\n",
    "    result_dict['log_likelihoods'] = []\n",
    "    \n",
    "    for sigma in sigmas:\n",
    "        posteriors, log_likelihood = get_posteriors(smoothed, sigma=sigma)\n",
    "        result_dict['posteriors'].append(posteriors)\n",
    "        result_dict['log_likelihoods'].append(log_likelihood)\n",
    "    \n",
    "    # Store all results keyed off of state name\n",
    "    results[state_name] = result_dict\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'{n_min} Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Each index of this array holds the total of the log likelihoods for\n",
    "# the corresponding index of the sigmas array.\n",
    "total_log_likelihoods = np.zeros_like(sigmas)\n",
    "\n",
    "# Loop through each state's results and add the log likelihoods to the running total.\n",
    "for state_name, result_series in results.items():\n",
    "    total_log_likelihoods += result_series['log_likelihoods']\n",
    "\n",
    "# Select the index with the largest log likelihood total\n",
    "max_likelihood_index = total_log_likelihoods.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_results = None\n",
    "\n",
    "for state_name, result in results.items():\n",
    "    print(state_name)\n",
    "    posteriors = result['posteriors'][max_likelihood_index]\n",
    "    hdis_90 = highest_density_interval(posteriors, p=.9)\n",
    "    hdis_50 = highest_density_interval(posteriors, p=.5)\n",
    "    most_likely = posteriors.idxmax().rename('ML')\n",
    "    result_df = pd.concat([most_likely, hdis_90, hdis_50], axis=1)\n",
    "    mask_series = result_df.Low_90.isnull() | result_df.High_90.isnull()\n",
    "    result_df = result_df[~mask_series]\n",
    "    if final_results is None:\n",
    "        final_results = result_df\n",
    "    else:\n",
    "        final_results = pd.concat([final_results, result_df])\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HERD_IMMUNITY_THRESHOLD = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = states.to_frame()\n",
    "df.columns = ['cumulative_cases']\n",
    "df['new_cases'] = df.cumulative_cases.diff()\n",
    "final_results['DuFI'] = np.nan\n",
    "for index_tuple, row_series in final_results.iterrows():\n",
    "    state_name = index_tuple[0]\n",
    "    state_mask_series = (df.index.get_level_values('state') == state_name)\n",
    "    time_stamp = index_tuple[1]\n",
    "    date_mask_series = (df.index.get_level_values('date') == time_stamp)\n",
    "    mask_series = state_mask_series & date_mask_series\n",
    "    if df[mask_series].shape[0] > 0:\n",
    "        case_rate = int(df[mask_series].new_cases.squeeze())\n",
    "        if case_rate > 0:\n",
    "            date_mask_series = (df.index.get_level_values('date') <= time_stamp)\n",
    "            mask_series = state_mask_series & date_mask_series\n",
    "            infected_population = int(df[mask_series].cumulative_cases[-1])\n",
    "            if state_name == 'DC':\n",
    "                population = 601_723\n",
    "            else:\n",
    "                mask_series = (states_stats_df.State_Abbreviation == state_name)\n",
    "                population = states_stats_df[mask_series].Census_Population_2010.squeeze()\n",
    "            days_until_full_infection = int((HERD_IMMUNITY_THRESHOLD*population - infected_population)/case_rate)\n",
    "            final_results.loc[index_tuple, 'DuFI'] = days_until_full_infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to /home/jovyan/repos/notebooks/covid19/saves/pickle/final_results.pickle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.store_objects(final_results=final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ML</th>\n",
       "      <th>Low_90</th>\n",
       "      <th>High_90</th>\n",
       "      <th>Low_50</th>\n",
       "      <th>High_50</th>\n",
       "      <th>DuFI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HI</th>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>1.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.28</td>\n",
       "      <td>67972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-20</th>\n",
       "      <td>1.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.21</td>\n",
       "      <td>45314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-21</th>\n",
       "      <td>1.78</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1.32</td>\n",
       "      <td>2.09</td>\n",
       "      <td>87390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-22</th>\n",
       "      <td>1.66</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.52</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.02</td>\n",
       "      <td>111223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23</th>\n",
       "      <td>1.50</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.81</td>\n",
       "      <td>611727.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ML  Low_90  High_90  Low_50  High_50      DuFI\n",
       "state date                                                        \n",
       "HI    2020-06-19  1.91    0.86     2.94    1.41     2.28   67972.0\n",
       "      2020-06-20  1.87    0.88     2.84    1.39     2.21   45314.0\n",
       "      2020-06-21  1.78    0.85     2.69    1.32     2.09   87390.0\n",
       "      2020-06-22  1.66    0.78     2.52    1.30     2.02  111223.0\n",
       "      2020-06-23  1.50    0.66     2.30    1.13     1.81  611727.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "state_mask_series = (final_results.index.get_level_values('state') == final_results.groupby('state').DuFI.min().idxmax())\n",
    "final_results[state_mask_series].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ML</th>\n",
       "      <th>Low_90</th>\n",
       "      <th>High_90</th>\n",
       "      <th>Low_50</th>\n",
       "      <th>High_50</th>\n",
       "      <th>DuFI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">TX</th>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>1.57</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.59</td>\n",
       "      <td>6522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-20</th>\n",
       "      <td>1.46</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.48</td>\n",
       "      <td>5084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-21</th>\n",
       "      <td>1.40</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.41</td>\n",
       "      <td>5824.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-22</th>\n",
       "      <td>1.34</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.38</td>\n",
       "      <td>6864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23</th>\n",
       "      <td>1.32</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ML  Low_90  High_90  Low_50  High_50    DuFI\n",
       "state date                                                      \n",
       "TX    2020-06-19  1.57    1.44     1.67    1.49     1.59  6522.0\n",
       "      2020-06-20  1.46    1.33     1.56    1.38     1.48  5084.0\n",
       "      2020-06-21  1.40    1.28     1.50    1.31     1.41  5824.0\n",
       "      2020-06-22  1.34    1.22     1.44    1.29     1.38  6864.0\n",
       "      2020-06-23  1.32    1.20     1.42    1.26     1.35  4101.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "state_mask_series = (final_results.index.get_level_values('state') == final_results.groupby('state').DuFI.max().idxmax())\n",
    "final_results[state_mask_series].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cumulative_cases</th>\n",
       "      <th>percent_population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">TX</th>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>103305.0</td>\n",
       "      <td>0.410828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-20</th>\n",
       "      <td>107735.0</td>\n",
       "      <td>0.428445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-21</th>\n",
       "      <td>111601.0</td>\n",
       "      <td>0.443820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-22</th>\n",
       "      <td>114881.0</td>\n",
       "      <td>0.456864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23</th>\n",
       "      <td>120370.0</td>\n",
       "      <td>0.478693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cumulative_cases  percent_population\n",
       "state date                                            \n",
       "TX    2020-06-19          103305.0            0.410828\n",
       "      2020-06-20          107735.0            0.428445\n",
       "      2020-06-21          111601.0            0.443820\n",
       "      2020-06-22          114881.0            0.456864\n",
       "      2020-06-23          120370.0            0.478693"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "state_name = final_results.groupby('state').DuFI.max().idxmax()\n",
    "mask_series = (states_stats_df.State_Abbreviation == state_name)\n",
    "population = states_stats_df[mask_series].Census_Population_2010.squeeze()\n",
    "state_mask_series = (states.index.get_level_values('state') == state_name)\n",
    "df = states[state_mask_series].to_frame()\n",
    "df.columns = ['cumulative_cases']\n",
    "df['percent_population'] = df.cumulative_cases.map(lambda x: 100*x/population)\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Foundations (Python 3.8.3)",
   "language": "python",
   "name": "data_foundations_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
