{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Have you heard of DBpedia? I think it uses the info boxes to provide RDF triples and so might be a cleaner and much faster way to extract this data, without having to scrape Wikipedia directly.\n",
    "\n",
    "I think it would be fairly straightforward to write a SPARQL query for US counties; here is an example of the information you could extract: http://dbpedia.org/page/Autauga_County%2C_Alabama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "command_str = '{sys.executable} -m pip install --upgrade wikidata'.format(sys=sys)\n",
    "print(command_str)\n",
    "!{command_str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\Repositories\\notebooks\\covid19\\ipynb\\WikiData Exploration.ipynb\n",
      "['s.attempt_to_pickle', 's.data_csv_folder', 's.data_folder', 's.encoding_type', 's.load_csv', 's.load_dataframes', 's.load_object', 's.save_dataframes', 's.saves_csv_folder', 's.saves_folder', 's.saves_pickle_folder', 's.store_objects']\n",
      "Pretty printing has been turned OFF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Config', 'In', 'Out', 'RandomForestClassifier', 'SequenceMatcher', 'Storage', '_', '__', '___', '__builtin__', '__builtins__', '__doc__', '__loader__', '__name__', '__nonzero__', '__package__', '__spec__', '__warningregistry__', '_dh', '_i', '_i1', '_i2', '_ih', '_ii', '_iii', '_oh', 'bs', 'check_4_doubles', 'check_for_typos', 'clear_output', 'conjunctify_list', 'copyfile', 'counties_df', 'csv', 'datetime', 'encoding', 'example_iterrows', 'exit', 'filepath_regex', 'get_classifier', 'get_column_descriptions', 'get_data_structs_dataframe', 'get_datastructure_prediction', 'get_dir_tree', 'get_git_lfs_track_commands', 'get_importances', 'get_input_sample', 'get_ipython', 'get_max_rsquared_adj', 'get_module_version', 'get_notebook_path', 'get_page_tables', 'get_specific_gitignore_files', 'get_struct_name', 'humanize_bytes', 'io', 'ipykernel', 'json', 'jupyter_config_dir', 'math', 'notebook_path', 'notebookapp', 'np', 'nx', 'os', 'pd', 'pearsonr', 'pickle', 'plt', 'preprocess_data', 'print_all_files_ending_starting_with', 'print_all_files_ending_with', 'print_all_files_starting_with', 'quit', 're', 'remove_empty_folders', 'request', 's', 'scraping_utils', 'similar', 'sm', 'sns', 'stats', 'subprocess', 'sys', 'time', 'timedelta', 'tqdm', 'unquote', 'url_regex', 'urllib', 'wikidata', 'wikipedia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%run ../../load_magic/storage.py\n",
    "%run ../../load_magic/paths.py\n",
    "%run ../../load_magic/lists.py\n",
    "%run ../../load_magic/environment.py\n",
    "%run ../../load_magic/dataframes.py\n",
    "\n",
    "import scraping_utils\n",
    "wikipedia = scraping_utils.wikipedia\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from urllib import request\n",
    "from urllib.parse import unquote\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import wikidata\n",
    "\n",
    "notebook_path = get_notebook_path()\n",
    "print(notebook_path)\n",
    "s = Storage()\n",
    "counties_df = s.load_object('counties_df')\n",
    "print(['s.{}'.format(fn) for fn in dir(s) if not fn.startswith('_')])\n",
    "\n",
    "%pprint\n",
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyperclip\n",
    "\n",
    "pyperclip.copy(str(tuple((v, k) for k, v in idx_dict.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
